{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import math\n",
    "import torch.optim as optim\n",
    "from torchvision.transforms import transforms\n",
    "from torchvision import datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#test = torch.randn([1,3,106,106])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#conv_test = nn.Conv2d(3,6,7,stride=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 6, 50, 50])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#conv_test.forward(test).shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dense Block without Bottleneck\n",
    "# Single Conv Block is BN>>Relu>>Conv PreActivation type\n",
    "class DenseBlock(nn.Module):\n",
    "    def __init__(self,inChannels,growth_rate):\n",
    "        super(DenseBlock, self).__init__()\n",
    "        self.bn1 = nn.BatchNorm2d(num_features=inChannels)\n",
    "        self.conv1 = nn.Conv2d(inChannels,growth_rate,kernel_size=3,padding=1,stride=1,bias=False)\n",
    "        \n",
    "    def forward(self,x):\n",
    "        out = self.conv1(F.relu(self.bn1(x)))\n",
    "        out = torch.cat([x,out], 1) #Channel wise concatenation [n_batch,channel,*size]         \n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TransitionLayer(nn.Module):\n",
    "    def __init__(self, inChannels, outChannels):\n",
    "        super(TransitionLayer, self).__init__()\n",
    "        self.bn1 = nn.BatchNorm2d(num_features=inChannels)\n",
    "        self.conv1 = nn.Conv2d(inChannels,outChannels, kernel_size=1,bias=False)\n",
    "    \n",
    "    def forward(self,x):\n",
    "        out = self.conv1(F.relu(self.bn1(x)))\n",
    "        out = F.avg_pool2d(out,kernel_size=2,stride=2,padding=0)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DenseNet(nn.Module):\n",
    "    def __init__(self, growthRate,nClasses,block_config = (6,12,24,16)):\n",
    "        super(DenseNet, self).__init__()\n",
    "        nChannels = 2 * growthRate\n",
    "        self.conv_i1 = nn.Conv2d(3,nChannels, kernel_size=7,stride=2)\n",
    "        self.bn_i1 = nn.BatchNorm2d(num_features=3)\n",
    "        self.relu_i1 = nn.ReLU(inplace=True)\n",
    "        self.max_pool_i1 = nn.MaxPool2d(3,stride=2,padding=1)\n",
    "        \n",
    "        self.dense1 = self._make_dense_block(nChannels,block_config[0],growthRate)\n",
    "        nChannels += block_config[0]*growthRate\n",
    "        nOutChannels = int(math.floor(nChannels // 2))\n",
    "        self.trans1 = TransitionLayer(nChannels, nOutChannels )\n",
    "        \n",
    "        nChannels = nOutChannels\n",
    "        self.dense2 = self._make_dense_block(nChannels,block_config[1],growthRate)\n",
    "        nChannels += block_config[1]*growthRate\n",
    "        nOutChannels = int(math.floor(nChannels // 2))\n",
    "        self.trans2 = TransitionLayer(nChannels, nOutChannels )\n",
    "        \n",
    "        nChannels = nOutChannels\n",
    "        self.dense3 = self._make_dense_block(nChannels,block_config[2],growthRate)\n",
    "        nChannels += block_config[2]*growthRate\n",
    "        nOutChannels = int(math.floor(nChannels // 2))\n",
    "        self.trans3 = TransitionLayer(nChannels, nOutChannels )\n",
    "        \n",
    "        nChannels = nOutChannels\n",
    "        self.dense4 = self._make_dense_block(nChannels,block_config[3],growthRate)\n",
    "        nOutChannels += block_config[3]*growthRate\n",
    "\n",
    "        \n",
    "        #self.bn1 = nn.BatchNorm2d(nOutChannels)\n",
    "        self.fc = nn.Linear(nOutChannels, nClasses)\n",
    "        \n",
    "    \n",
    "    def _make_dense_block(self,inChannels,numBlocks,growthRate):\n",
    "        layers = []\n",
    "        for i in range(0,numBlocks):\n",
    "            layers.append(DenseBlock(inChannels, growthRate))\n",
    "            inChannels += growthRate\n",
    "        return nn.Sequential(*layers)\n",
    "    \n",
    "    \n",
    "    def weight_init(self):\n",
    "        for i,m in enumerate(self.modules()):\n",
    "            if isinstance(m,nn.Conv2d):\n",
    "                nn.init.xavier_normal(m.weight)\n",
    "                #nn.init.constant(m.bias, 0)\n",
    "    \n",
    "    def forward(self,x):\n",
    "        out = self.conv_i1(self.relu_i1(self.bn_i1(x)))\n",
    "        \n",
    "        #print(out.shape)\n",
    "        out = self.trans1(self.dense1(out))\n",
    "        #print(out.shape)\n",
    "        out = self.trans2(self.dense2(out))\n",
    "        #print(out.shape)\n",
    "        out = self.trans3(self.dense3(out))\n",
    "        #print(out.shape)\n",
    "        out = self.dense4(out)\n",
    "        #print(out.shape)\n",
    "        out = F.adaptive_avg_pool2d(out,(1,1))\n",
    "        #print(out.shape)\n",
    "        out = torch.flatten(out,1)\n",
    "        #print(out.shape)\n",
    "        out = self.fc(out)\n",
    "        #print(out.shape)\n",
    "        return out\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = DenseNet(12,10).cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DenseNet(\n",
       "  (conv_i1): Conv2d(3, 24, kernel_size=(7, 7), stride=(2, 2))\n",
       "  (bn_i1): BatchNorm2d(3, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (relu_i1): ReLU(inplace=True)\n",
       "  (max_pool_i1): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "  (dense1): Sequential(\n",
       "    (0): DenseBlock(\n",
       "      (bn1): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv1): Conv2d(24, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "    )\n",
       "    (1): DenseBlock(\n",
       "      (bn1): BatchNorm2d(36, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv1): Conv2d(36, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "    )\n",
       "    (2): DenseBlock(\n",
       "      (bn1): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv1): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "    )\n",
       "    (3): DenseBlock(\n",
       "      (bn1): BatchNorm2d(60, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv1): Conv2d(60, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "    )\n",
       "    (4): DenseBlock(\n",
       "      (bn1): BatchNorm2d(72, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv1): Conv2d(72, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "    )\n",
       "    (5): DenseBlock(\n",
       "      (bn1): BatchNorm2d(84, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv1): Conv2d(84, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "    )\n",
       "  )\n",
       "  (trans1): TransitionLayer(\n",
       "    (bn1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (conv1): Conv2d(96, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  )\n",
       "  (dense2): Sequential(\n",
       "    (0): DenseBlock(\n",
       "      (bn1): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv1): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "    )\n",
       "    (1): DenseBlock(\n",
       "      (bn1): BatchNorm2d(60, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv1): Conv2d(60, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "    )\n",
       "    (2): DenseBlock(\n",
       "      (bn1): BatchNorm2d(72, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv1): Conv2d(72, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "    )\n",
       "    (3): DenseBlock(\n",
       "      (bn1): BatchNorm2d(84, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv1): Conv2d(84, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "    )\n",
       "    (4): DenseBlock(\n",
       "      (bn1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv1): Conv2d(96, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "    )\n",
       "    (5): DenseBlock(\n",
       "      (bn1): BatchNorm2d(108, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv1): Conv2d(108, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "    )\n",
       "    (6): DenseBlock(\n",
       "      (bn1): BatchNorm2d(120, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv1): Conv2d(120, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "    )\n",
       "    (7): DenseBlock(\n",
       "      (bn1): BatchNorm2d(132, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv1): Conv2d(132, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "    )\n",
       "    (8): DenseBlock(\n",
       "      (bn1): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv1): Conv2d(144, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "    )\n",
       "    (9): DenseBlock(\n",
       "      (bn1): BatchNorm2d(156, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv1): Conv2d(156, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "    )\n",
       "    (10): DenseBlock(\n",
       "      (bn1): BatchNorm2d(168, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv1): Conv2d(168, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "    )\n",
       "    (11): DenseBlock(\n",
       "      (bn1): BatchNorm2d(180, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv1): Conv2d(180, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "    )\n",
       "  )\n",
       "  (trans2): TransitionLayer(\n",
       "    (bn1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (conv1): Conv2d(192, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  )\n",
       "  (dense3): Sequential(\n",
       "    (0): DenseBlock(\n",
       "      (bn1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv1): Conv2d(96, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "    )\n",
       "    (1): DenseBlock(\n",
       "      (bn1): BatchNorm2d(108, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv1): Conv2d(108, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "    )\n",
       "    (2): DenseBlock(\n",
       "      (bn1): BatchNorm2d(120, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv1): Conv2d(120, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "    )\n",
       "    (3): DenseBlock(\n",
       "      (bn1): BatchNorm2d(132, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv1): Conv2d(132, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "    )\n",
       "    (4): DenseBlock(\n",
       "      (bn1): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv1): Conv2d(144, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "    )\n",
       "    (5): DenseBlock(\n",
       "      (bn1): BatchNorm2d(156, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv1): Conv2d(156, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "    )\n",
       "    (6): DenseBlock(\n",
       "      (bn1): BatchNorm2d(168, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv1): Conv2d(168, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "    )\n",
       "    (7): DenseBlock(\n",
       "      (bn1): BatchNorm2d(180, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv1): Conv2d(180, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "    )\n",
       "    (8): DenseBlock(\n",
       "      (bn1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv1): Conv2d(192, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "    )\n",
       "    (9): DenseBlock(\n",
       "      (bn1): BatchNorm2d(204, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv1): Conv2d(204, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "    )\n",
       "    (10): DenseBlock(\n",
       "      (bn1): BatchNorm2d(216, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv1): Conv2d(216, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "    )\n",
       "    (11): DenseBlock(\n",
       "      (bn1): BatchNorm2d(228, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv1): Conv2d(228, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "    )\n",
       "    (12): DenseBlock(\n",
       "      (bn1): BatchNorm2d(240, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv1): Conv2d(240, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "    )\n",
       "    (13): DenseBlock(\n",
       "      (bn1): BatchNorm2d(252, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv1): Conv2d(252, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "    )\n",
       "    (14): DenseBlock(\n",
       "      (bn1): BatchNorm2d(264, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv1): Conv2d(264, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "    )\n",
       "    (15): DenseBlock(\n",
       "      (bn1): BatchNorm2d(276, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv1): Conv2d(276, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "    )\n",
       "    (16): DenseBlock(\n",
       "      (bn1): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv1): Conv2d(288, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "    )\n",
       "    (17): DenseBlock(\n",
       "      (bn1): BatchNorm2d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv1): Conv2d(300, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "    )\n",
       "    (18): DenseBlock(\n",
       "      (bn1): BatchNorm2d(312, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv1): Conv2d(312, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "    )\n",
       "    (19): DenseBlock(\n",
       "      (bn1): BatchNorm2d(324, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv1): Conv2d(324, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "    )\n",
       "    (20): DenseBlock(\n",
       "      (bn1): BatchNorm2d(336, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv1): Conv2d(336, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "    )\n",
       "    (21): DenseBlock(\n",
       "      (bn1): BatchNorm2d(348, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv1): Conv2d(348, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "    )\n",
       "    (22): DenseBlock(\n",
       "      (bn1): BatchNorm2d(360, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv1): Conv2d(360, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "    )\n",
       "    (23): DenseBlock(\n",
       "      (bn1): BatchNorm2d(372, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv1): Conv2d(372, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "    )\n",
       "  )\n",
       "  (trans3): TransitionLayer(\n",
       "    (bn1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (conv1): Conv2d(384, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  )\n",
       "  (dense4): Sequential(\n",
       "    (0): DenseBlock(\n",
       "      (bn1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv1): Conv2d(192, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "    )\n",
       "    (1): DenseBlock(\n",
       "      (bn1): BatchNorm2d(204, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv1): Conv2d(204, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "    )\n",
       "    (2): DenseBlock(\n",
       "      (bn1): BatchNorm2d(216, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv1): Conv2d(216, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "    )\n",
       "    (3): DenseBlock(\n",
       "      (bn1): BatchNorm2d(228, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv1): Conv2d(228, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "    )\n",
       "    (4): DenseBlock(\n",
       "      (bn1): BatchNorm2d(240, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv1): Conv2d(240, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "    )\n",
       "    (5): DenseBlock(\n",
       "      (bn1): BatchNorm2d(252, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv1): Conv2d(252, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "    )\n",
       "    (6): DenseBlock(\n",
       "      (bn1): BatchNorm2d(264, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv1): Conv2d(264, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "    )\n",
       "    (7): DenseBlock(\n",
       "      (bn1): BatchNorm2d(276, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv1): Conv2d(276, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "    )\n",
       "    (8): DenseBlock(\n",
       "      (bn1): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv1): Conv2d(288, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "    )\n",
       "    (9): DenseBlock(\n",
       "      (bn1): BatchNorm2d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv1): Conv2d(300, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "    )\n",
       "    (10): DenseBlock(\n",
       "      (bn1): BatchNorm2d(312, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv1): Conv2d(312, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "    )\n",
       "    (11): DenseBlock(\n",
       "      (bn1): BatchNorm2d(324, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv1): Conv2d(324, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "    )\n",
       "    (12): DenseBlock(\n",
       "      (bn1): BatchNorm2d(336, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv1): Conv2d(336, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "    )\n",
       "    (13): DenseBlock(\n",
       "      (bn1): BatchNorm2d(348, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv1): Conv2d(348, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "    )\n",
       "    (14): DenseBlock(\n",
       "      (bn1): BatchNorm2d(360, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv1): Conv2d(360, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "    )\n",
       "    (15): DenseBlock(\n",
       "      (bn1): BatchNorm2d(372, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv1): Conv2d(372, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "    )\n",
       "  )\n",
       "  (fc): Linear(in_features=384, out_features=10, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mohit\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:47: UserWarning: nn.init.xavier_normal is now deprecated in favor of nn.init.xavier_normal_.\n"
     ]
    }
   ],
   "source": [
    "model.weight_init()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "       BatchNorm2d-1            [-1, 3, 32, 32]               6\n",
      "              ReLU-2            [-1, 3, 32, 32]               0\n",
      "            Conv2d-3           [-1, 24, 13, 13]           3,552\n",
      "       BatchNorm2d-4           [-1, 24, 13, 13]              48\n",
      "            Conv2d-5           [-1, 12, 13, 13]           2,592\n",
      "        DenseBlock-6           [-1, 36, 13, 13]               0\n",
      "       BatchNorm2d-7           [-1, 36, 13, 13]              72\n",
      "            Conv2d-8           [-1, 12, 13, 13]           3,888\n",
      "        DenseBlock-9           [-1, 48, 13, 13]               0\n",
      "      BatchNorm2d-10           [-1, 48, 13, 13]              96\n",
      "           Conv2d-11           [-1, 12, 13, 13]           5,184\n",
      "       DenseBlock-12           [-1, 60, 13, 13]               0\n",
      "      BatchNorm2d-13           [-1, 60, 13, 13]             120\n",
      "           Conv2d-14           [-1, 12, 13, 13]           6,480\n",
      "       DenseBlock-15           [-1, 72, 13, 13]               0\n",
      "      BatchNorm2d-16           [-1, 72, 13, 13]             144\n",
      "           Conv2d-17           [-1, 12, 13, 13]           7,776\n",
      "       DenseBlock-18           [-1, 84, 13, 13]               0\n",
      "      BatchNorm2d-19           [-1, 84, 13, 13]             168\n",
      "           Conv2d-20           [-1, 12, 13, 13]           9,072\n",
      "       DenseBlock-21           [-1, 96, 13, 13]               0\n",
      "      BatchNorm2d-22           [-1, 96, 13, 13]             192\n",
      "           Conv2d-23           [-1, 48, 13, 13]           4,608\n",
      "  TransitionLayer-24             [-1, 48, 6, 6]               0\n",
      "      BatchNorm2d-25             [-1, 48, 6, 6]              96\n",
      "           Conv2d-26             [-1, 12, 6, 6]           5,184\n",
      "       DenseBlock-27             [-1, 60, 6, 6]               0\n",
      "      BatchNorm2d-28             [-1, 60, 6, 6]             120\n",
      "           Conv2d-29             [-1, 12, 6, 6]           6,480\n",
      "       DenseBlock-30             [-1, 72, 6, 6]               0\n",
      "      BatchNorm2d-31             [-1, 72, 6, 6]             144\n",
      "           Conv2d-32             [-1, 12, 6, 6]           7,776\n",
      "       DenseBlock-33             [-1, 84, 6, 6]               0\n",
      "      BatchNorm2d-34             [-1, 84, 6, 6]             168\n",
      "           Conv2d-35             [-1, 12, 6, 6]           9,072\n",
      "       DenseBlock-36             [-1, 96, 6, 6]               0\n",
      "      BatchNorm2d-37             [-1, 96, 6, 6]             192\n",
      "           Conv2d-38             [-1, 12, 6, 6]          10,368\n",
      "       DenseBlock-39            [-1, 108, 6, 6]               0\n",
      "      BatchNorm2d-40            [-1, 108, 6, 6]             216\n",
      "           Conv2d-41             [-1, 12, 6, 6]          11,664\n",
      "       DenseBlock-42            [-1, 120, 6, 6]               0\n",
      "      BatchNorm2d-43            [-1, 120, 6, 6]             240\n",
      "           Conv2d-44             [-1, 12, 6, 6]          12,960\n",
      "       DenseBlock-45            [-1, 132, 6, 6]               0\n",
      "      BatchNorm2d-46            [-1, 132, 6, 6]             264\n",
      "           Conv2d-47             [-1, 12, 6, 6]          14,256\n",
      "       DenseBlock-48            [-1, 144, 6, 6]               0\n",
      "      BatchNorm2d-49            [-1, 144, 6, 6]             288\n",
      "           Conv2d-50             [-1, 12, 6, 6]          15,552\n",
      "       DenseBlock-51            [-1, 156, 6, 6]               0\n",
      "      BatchNorm2d-52            [-1, 156, 6, 6]             312\n",
      "           Conv2d-53             [-1, 12, 6, 6]          16,848\n",
      "       DenseBlock-54            [-1, 168, 6, 6]               0\n",
      "      BatchNorm2d-55            [-1, 168, 6, 6]             336\n",
      "           Conv2d-56             [-1, 12, 6, 6]          18,144\n",
      "       DenseBlock-57            [-1, 180, 6, 6]               0\n",
      "      BatchNorm2d-58            [-1, 180, 6, 6]             360\n",
      "           Conv2d-59             [-1, 12, 6, 6]          19,440\n",
      "       DenseBlock-60            [-1, 192, 6, 6]               0\n",
      "      BatchNorm2d-61            [-1, 192, 6, 6]             384\n",
      "           Conv2d-62             [-1, 96, 6, 6]          18,432\n",
      "  TransitionLayer-63             [-1, 96, 3, 3]               0\n",
      "      BatchNorm2d-64             [-1, 96, 3, 3]             192\n",
      "           Conv2d-65             [-1, 12, 3, 3]          10,368\n",
      "       DenseBlock-66            [-1, 108, 3, 3]               0\n",
      "      BatchNorm2d-67            [-1, 108, 3, 3]             216\n",
      "           Conv2d-68             [-1, 12, 3, 3]          11,664\n",
      "       DenseBlock-69            [-1, 120, 3, 3]               0\n",
      "      BatchNorm2d-70            [-1, 120, 3, 3]             240\n",
      "           Conv2d-71             [-1, 12, 3, 3]          12,960\n",
      "       DenseBlock-72            [-1, 132, 3, 3]               0\n",
      "      BatchNorm2d-73            [-1, 132, 3, 3]             264\n",
      "           Conv2d-74             [-1, 12, 3, 3]          14,256\n",
      "       DenseBlock-75            [-1, 144, 3, 3]               0\n",
      "      BatchNorm2d-76            [-1, 144, 3, 3]             288\n",
      "           Conv2d-77             [-1, 12, 3, 3]          15,552\n",
      "       DenseBlock-78            [-1, 156, 3, 3]               0\n",
      "      BatchNorm2d-79            [-1, 156, 3, 3]             312\n",
      "           Conv2d-80             [-1, 12, 3, 3]          16,848\n",
      "       DenseBlock-81            [-1, 168, 3, 3]               0\n",
      "      BatchNorm2d-82            [-1, 168, 3, 3]             336\n",
      "           Conv2d-83             [-1, 12, 3, 3]          18,144\n",
      "       DenseBlock-84            [-1, 180, 3, 3]               0\n",
      "      BatchNorm2d-85            [-1, 180, 3, 3]             360\n",
      "           Conv2d-86             [-1, 12, 3, 3]          19,440\n",
      "       DenseBlock-87            [-1, 192, 3, 3]               0\n",
      "      BatchNorm2d-88            [-1, 192, 3, 3]             384\n",
      "           Conv2d-89             [-1, 12, 3, 3]          20,736\n",
      "       DenseBlock-90            [-1, 204, 3, 3]               0\n",
      "      BatchNorm2d-91            [-1, 204, 3, 3]             408\n",
      "           Conv2d-92             [-1, 12, 3, 3]          22,032\n",
      "       DenseBlock-93            [-1, 216, 3, 3]               0\n",
      "      BatchNorm2d-94            [-1, 216, 3, 3]             432\n",
      "           Conv2d-95             [-1, 12, 3, 3]          23,328\n",
      "       DenseBlock-96            [-1, 228, 3, 3]               0\n",
      "      BatchNorm2d-97            [-1, 228, 3, 3]             456\n",
      "           Conv2d-98             [-1, 12, 3, 3]          24,624\n",
      "       DenseBlock-99            [-1, 240, 3, 3]               0\n",
      "     BatchNorm2d-100            [-1, 240, 3, 3]             480\n",
      "          Conv2d-101             [-1, 12, 3, 3]          25,920\n",
      "      DenseBlock-102            [-1, 252, 3, 3]               0\n",
      "     BatchNorm2d-103            [-1, 252, 3, 3]             504\n",
      "          Conv2d-104             [-1, 12, 3, 3]          27,216\n",
      "      DenseBlock-105            [-1, 264, 3, 3]               0\n",
      "     BatchNorm2d-106            [-1, 264, 3, 3]             528\n",
      "          Conv2d-107             [-1, 12, 3, 3]          28,512\n",
      "      DenseBlock-108            [-1, 276, 3, 3]               0\n",
      "     BatchNorm2d-109            [-1, 276, 3, 3]             552\n",
      "          Conv2d-110             [-1, 12, 3, 3]          29,808\n",
      "      DenseBlock-111            [-1, 288, 3, 3]               0\n",
      "     BatchNorm2d-112            [-1, 288, 3, 3]             576\n",
      "          Conv2d-113             [-1, 12, 3, 3]          31,104\n",
      "      DenseBlock-114            [-1, 300, 3, 3]               0\n",
      "     BatchNorm2d-115            [-1, 300, 3, 3]             600\n",
      "          Conv2d-116             [-1, 12, 3, 3]          32,400\n",
      "      DenseBlock-117            [-1, 312, 3, 3]               0\n",
      "     BatchNorm2d-118            [-1, 312, 3, 3]             624\n",
      "          Conv2d-119             [-1, 12, 3, 3]          33,696\n",
      "      DenseBlock-120            [-1, 324, 3, 3]               0\n",
      "     BatchNorm2d-121            [-1, 324, 3, 3]             648\n",
      "          Conv2d-122             [-1, 12, 3, 3]          34,992\n",
      "      DenseBlock-123            [-1, 336, 3, 3]               0\n",
      "     BatchNorm2d-124            [-1, 336, 3, 3]             672\n",
      "          Conv2d-125             [-1, 12, 3, 3]          36,288\n",
      "      DenseBlock-126            [-1, 348, 3, 3]               0\n",
      "     BatchNorm2d-127            [-1, 348, 3, 3]             696\n",
      "          Conv2d-128             [-1, 12, 3, 3]          37,584\n",
      "      DenseBlock-129            [-1, 360, 3, 3]               0\n",
      "     BatchNorm2d-130            [-1, 360, 3, 3]             720\n",
      "          Conv2d-131             [-1, 12, 3, 3]          38,880\n",
      "      DenseBlock-132            [-1, 372, 3, 3]               0\n",
      "     BatchNorm2d-133            [-1, 372, 3, 3]             744\n",
      "          Conv2d-134             [-1, 12, 3, 3]          40,176\n",
      "      DenseBlock-135            [-1, 384, 3, 3]               0\n",
      "     BatchNorm2d-136            [-1, 384, 3, 3]             768\n",
      "          Conv2d-137            [-1, 192, 3, 3]          73,728\n",
      " TransitionLayer-138            [-1, 192, 1, 1]               0\n",
      "     BatchNorm2d-139            [-1, 192, 1, 1]             384\n",
      "          Conv2d-140             [-1, 12, 1, 1]          20,736\n",
      "      DenseBlock-141            [-1, 204, 1, 1]               0\n",
      "     BatchNorm2d-142            [-1, 204, 1, 1]             408\n",
      "          Conv2d-143             [-1, 12, 1, 1]          22,032\n",
      "      DenseBlock-144            [-1, 216, 1, 1]               0\n",
      "     BatchNorm2d-145            [-1, 216, 1, 1]             432\n",
      "          Conv2d-146             [-1, 12, 1, 1]          23,328\n",
      "      DenseBlock-147            [-1, 228, 1, 1]               0\n",
      "     BatchNorm2d-148            [-1, 228, 1, 1]             456\n",
      "          Conv2d-149             [-1, 12, 1, 1]          24,624\n",
      "      DenseBlock-150            [-1, 240, 1, 1]               0\n",
      "     BatchNorm2d-151            [-1, 240, 1, 1]             480\n",
      "          Conv2d-152             [-1, 12, 1, 1]          25,920\n",
      "      DenseBlock-153            [-1, 252, 1, 1]               0\n",
      "     BatchNorm2d-154            [-1, 252, 1, 1]             504\n",
      "          Conv2d-155             [-1, 12, 1, 1]          27,216\n",
      "      DenseBlock-156            [-1, 264, 1, 1]               0\n",
      "     BatchNorm2d-157            [-1, 264, 1, 1]             528\n",
      "          Conv2d-158             [-1, 12, 1, 1]          28,512\n",
      "      DenseBlock-159            [-1, 276, 1, 1]               0\n",
      "     BatchNorm2d-160            [-1, 276, 1, 1]             552\n",
      "          Conv2d-161             [-1, 12, 1, 1]          29,808\n",
      "      DenseBlock-162            [-1, 288, 1, 1]               0\n",
      "     BatchNorm2d-163            [-1, 288, 1, 1]             576\n",
      "          Conv2d-164             [-1, 12, 1, 1]          31,104\n",
      "      DenseBlock-165            [-1, 300, 1, 1]               0\n",
      "     BatchNorm2d-166            [-1, 300, 1, 1]             600\n",
      "          Conv2d-167             [-1, 12, 1, 1]          32,400\n",
      "      DenseBlock-168            [-1, 312, 1, 1]               0\n",
      "     BatchNorm2d-169            [-1, 312, 1, 1]             624\n",
      "          Conv2d-170             [-1, 12, 1, 1]          33,696\n",
      "      DenseBlock-171            [-1, 324, 1, 1]               0\n",
      "     BatchNorm2d-172            [-1, 324, 1, 1]             648\n",
      "          Conv2d-173             [-1, 12, 1, 1]          34,992\n",
      "      DenseBlock-174            [-1, 336, 1, 1]               0\n",
      "     BatchNorm2d-175            [-1, 336, 1, 1]             672\n",
      "          Conv2d-176             [-1, 12, 1, 1]          36,288\n",
      "      DenseBlock-177            [-1, 348, 1, 1]               0\n",
      "     BatchNorm2d-178            [-1, 348, 1, 1]             696\n",
      "          Conv2d-179             [-1, 12, 1, 1]          37,584\n",
      "      DenseBlock-180            [-1, 360, 1, 1]               0\n",
      "     BatchNorm2d-181            [-1, 360, 1, 1]             720\n",
      "          Conv2d-182             [-1, 12, 1, 1]          38,880\n",
      "      DenseBlock-183            [-1, 372, 1, 1]               0\n",
      "     BatchNorm2d-184            [-1, 372, 1, 1]             744\n",
      "          Conv2d-185             [-1, 12, 1, 1]          40,176\n",
      "      DenseBlock-186            [-1, 384, 1, 1]               0\n",
      "          Linear-187                   [-1, 10]           3,850\n",
      "================================================================\n",
      "Total params: 1,405,720\n",
      "Trainable params: 1,405,720\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.01\n",
      "Forward/backward pass size (MB): 3.14\n",
      "Params size (MB): 5.36\n",
      "Estimated Total Size (MB): 8.51\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "from torchsummary import summary\n",
    "summary(model.cuda(), input_size=(3,32,32))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "transform = transforms.Compose(\n",
    "    [transforms.ToTensor(),\n",
    "     transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
    "\n",
    "trainset = datasets.CIFAR10(root='D:\\Work\\DL_learn\\Datasets', train=True,\n",
    "                                        download=True, transform=transform)\n",
    "\n",
    "testset = datasets.CIFAR10(root='D:\\Work\\DL_learn\\Datasets', train=False,\n",
    "                                       download=True, transform=transform)\n",
    "\n",
    "classes = ('plane', 'car', 'bird', 'cat',\n",
    "           'deer', 'dog', 'frog', 'horse', 'ship', 'truck')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 10\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=batch_size,\n",
    "                                          shuffle=True, num_workers=2)\n",
    "\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size=batch_size,\n",
    "                                         shuffle=False, num_workers=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hyper Params and Loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "momentum = 0.95\n",
    "learning_rate = 0.001\n",
    "nr_classes = 10\n",
    "num_epochs = 150\n",
    "loss_vctr = []\n",
    "\n",
    "# Oprimization Criteria and Optimization method\n",
    "criterion = nn.CrossEntropyLoss().cuda()\n",
    "optimizer = optim.SGD(model.parameters(), lr=learning_rate, momentum=momentum, nesterov = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorboardX import SummaryWriter\n",
    "writer = SummaryWriter('runs_densenetcifar10')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([10, 10])\n"
     ]
    }
   ],
   "source": [
    "# check\n",
    "img,lab = next(iter(trainloader))\n",
    "print(model(img.cuda()).shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "@torch.no_grad()\n",
    "def val(testloader,model):\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    for data in testloader:\n",
    "        images, labels = data\n",
    "        outputs = model(images.cuda())\n",
    "        _, predicted = torch.max(outputs.cpu().data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum()\n",
    "        return (100 * correct / total)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/150], Step [1/5000], Loss = 2.2603\n",
      "Epoch [1/150], Step [101/5000], Loss = 2.1505\n",
      "Epoch [1/150], Step [201/5000], Loss = 1.8400\n",
      "Epoch [1/150], Step [301/5000], Loss = 1.9526\n",
      "Epoch [1/150], Step [401/5000], Loss = 1.5498\n",
      "Epoch [1/150], Step [501/5000], Loss = 1.5303\n",
      "Epoch [1/150], Step [601/5000], Loss = 2.2121\n",
      "Epoch [1/150], Step [701/5000], Loss = 1.5430\n",
      "Epoch [1/150], Step [801/5000], Loss = 2.0853\n",
      "Epoch [1/150], Step [901/5000], Loss = 1.6663\n",
      "Epoch [1/150], Step [1001/5000], Loss = 1.9463\n",
      "Epoch [1/150], Step [1101/5000], Loss = 1.9798\n",
      "Epoch [1/150], Step [1201/5000], Loss = 1.6013\n",
      "Epoch [1/150], Step [1301/5000], Loss = 1.5902\n",
      "Epoch [1/150], Step [1401/5000], Loss = 1.9786\n",
      "Epoch [1/150], Step [1501/5000], Loss = 1.6033\n",
      "Epoch [1/150], Step [1601/5000], Loss = 2.0231\n",
      "Epoch [1/150], Step [1701/5000], Loss = 2.1045\n",
      "Epoch [1/150], Step [1801/5000], Loss = 1.3183\n",
      "Epoch [1/150], Step [1901/5000], Loss = 1.2828\n",
      "Epoch [1/150], Step [2001/5000], Loss = 1.2455\n",
      "Epoch [1/150], Step [2101/5000], Loss = 1.4291\n",
      "Epoch [1/150], Step [2201/5000], Loss = 1.0902\n",
      "Epoch [1/150], Step [2301/5000], Loss = 1.6161\n",
      "Epoch [1/150], Step [2401/5000], Loss = 1.3895\n",
      "Epoch [1/150], Step [2501/5000], Loss = 1.5603\n",
      "Epoch [1/150], Step [2601/5000], Loss = 1.3525\n",
      "Epoch [1/150], Step [2701/5000], Loss = 1.2562\n",
      "Epoch [1/150], Step [2801/5000], Loss = 1.2106\n",
      "Epoch [1/150], Step [2901/5000], Loss = 1.5106\n",
      "Epoch [1/150], Step [3001/5000], Loss = 2.1577\n",
      "Epoch [1/150], Step [3101/5000], Loss = 1.6955\n",
      "Epoch [1/150], Step [3201/5000], Loss = 1.8953\n",
      "Epoch [1/150], Step [3301/5000], Loss = 0.8424\n",
      "Epoch [1/150], Step [3401/5000], Loss = 0.6789\n",
      "Epoch [1/150], Step [3501/5000], Loss = 0.7510\n",
      "Epoch [1/150], Step [3601/5000], Loss = 1.1295\n",
      "Epoch [1/150], Step [3701/5000], Loss = 1.0693\n",
      "Epoch [1/150], Step [3801/5000], Loss = 1.4582\n",
      "Epoch [1/150], Step [3901/5000], Loss = 1.2534\n",
      "Epoch [1/150], Step [4001/5000], Loss = 0.9597\n",
      "Epoch [1/150], Step [4101/5000], Loss = 1.3290\n",
      "Epoch [1/150], Step [4201/5000], Loss = 1.1839\n",
      "Epoch [1/150], Step [4301/5000], Loss = 0.8348\n",
      "Epoch [1/150], Step [4401/5000], Loss = 1.2470\n",
      "Epoch [1/150], Step [4501/5000], Loss = 1.7125\n",
      "Epoch [1/150], Step [4601/5000], Loss = 1.1733\n",
      "Epoch [1/150], Step [4701/5000], Loss = 1.3299\n",
      "Epoch [1/150], Step [4801/5000], Loss = 0.9699\n",
      "Epoch [1/150], Step [4901/5000], Loss = 1.5513\n",
      "Epoch [1/150], Acc = 50.0000\n",
      "Epoch [2/150], Step [1/5000], Loss = 0.8409\n",
      "Epoch [2/150], Step [101/5000], Loss = 0.6354\n",
      "Epoch [2/150], Step [201/5000], Loss = 0.8326\n",
      "Epoch [2/150], Step [301/5000], Loss = 1.4726\n",
      "Epoch [2/150], Step [401/5000], Loss = 0.6881\n",
      "Epoch [2/150], Step [501/5000], Loss = 1.4352\n",
      "Epoch [2/150], Step [601/5000], Loss = 2.0939\n",
      "Epoch [2/150], Step [701/5000], Loss = 1.2106\n",
      "Epoch [2/150], Step [801/5000], Loss = 0.9497\n",
      "Epoch [2/150], Step [901/5000], Loss = 1.9549\n",
      "Epoch [2/150], Step [1001/5000], Loss = 0.7057\n",
      "Epoch [2/150], Step [1101/5000], Loss = 1.7756\n",
      "Epoch [2/150], Step [1201/5000], Loss = 1.2994\n",
      "Epoch [2/150], Step [1301/5000], Loss = 1.7245\n",
      "Epoch [2/150], Step [1401/5000], Loss = 1.0271\n",
      "Epoch [2/150], Step [1501/5000], Loss = 1.0681\n",
      "Epoch [2/150], Step [1601/5000], Loss = 1.5180\n",
      "Epoch [2/150], Step [1701/5000], Loss = 1.9050\n",
      "Epoch [2/150], Step [1801/5000], Loss = 0.8563\n",
      "Epoch [2/150], Step [1901/5000], Loss = 1.3678\n",
      "Epoch [2/150], Step [2001/5000], Loss = 0.9171\n",
      "Epoch [2/150], Step [2101/5000], Loss = 1.2040\n",
      "Epoch [2/150], Step [2201/5000], Loss = 0.6253\n",
      "Epoch [2/150], Step [2301/5000], Loss = 1.1776\n",
      "Epoch [2/150], Step [2401/5000], Loss = 1.4378\n",
      "Epoch [2/150], Step [2501/5000], Loss = 0.8018\n",
      "Epoch [2/150], Step [2601/5000], Loss = 0.8439\n",
      "Epoch [2/150], Step [2701/5000], Loss = 0.7915\n",
      "Epoch [2/150], Step [2801/5000], Loss = 0.9538\n",
      "Epoch [2/150], Step [2901/5000], Loss = 0.9566\n",
      "Epoch [2/150], Step [3001/5000], Loss = 0.9434\n",
      "Epoch [2/150], Step [3101/5000], Loss = 1.4160\n",
      "Epoch [2/150], Step [3201/5000], Loss = 1.0617\n",
      "Epoch [2/150], Step [3301/5000], Loss = 1.0491\n",
      "Epoch [2/150], Step [3401/5000], Loss = 0.6924\n",
      "Epoch [2/150], Step [3501/5000], Loss = 1.0960\n",
      "Epoch [2/150], Step [3601/5000], Loss = 0.3823\n",
      "Epoch [2/150], Step [3701/5000], Loss = 1.8978\n",
      "Epoch [2/150], Step [3801/5000], Loss = 0.7678\n",
      "Epoch [2/150], Step [3901/5000], Loss = 0.9470\n",
      "Epoch [2/150], Step [4001/5000], Loss = 1.1046\n",
      "Epoch [2/150], Step [4101/5000], Loss = 0.6799\n",
      "Epoch [2/150], Step [4201/5000], Loss = 0.9348\n",
      "Epoch [2/150], Step [4301/5000], Loss = 1.3420\n",
      "Epoch [2/150], Step [4401/5000], Loss = 1.2762\n",
      "Epoch [2/150], Step [4501/5000], Loss = 1.3945\n",
      "Epoch [2/150], Step [4601/5000], Loss = 0.6880\n",
      "Epoch [2/150], Step [4701/5000], Loss = 0.5640\n",
      "Epoch [2/150], Step [4801/5000], Loss = 1.9795\n",
      "Epoch [2/150], Step [4901/5000], Loss = 0.7915\n",
      "Epoch [2/150], Acc = 30.0000\n",
      "Epoch [3/150], Step [1/5000], Loss = 0.6286\n",
      "Epoch [3/150], Step [101/5000], Loss = 1.6326\n",
      "Epoch [3/150], Step [201/5000], Loss = 1.4248\n",
      "Epoch [3/150], Step [301/5000], Loss = 0.8370\n",
      "Epoch [3/150], Step [401/5000], Loss = 1.5230\n",
      "Epoch [3/150], Step [501/5000], Loss = 0.4057\n",
      "Epoch [3/150], Step [601/5000], Loss = 1.6147\n",
      "Epoch [3/150], Step [701/5000], Loss = 1.0647\n",
      "Epoch [3/150], Step [801/5000], Loss = 0.6628\n",
      "Epoch [3/150], Step [901/5000], Loss = 0.7119\n",
      "Epoch [3/150], Step [1001/5000], Loss = 1.2606\n",
      "Epoch [3/150], Step [1101/5000], Loss = 1.2945\n",
      "Epoch [3/150], Step [1201/5000], Loss = 0.5558\n",
      "Epoch [3/150], Step [1301/5000], Loss = 0.8745\n",
      "Epoch [3/150], Step [1401/5000], Loss = 0.3882\n",
      "Epoch [3/150], Step [1501/5000], Loss = 0.4713\n",
      "Epoch [3/150], Step [1601/5000], Loss = 1.2278\n",
      "Epoch [3/150], Step [1701/5000], Loss = 1.4511\n",
      "Epoch [3/150], Step [1801/5000], Loss = 1.3686\n",
      "Epoch [3/150], Step [1901/5000], Loss = 1.8839\n",
      "Epoch [3/150], Step [2001/5000], Loss = 1.6542\n",
      "Epoch [3/150], Step [2101/5000], Loss = 0.9187\n",
      "Epoch [3/150], Step [2201/5000], Loss = 0.7881\n",
      "Epoch [3/150], Step [2301/5000], Loss = 1.2903\n",
      "Epoch [3/150], Step [2401/5000], Loss = 0.7257\n",
      "Epoch [3/150], Step [2501/5000], Loss = 1.2443\n",
      "Epoch [3/150], Step [2601/5000], Loss = 0.4770\n",
      "Epoch [3/150], Step [2701/5000], Loss = 1.1114\n",
      "Epoch [3/150], Step [2801/5000], Loss = 1.4628\n",
      "Epoch [3/150], Step [2901/5000], Loss = 1.2101\n",
      "Epoch [3/150], Step [3001/5000], Loss = 0.3615\n",
      "Epoch [3/150], Step [3101/5000], Loss = 1.2462\n",
      "Epoch [3/150], Step [3201/5000], Loss = 0.9036\n",
      "Epoch [3/150], Step [3301/5000], Loss = 0.7006\n",
      "Epoch [3/150], Step [3401/5000], Loss = 1.0617\n",
      "Epoch [3/150], Step [3501/5000], Loss = 0.7392\n",
      "Epoch [3/150], Step [3601/5000], Loss = 0.5823\n",
      "Epoch [3/150], Step [3701/5000], Loss = 0.7891\n",
      "Epoch [3/150], Step [3801/5000], Loss = 0.9199\n",
      "Epoch [3/150], Step [3901/5000], Loss = 0.9045\n",
      "Epoch [3/150], Step [4001/5000], Loss = 0.9529\n",
      "Epoch [3/150], Step [4101/5000], Loss = 1.0156\n",
      "Epoch [3/150], Step [4201/5000], Loss = 0.5673\n",
      "Epoch [3/150], Step [4301/5000], Loss = 1.1537\n",
      "Epoch [3/150], Step [4401/5000], Loss = 1.0307\n",
      "Epoch [3/150], Step [4501/5000], Loss = 1.4176\n",
      "Epoch [3/150], Step [4601/5000], Loss = 0.7556\n",
      "Epoch [3/150], Step [4701/5000], Loss = 1.0506\n",
      "Epoch [3/150], Step [4801/5000], Loss = 0.7387\n",
      "Epoch [3/150], Step [4901/5000], Loss = 1.0185\n",
      "Epoch [3/150], Acc = 40.0000\n",
      "Epoch [4/150], Step [1/5000], Loss = 0.4441\n",
      "Epoch [4/150], Step [101/5000], Loss = 1.0198\n",
      "Epoch [4/150], Step [201/5000], Loss = 0.6757\n",
      "Epoch [4/150], Step [301/5000], Loss = 0.8483\n",
      "Epoch [4/150], Step [401/5000], Loss = 0.8822\n",
      "Epoch [4/150], Step [501/5000], Loss = 0.5355\n",
      "Epoch [4/150], Step [601/5000], Loss = 0.5946\n",
      "Epoch [4/150], Step [701/5000], Loss = 0.6845\n",
      "Epoch [4/150], Step [801/5000], Loss = 0.7959\n",
      "Epoch [4/150], Step [901/5000], Loss = 0.8038\n",
      "Epoch [4/150], Step [1001/5000], Loss = 1.0543\n",
      "Epoch [4/150], Step [1101/5000], Loss = 0.1246\n",
      "Epoch [4/150], Step [1201/5000], Loss = 0.7508\n",
      "Epoch [4/150], Step [1301/5000], Loss = 1.6061\n",
      "Epoch [4/150], Step [1401/5000], Loss = 1.3690\n",
      "Epoch [4/150], Step [1501/5000], Loss = 0.8285\n",
      "Epoch [4/150], Step [1601/5000], Loss = 0.7966\n",
      "Epoch [4/150], Step [1701/5000], Loss = 0.6964\n",
      "Epoch [4/150], Step [1801/5000], Loss = 1.0460\n",
      "Epoch [4/150], Step [1901/5000], Loss = 0.6790\n",
      "Epoch [4/150], Step [2001/5000], Loss = 1.0518\n",
      "Epoch [4/150], Step [2101/5000], Loss = 1.0660\n",
      "Epoch [4/150], Step [2201/5000], Loss = 0.7523\n",
      "Epoch [4/150], Step [2301/5000], Loss = 0.8715\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [4/150], Step [2401/5000], Loss = 0.8739\n",
      "Epoch [4/150], Step [2501/5000], Loss = 0.9294\n",
      "Epoch [4/150], Step [2601/5000], Loss = 0.7423\n",
      "Epoch [4/150], Step [2701/5000], Loss = 1.2037\n",
      "Epoch [4/150], Step [2801/5000], Loss = 0.7492\n",
      "Epoch [4/150], Step [2901/5000], Loss = 1.1895\n",
      "Epoch [4/150], Step [3001/5000], Loss = 0.6321\n",
      "Epoch [4/150], Step [3101/5000], Loss = 0.5908\n",
      "Epoch [4/150], Step [3201/5000], Loss = 0.6837\n",
      "Epoch [4/150], Step [3301/5000], Loss = 1.2573\n",
      "Epoch [4/150], Step [3401/5000], Loss = 1.2678\n",
      "Epoch [4/150], Step [3501/5000], Loss = 0.7981\n",
      "Epoch [4/150], Step [3601/5000], Loss = 0.7928\n",
      "Epoch [4/150], Step [3701/5000], Loss = 0.4307\n",
      "Epoch [4/150], Step [3801/5000], Loss = 0.6854\n",
      "Epoch [4/150], Step [3901/5000], Loss = 1.5771\n",
      "Epoch [4/150], Step [4001/5000], Loss = 0.4243\n",
      "Epoch [4/150], Step [4101/5000], Loss = 0.3415\n",
      "Epoch [4/150], Step [4201/5000], Loss = 1.1349\n",
      "Epoch [4/150], Step [4301/5000], Loss = 1.2291\n",
      "Epoch [4/150], Step [4401/5000], Loss = 0.6964\n",
      "Epoch [4/150], Step [4501/5000], Loss = 0.7985\n",
      "Epoch [4/150], Step [4601/5000], Loss = 0.5471\n",
      "Epoch [4/150], Step [4701/5000], Loss = 0.6507\n",
      "Epoch [4/150], Step [4801/5000], Loss = 0.5245\n",
      "Epoch [4/150], Step [4901/5000], Loss = 0.5355\n",
      "Epoch [4/150], Acc = 60.0000\n",
      "Epoch [5/150], Step [1/5000], Loss = 0.4021\n",
      "Epoch [5/150], Step [101/5000], Loss = 0.9549\n",
      "Epoch [5/150], Step [201/5000], Loss = 0.8063\n",
      "Epoch [5/150], Step [301/5000], Loss = 0.2269\n",
      "Epoch [5/150], Step [401/5000], Loss = 0.6549\n",
      "Epoch [5/150], Step [501/5000], Loss = 0.8173\n",
      "Epoch [5/150], Step [601/5000], Loss = 0.5952\n",
      "Epoch [5/150], Step [701/5000], Loss = 0.8876\n",
      "Epoch [5/150], Step [801/5000], Loss = 0.4740\n",
      "Epoch [5/150], Step [901/5000], Loss = 0.8012\n",
      "Epoch [5/150], Step [1001/5000], Loss = 0.9021\n",
      "Epoch [5/150], Step [1101/5000], Loss = 0.9758\n",
      "Epoch [5/150], Step [1201/5000], Loss = 0.4032\n",
      "Epoch [5/150], Step [1301/5000], Loss = 0.6214\n",
      "Epoch [5/150], Step [1401/5000], Loss = 0.7081\n",
      "Epoch [5/150], Step [1501/5000], Loss = 0.2107\n",
      "Epoch [5/150], Step [1601/5000], Loss = 0.7201\n",
      "Epoch [5/150], Step [1701/5000], Loss = 0.2960\n",
      "Epoch [5/150], Step [1801/5000], Loss = 0.9448\n",
      "Epoch [5/150], Step [1901/5000], Loss = 0.5420\n",
      "Epoch [5/150], Step [2001/5000], Loss = 0.2921\n",
      "Epoch [5/150], Step [2101/5000], Loss = 0.4871\n",
      "Epoch [5/150], Step [2201/5000], Loss = 0.5521\n",
      "Epoch [5/150], Step [2301/5000], Loss = 0.9491\n",
      "Epoch [5/150], Step [2401/5000], Loss = 0.6147\n",
      "Epoch [5/150], Step [2501/5000], Loss = 0.6527\n",
      "Epoch [5/150], Step [2601/5000], Loss = 1.3511\n",
      "Epoch [5/150], Step [2701/5000], Loss = 1.1126\n",
      "Epoch [5/150], Step [2801/5000], Loss = 0.6348\n",
      "Epoch [5/150], Step [2901/5000], Loss = 0.5798\n",
      "Epoch [5/150], Step [3001/5000], Loss = 0.7467\n",
      "Epoch [5/150], Step [3101/5000], Loss = 0.6279\n",
      "Epoch [5/150], Step [3201/5000], Loss = 0.7356\n",
      "Epoch [5/150], Step [3301/5000], Loss = 0.7874\n",
      "Epoch [5/150], Step [3401/5000], Loss = 0.4811\n",
      "Epoch [5/150], Step [3501/5000], Loss = 1.4192\n",
      "Epoch [5/150], Step [3601/5000], Loss = 0.7697\n",
      "Epoch [5/150], Step [3701/5000], Loss = 0.5823\n",
      "Epoch [5/150], Step [3801/5000], Loss = 0.7027\n",
      "Epoch [5/150], Step [3901/5000], Loss = 0.5258\n",
      "Epoch [5/150], Step [4001/5000], Loss = 0.8252\n",
      "Epoch [5/150], Step [4101/5000], Loss = 0.9520\n",
      "Epoch [5/150], Step [4201/5000], Loss = 0.9193\n",
      "Epoch [5/150], Step [4301/5000], Loss = 0.4685\n",
      "Epoch [5/150], Step [4401/5000], Loss = 0.4449\n",
      "Epoch [5/150], Step [4501/5000], Loss = 0.6785\n",
      "Epoch [5/150], Step [4601/5000], Loss = 0.4287\n",
      "Epoch [5/150], Step [4701/5000], Loss = 0.5569\n",
      "Epoch [5/150], Step [4801/5000], Loss = 0.3843\n",
      "Epoch [5/150], Step [4901/5000], Loss = 0.3132\n",
      "Epoch [5/150], Acc = 70.0000\n",
      "Epoch [6/150], Step [1/5000], Loss = 0.6071\n",
      "Epoch [6/150], Step [101/5000], Loss = 0.3333\n",
      "Epoch [6/150], Step [201/5000], Loss = 0.7949\n",
      "Epoch [6/150], Step [301/5000], Loss = 0.2919\n",
      "Epoch [6/150], Step [401/5000], Loss = 0.4992\n",
      "Epoch [6/150], Step [501/5000], Loss = 0.6847\n",
      "Epoch [6/150], Step [601/5000], Loss = 0.3317\n",
      "Epoch [6/150], Step [701/5000], Loss = 0.6254\n",
      "Epoch [6/150], Step [801/5000], Loss = 1.1532\n",
      "Epoch [6/150], Step [901/5000], Loss = 0.8375\n",
      "Epoch [6/150], Step [1001/5000], Loss = 0.6557\n",
      "Epoch [6/150], Step [1101/5000], Loss = 1.0096\n",
      "Epoch [6/150], Step [1201/5000], Loss = 0.1652\n",
      "Epoch [6/150], Step [1301/5000], Loss = 0.4108\n",
      "Epoch [6/150], Step [1401/5000], Loss = 0.8934\n",
      "Epoch [6/150], Step [1501/5000], Loss = 0.8566\n",
      "Epoch [6/150], Step [1601/5000], Loss = 0.4043\n",
      "Epoch [6/150], Step [1701/5000], Loss = 0.9993\n",
      "Epoch [6/150], Step [1801/5000], Loss = 0.5746\n",
      "Epoch [6/150], Step [1901/5000], Loss = 0.3848\n",
      "Epoch [6/150], Step [2001/5000], Loss = 0.2887\n",
      "Epoch [6/150], Step [2101/5000], Loss = 1.0322\n",
      "Epoch [6/150], Step [2201/5000], Loss = 1.2742\n",
      "Epoch [6/150], Step [2301/5000], Loss = 0.1879\n",
      "Epoch [6/150], Step [2401/5000], Loss = 0.6320\n",
      "Epoch [6/150], Step [2501/5000], Loss = 0.7852\n",
      "Epoch [6/150], Step [2601/5000], Loss = 0.2306\n",
      "Epoch [6/150], Step [2701/5000], Loss = 0.4532\n",
      "Epoch [6/150], Step [2801/5000], Loss = 0.8695\n",
      "Epoch [6/150], Step [2901/5000], Loss = 0.2727\n",
      "Epoch [6/150], Step [3001/5000], Loss = 0.3358\n",
      "Epoch [6/150], Step [3101/5000], Loss = 0.7113\n",
      "Epoch [6/150], Step [3201/5000], Loss = 0.1274\n",
      "Epoch [6/150], Step [3301/5000], Loss = 0.8346\n",
      "Epoch [6/150], Step [3401/5000], Loss = 0.4729\n",
      "Epoch [6/150], Step [3501/5000], Loss = 0.5867\n",
      "Epoch [6/150], Step [3601/5000], Loss = 0.3795\n",
      "Epoch [6/150], Step [3701/5000], Loss = 0.5682\n",
      "Epoch [6/150], Step [3801/5000], Loss = 1.0126\n",
      "Epoch [6/150], Step [3901/5000], Loss = 0.6780\n",
      "Epoch [6/150], Step [4001/5000], Loss = 0.7205\n",
      "Epoch [6/150], Step [4101/5000], Loss = 0.8401\n",
      "Epoch [6/150], Step [4201/5000], Loss = 0.3832\n",
      "Epoch [6/150], Step [4301/5000], Loss = 1.0430\n",
      "Epoch [6/150], Step [4401/5000], Loss = 0.7655\n",
      "Epoch [6/150], Step [4501/5000], Loss = 0.7312\n",
      "Epoch [6/150], Step [4601/5000], Loss = 0.7496\n",
      "Epoch [6/150], Step [4701/5000], Loss = 0.7904\n",
      "Epoch [6/150], Step [4801/5000], Loss = 1.3350\n",
      "Epoch [6/150], Step [4901/5000], Loss = 0.5581\n",
      "Epoch [6/150], Acc = 80.0000\n",
      "Epoch [7/150], Step [1/5000], Loss = 0.2635\n",
      "Epoch [7/150], Step [101/5000], Loss = 0.6444\n",
      "Epoch [7/150], Step [201/5000], Loss = 0.4078\n",
      "Epoch [7/150], Step [301/5000], Loss = 0.6959\n",
      "Epoch [7/150], Step [401/5000], Loss = 0.4647\n",
      "Epoch [7/150], Step [501/5000], Loss = 0.1119\n",
      "Epoch [7/150], Step [601/5000], Loss = 0.2980\n",
      "Epoch [7/150], Step [701/5000], Loss = 0.8604\n",
      "Epoch [7/150], Step [801/5000], Loss = 0.4575\n",
      "Epoch [7/150], Step [901/5000], Loss = 0.3566\n",
      "Epoch [7/150], Step [1001/5000], Loss = 0.5633\n",
      "Epoch [7/150], Step [1101/5000], Loss = 0.8690\n",
      "Epoch [7/150], Step [1201/5000], Loss = 0.4174\n",
      "Epoch [7/150], Step [1301/5000], Loss = 0.4345\n",
      "Epoch [7/150], Step [1401/5000], Loss = 1.0125\n",
      "Epoch [7/150], Step [1501/5000], Loss = 0.8542\n",
      "Epoch [7/150], Step [1601/5000], Loss = 0.3945\n",
      "Epoch [7/150], Step [1701/5000], Loss = 0.4856\n",
      "Epoch [7/150], Step [1801/5000], Loss = 0.6476\n",
      "Epoch [7/150], Step [1901/5000], Loss = 0.5624\n",
      "Epoch [7/150], Step [2001/5000], Loss = 0.5652\n",
      "Epoch [7/150], Step [2101/5000], Loss = 0.4779\n",
      "Epoch [7/150], Step [2201/5000], Loss = 0.3116\n",
      "Epoch [7/150], Step [2301/5000], Loss = 0.5644\n",
      "Epoch [7/150], Step [2401/5000], Loss = 1.2006\n",
      "Epoch [7/150], Step [2501/5000], Loss = 0.9674\n",
      "Epoch [7/150], Step [2601/5000], Loss = 0.3296\n",
      "Epoch [7/150], Step [2701/5000], Loss = 0.5011\n",
      "Epoch [7/150], Step [2801/5000], Loss = 0.9627\n",
      "Epoch [7/150], Step [2901/5000], Loss = 0.6665\n",
      "Epoch [7/150], Step [3001/5000], Loss = 0.6656\n",
      "Epoch [7/150], Step [3101/5000], Loss = 0.1242\n",
      "Epoch [7/150], Step [3201/5000], Loss = 0.4079\n",
      "Epoch [7/150], Step [3301/5000], Loss = 0.8675\n",
      "Epoch [7/150], Step [3401/5000], Loss = 0.4442\n",
      "Epoch [7/150], Step [3501/5000], Loss = 0.1331\n",
      "Epoch [7/150], Step [3601/5000], Loss = 0.1391\n",
      "Epoch [7/150], Step [3701/5000], Loss = 0.5802\n",
      "Epoch [7/150], Step [3801/5000], Loss = 0.8744\n",
      "Epoch [7/150], Step [3901/5000], Loss = 0.3571\n",
      "Epoch [7/150], Step [4001/5000], Loss = 0.4740\n",
      "Epoch [7/150], Step [4101/5000], Loss = 0.5241\n",
      "Epoch [7/150], Step [4201/5000], Loss = 0.7192\n",
      "Epoch [7/150], Step [4301/5000], Loss = 0.2142\n",
      "Epoch [7/150], Step [4401/5000], Loss = 0.4248\n",
      "Epoch [7/150], Step [4501/5000], Loss = 0.8745\n",
      "Epoch [7/150], Step [4601/5000], Loss = 0.1827\n",
      "Epoch [7/150], Step [4701/5000], Loss = 0.4622\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [7/150], Step [4801/5000], Loss = 0.3396\n",
      "Epoch [7/150], Step [4901/5000], Loss = 0.4436\n",
      "Epoch [7/150], Acc = 70.0000\n",
      "Epoch [8/150], Step [1/5000], Loss = 0.3351\n",
      "Epoch [8/150], Step [101/5000], Loss = 0.4596\n",
      "Epoch [8/150], Step [201/5000], Loss = 0.5497\n",
      "Epoch [8/150], Step [301/5000], Loss = 0.2926\n",
      "Epoch [8/150], Step [401/5000], Loss = 0.3153\n",
      "Epoch [8/150], Step [501/5000], Loss = 0.4674\n",
      "Epoch [8/150], Step [601/5000], Loss = 0.3758\n",
      "Epoch [8/150], Step [701/5000], Loss = 0.3520\n",
      "Epoch [8/150], Step [801/5000], Loss = 0.2146\n",
      "Epoch [8/150], Step [901/5000], Loss = 0.2455\n",
      "Epoch [8/150], Step [1001/5000], Loss = 0.2790\n",
      "Epoch [8/150], Step [1101/5000], Loss = 0.4921\n",
      "Epoch [8/150], Step [1201/5000], Loss = 0.1399\n",
      "Epoch [8/150], Step [1301/5000], Loss = 0.2894\n",
      "Epoch [8/150], Step [1401/5000], Loss = 0.6084\n",
      "Epoch [8/150], Step [1501/5000], Loss = 0.8095\n",
      "Epoch [8/150], Step [1601/5000], Loss = 0.2862\n",
      "Epoch [8/150], Step [1701/5000], Loss = 0.7234\n",
      "Epoch [8/150], Step [1801/5000], Loss = 0.6744\n",
      "Epoch [8/150], Step [1901/5000], Loss = 0.4526\n",
      "Epoch [8/150], Step [2001/5000], Loss = 0.6073\n",
      "Epoch [8/150], Step [2101/5000], Loss = 0.3939\n",
      "Epoch [8/150], Step [2201/5000], Loss = 0.8208\n",
      "Epoch [8/150], Step [2301/5000], Loss = 0.7397\n",
      "Epoch [8/150], Step [2401/5000], Loss = 0.1344\n",
      "Epoch [8/150], Step [2501/5000], Loss = 0.2209\n",
      "Epoch [8/150], Step [2601/5000], Loss = 0.9513\n",
      "Epoch [8/150], Step [2701/5000], Loss = 0.9588\n",
      "Epoch [8/150], Step [2801/5000], Loss = 0.6852\n",
      "Epoch [8/150], Step [2901/5000], Loss = 0.4875\n",
      "Epoch [8/150], Step [3001/5000], Loss = 0.2373\n",
      "Epoch [8/150], Step [3101/5000], Loss = 0.6775\n",
      "Epoch [8/150], Step [3201/5000], Loss = 0.8514\n",
      "Epoch [8/150], Step [3301/5000], Loss = 0.1907\n",
      "Epoch [8/150], Step [3401/5000], Loss = 0.4060\n",
      "Epoch [8/150], Step [3501/5000], Loss = 0.5182\n",
      "Epoch [8/150], Step [3601/5000], Loss = 0.5503\n",
      "Epoch [8/150], Step [3701/5000], Loss = 0.5569\n",
      "Epoch [8/150], Step [3801/5000], Loss = 0.7783\n",
      "Epoch [8/150], Step [3901/5000], Loss = 0.8453\n",
      "Epoch [8/150], Step [4001/5000], Loss = 0.2571\n",
      "Epoch [8/150], Step [4101/5000], Loss = 0.6566\n",
      "Epoch [8/150], Step [4201/5000], Loss = 0.3788\n",
      "Epoch [8/150], Step [4301/5000], Loss = 0.1880\n",
      "Epoch [8/150], Step [4401/5000], Loss = 1.0674\n",
      "Epoch [8/150], Step [4501/5000], Loss = 0.9205\n",
      "Epoch [8/150], Step [4601/5000], Loss = 0.3572\n",
      "Epoch [8/150], Step [4701/5000], Loss = 0.4392\n",
      "Epoch [8/150], Step [4801/5000], Loss = 0.1069\n",
      "Epoch [8/150], Step [4901/5000], Loss = 0.2462\n",
      "Epoch [8/150], Acc = 70.0000\n",
      "Epoch [9/150], Step [1/5000], Loss = 0.2788\n",
      "Epoch [9/150], Step [101/5000], Loss = 0.6391\n",
      "Epoch [9/150], Step [201/5000], Loss = 0.2947\n",
      "Epoch [9/150], Step [301/5000], Loss = 0.3774\n",
      "Epoch [9/150], Step [401/5000], Loss = 0.2438\n",
      "Epoch [9/150], Step [501/5000], Loss = 0.1761\n",
      "Epoch [9/150], Step [601/5000], Loss = 0.3778\n",
      "Epoch [9/150], Step [701/5000], Loss = 0.1587\n",
      "Epoch [9/150], Step [801/5000], Loss = 0.2070\n",
      "Epoch [9/150], Step [901/5000], Loss = 0.5505\n",
      "Epoch [9/150], Step [1001/5000], Loss = 0.2809\n",
      "Epoch [9/150], Step [1101/5000], Loss = 0.5862\n",
      "Epoch [9/150], Step [1201/5000], Loss = 0.1769\n",
      "Epoch [9/150], Step [1301/5000], Loss = 0.3651\n",
      "Epoch [9/150], Step [1401/5000], Loss = 0.3273\n",
      "Epoch [9/150], Step [1501/5000], Loss = 0.4613\n",
      "Epoch [9/150], Step [1601/5000], Loss = 0.2045\n",
      "Epoch [9/150], Step [1701/5000], Loss = 0.4632\n",
      "Epoch [9/150], Step [1801/5000], Loss = 0.3266\n",
      "Epoch [9/150], Step [1901/5000], Loss = 0.5113\n",
      "Epoch [9/150], Step [2001/5000], Loss = 0.4456\n",
      "Epoch [9/150], Step [2101/5000], Loss = 0.5592\n",
      "Epoch [9/150], Step [2201/5000], Loss = 0.2068\n",
      "Epoch [9/150], Step [2301/5000], Loss = 0.4106\n",
      "Epoch [9/150], Step [2401/5000], Loss = 0.7441\n",
      "Epoch [9/150], Step [2501/5000], Loss = 0.3390\n",
      "Epoch [9/150], Step [2601/5000], Loss = 0.8753\n",
      "Epoch [9/150], Step [2701/5000], Loss = 0.4585\n",
      "Epoch [9/150], Step [2801/5000], Loss = 0.2055\n",
      "Epoch [9/150], Step [2901/5000], Loss = 0.8024\n",
      "Epoch [9/150], Step [3001/5000], Loss = 0.5560\n",
      "Epoch [9/150], Step [3101/5000], Loss = 0.7475\n",
      "Epoch [9/150], Step [3201/5000], Loss = 0.1203\n",
      "Epoch [9/150], Step [3301/5000], Loss = 0.4535\n",
      "Epoch [9/150], Step [3401/5000], Loss = 0.6457\n",
      "Epoch [9/150], Step [3501/5000], Loss = 0.0630\n",
      "Epoch [9/150], Step [3601/5000], Loss = 0.6153\n",
      "Epoch [9/150], Step [3701/5000], Loss = 0.0752\n",
      "Epoch [9/150], Step [3801/5000], Loss = 0.2482\n",
      "Epoch [9/150], Step [3901/5000], Loss = 0.6877\n",
      "Epoch [9/150], Step [4001/5000], Loss = 0.1540\n",
      "Epoch [9/150], Step [4101/5000], Loss = 0.2801\n",
      "Epoch [9/150], Step [4201/5000], Loss = 0.8851\n",
      "Epoch [9/150], Step [4301/5000], Loss = 0.2229\n",
      "Epoch [9/150], Step [4401/5000], Loss = 0.3964\n",
      "Epoch [9/150], Step [4501/5000], Loss = 0.4074\n",
      "Epoch [9/150], Step [4601/5000], Loss = 0.5151\n",
      "Epoch [9/150], Step [4701/5000], Loss = 0.9763\n",
      "Epoch [9/150], Step [4801/5000], Loss = 0.3425\n",
      "Epoch [9/150], Step [4901/5000], Loss = 0.5508\n",
      "Epoch [9/150], Acc = 70.0000\n",
      "Epoch [10/150], Step [1/5000], Loss = 0.2570\n",
      "Epoch [10/150], Step [101/5000], Loss = 0.0607\n",
      "Epoch [10/150], Step [201/5000], Loss = 0.6766\n",
      "Epoch [10/150], Step [301/5000], Loss = 0.1672\n",
      "Epoch [10/150], Step [401/5000], Loss = 0.2241\n",
      "Epoch [10/150], Step [501/5000], Loss = 0.8482\n",
      "Epoch [10/150], Step [601/5000], Loss = 0.4076\n",
      "Epoch [10/150], Step [701/5000], Loss = 0.4985\n",
      "Epoch [10/150], Step [801/5000], Loss = 0.0815\n",
      "Epoch [10/150], Step [901/5000], Loss = 0.5503\n",
      "Epoch [10/150], Step [1001/5000], Loss = 0.2513\n",
      "Epoch [10/150], Step [1101/5000], Loss = 0.2293\n",
      "Epoch [10/150], Step [1201/5000], Loss = 0.1428\n",
      "Epoch [10/150], Step [1301/5000], Loss = 0.1496\n",
      "Epoch [10/150], Step [1401/5000], Loss = 1.0016\n",
      "Epoch [10/150], Step [1501/5000], Loss = 0.6792\n",
      "Epoch [10/150], Step [1601/5000], Loss = 0.5668\n",
      "Epoch [10/150], Step [1701/5000], Loss = 0.3400\n",
      "Epoch [10/150], Step [1801/5000], Loss = 1.1992\n",
      "Epoch [10/150], Step [1901/5000], Loss = 0.5141\n",
      "Epoch [10/150], Step [2001/5000], Loss = 0.5525\n",
      "Epoch [10/150], Step [2101/5000], Loss = 0.6101\n",
      "Epoch [10/150], Step [2201/5000], Loss = 0.5962\n",
      "Epoch [10/150], Step [2301/5000], Loss = 0.6004\n",
      "Epoch [10/150], Step [2401/5000], Loss = 0.1918\n",
      "Epoch [10/150], Step [2501/5000], Loss = 0.5177\n",
      "Epoch [10/150], Step [2601/5000], Loss = 0.3153\n",
      "Epoch [10/150], Step [2701/5000], Loss = 0.7026\n",
      "Epoch [10/150], Step [2801/5000], Loss = 0.0470\n",
      "Epoch [10/150], Step [2901/5000], Loss = 0.3298\n",
      "Epoch [10/150], Step [3001/5000], Loss = 0.5533\n",
      "Epoch [10/150], Step [3101/5000], Loss = 0.3022\n",
      "Epoch [10/150], Step [3201/5000], Loss = 0.3028\n",
      "Epoch [10/150], Step [3301/5000], Loss = 0.3116\n",
      "Epoch [10/150], Step [3401/5000], Loss = 0.3161\n",
      "Epoch [10/150], Step [3501/5000], Loss = 0.9141\n",
      "Epoch [10/150], Step [3601/5000], Loss = 0.4948\n",
      "Epoch [10/150], Step [3701/5000], Loss = 0.2114\n",
      "Epoch [10/150], Step [3801/5000], Loss = 0.8139\n",
      "Epoch [10/150], Step [3901/5000], Loss = 0.6277\n",
      "Epoch [10/150], Step [4001/5000], Loss = 0.1827\n",
      "Epoch [10/150], Step [4101/5000], Loss = 0.3254\n",
      "Epoch [10/150], Step [4201/5000], Loss = 0.2971\n",
      "Epoch [10/150], Step [4301/5000], Loss = 0.2319\n",
      "Epoch [10/150], Step [4401/5000], Loss = 0.3048\n",
      "Epoch [10/150], Step [4501/5000], Loss = 0.3658\n",
      "Epoch [10/150], Step [4601/5000], Loss = 0.0477\n",
      "Epoch [10/150], Step [4701/5000], Loss = 0.3279\n",
      "Epoch [10/150], Step [4801/5000], Loss = 0.5012\n",
      "Epoch [10/150], Step [4901/5000], Loss = 0.8303\n",
      "Epoch [10/150], Acc = 80.0000\n",
      "Epoch [11/150], Step [1/5000], Loss = 0.0801\n",
      "Epoch [11/150], Step [101/5000], Loss = 0.2936\n",
      "Epoch [11/150], Step [201/5000], Loss = 0.7982\n",
      "Epoch [11/150], Step [301/5000], Loss = 0.0600\n",
      "Epoch [11/150], Step [401/5000], Loss = 0.2722\n",
      "Epoch [11/150], Step [501/5000], Loss = 0.1776\n",
      "Epoch [11/150], Step [601/5000], Loss = 0.3510\n",
      "Epoch [11/150], Step [701/5000], Loss = 0.3424\n",
      "Epoch [11/150], Step [801/5000], Loss = 0.4048\n",
      "Epoch [11/150], Step [901/5000], Loss = 0.5523\n",
      "Epoch [11/150], Step [1001/5000], Loss = 0.0901\n",
      "Epoch [11/150], Step [1101/5000], Loss = 0.2946\n",
      "Epoch [11/150], Step [1201/5000], Loss = 0.1825\n",
      "Epoch [11/150], Step [1301/5000], Loss = 0.1768\n",
      "Epoch [11/150], Step [1401/5000], Loss = 0.4576\n",
      "Epoch [11/150], Step [1501/5000], Loss = 0.2641\n",
      "Epoch [11/150], Step [1601/5000], Loss = 0.6921\n",
      "Epoch [11/150], Step [1701/5000], Loss = 0.2069\n",
      "Epoch [11/150], Step [1801/5000], Loss = 0.5335\n",
      "Epoch [11/150], Step [1901/5000], Loss = 0.1079\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [11/150], Step [2001/5000], Loss = 0.2297\n",
      "Epoch [11/150], Step [2101/5000], Loss = 0.2077\n",
      "Epoch [11/150], Step [2201/5000], Loss = 0.2226\n",
      "Epoch [11/150], Step [2301/5000], Loss = 0.0409\n",
      "Epoch [11/150], Step [2401/5000], Loss = 0.3865\n",
      "Epoch [11/150], Step [2501/5000], Loss = 0.4849\n",
      "Epoch [11/150], Step [2601/5000], Loss = 0.1403\n",
      "Epoch [11/150], Step [2701/5000], Loss = 0.1898\n",
      "Epoch [11/150], Step [2801/5000], Loss = 0.1653\n",
      "Epoch [11/150], Step [2901/5000], Loss = 0.1103\n",
      "Epoch [11/150], Step [3001/5000], Loss = 0.6431\n",
      "Epoch [11/150], Step [3101/5000], Loss = 0.3356\n",
      "Epoch [11/150], Step [3201/5000], Loss = 0.7917\n",
      "Epoch [11/150], Step [3301/5000], Loss = 0.0425\n",
      "Epoch [11/150], Step [3401/5000], Loss = 0.3765\n",
      "Epoch [11/150], Step [3501/5000], Loss = 0.0068\n",
      "Epoch [11/150], Step [3601/5000], Loss = 0.3831\n",
      "Epoch [11/150], Step [3701/5000], Loss = 0.1550\n",
      "Epoch [11/150], Step [3801/5000], Loss = 0.6547\n",
      "Epoch [11/150], Step [3901/5000], Loss = 0.3512\n",
      "Epoch [11/150], Step [4001/5000], Loss = 0.4980\n",
      "Epoch [11/150], Step [4101/5000], Loss = 0.1695\n",
      "Epoch [11/150], Step [4201/5000], Loss = 0.5211\n",
      "Epoch [11/150], Step [4301/5000], Loss = 0.2110\n",
      "Epoch [11/150], Step [4401/5000], Loss = 1.2484\n",
      "Epoch [11/150], Step [4501/5000], Loss = 0.3755\n",
      "Epoch [11/150], Step [4601/5000], Loss = 0.6744\n",
      "Epoch [11/150], Step [4701/5000], Loss = 0.3457\n",
      "Epoch [11/150], Step [4801/5000], Loss = 0.6437\n",
      "Epoch [11/150], Step [4901/5000], Loss = 0.6035\n",
      "Epoch [11/150], Acc = 70.0000\n",
      "Epoch [12/150], Step [1/5000], Loss = 0.4001\n",
      "Epoch [12/150], Step [101/5000], Loss = 0.1666\n",
      "Epoch [12/150], Step [201/5000], Loss = 0.1014\n",
      "Epoch [12/150], Step [301/5000], Loss = 0.7489\n",
      "Epoch [12/150], Step [401/5000], Loss = 0.2730\n",
      "Epoch [12/150], Step [501/5000], Loss = 0.2460\n",
      "Epoch [12/150], Step [601/5000], Loss = 0.1665\n",
      "Epoch [12/150], Step [701/5000], Loss = 0.0988\n",
      "Epoch [12/150], Step [801/5000], Loss = 0.0478\n",
      "Epoch [12/150], Step [901/5000], Loss = 0.0158\n",
      "Epoch [12/150], Step [1001/5000], Loss = 0.2946\n",
      "Epoch [12/150], Step [1101/5000], Loss = 0.1636\n",
      "Epoch [12/150], Step [1201/5000], Loss = 0.1720\n",
      "Epoch [12/150], Step [1301/5000], Loss = 0.4849\n",
      "Epoch [12/150], Step [1401/5000], Loss = 0.3091\n",
      "Epoch [12/150], Step [1501/5000], Loss = 0.4273\n",
      "Epoch [12/150], Step [1601/5000], Loss = 0.2886\n",
      "Epoch [12/150], Step [1701/5000], Loss = 0.3551\n",
      "Epoch [12/150], Step [1801/5000], Loss = 0.3929\n",
      "Epoch [12/150], Step [1901/5000], Loss = 0.0338\n",
      "Epoch [12/150], Step [2001/5000], Loss = 0.2214\n",
      "Epoch [12/150], Step [2101/5000], Loss = 0.3305\n",
      "Epoch [12/150], Step [2201/5000], Loss = 0.3098\n",
      "Epoch [12/150], Step [2301/5000], Loss = 0.1839\n",
      "Epoch [12/150], Step [2401/5000], Loss = 0.1096\n",
      "Epoch [12/150], Step [2501/5000], Loss = 0.2075\n",
      "Epoch [12/150], Step [2601/5000], Loss = 1.1136\n",
      "Epoch [12/150], Step [2701/5000], Loss = 0.4701\n",
      "Epoch [12/150], Step [2801/5000], Loss = 0.3027\n",
      "Epoch [12/150], Step [2901/5000], Loss = 0.0931\n",
      "Epoch [12/150], Step [3001/5000], Loss = 0.3381\n",
      "Epoch [12/150], Step [3101/5000], Loss = 0.1265\n",
      "Epoch [12/150], Step [3201/5000], Loss = 0.1428\n",
      "Epoch [12/150], Step [3301/5000], Loss = 0.0367\n",
      "Epoch [12/150], Step [3401/5000], Loss = 0.2346\n",
      "Epoch [12/150], Step [3501/5000], Loss = 0.3423\n",
      "Epoch [12/150], Step [3601/5000], Loss = 0.1915\n",
      "Epoch [12/150], Step [3701/5000], Loss = 0.4776\n",
      "Epoch [12/150], Step [3801/5000], Loss = 0.2601\n",
      "Epoch [12/150], Step [3901/5000], Loss = 0.0229\n",
      "Epoch [12/150], Step [4001/5000], Loss = 0.4254\n",
      "Epoch [12/150], Step [4101/5000], Loss = 0.3102\n",
      "Epoch [12/150], Step [4201/5000], Loss = 0.1996\n",
      "Epoch [12/150], Step [4301/5000], Loss = 0.7943\n",
      "Epoch [12/150], Step [4401/5000], Loss = 0.0944\n",
      "Epoch [12/150], Step [4501/5000], Loss = 0.4905\n",
      "Epoch [12/150], Step [4601/5000], Loss = 1.3374\n",
      "Epoch [12/150], Step [4701/5000], Loss = 0.4294\n",
      "Epoch [12/150], Step [4801/5000], Loss = 1.2138\n",
      "Epoch [12/150], Step [4901/5000], Loss = 0.2890\n",
      "Epoch [12/150], Acc = 60.0000\n",
      "Epoch [13/150], Step [1/5000], Loss = 0.1904\n",
      "Epoch [13/150], Step [101/5000], Loss = 0.6384\n",
      "Epoch [13/150], Step [201/5000], Loss = 0.7085\n",
      "Epoch [13/150], Step [301/5000], Loss = 0.1005\n",
      "Epoch [13/150], Step [401/5000], Loss = 0.1443\n",
      "Epoch [13/150], Step [501/5000], Loss = 0.3299\n",
      "Epoch [13/150], Step [601/5000], Loss = 0.1579\n",
      "Epoch [13/150], Step [701/5000], Loss = 0.3252\n",
      "Epoch [13/150], Step [801/5000], Loss = 0.0493\n",
      "Epoch [13/150], Step [901/5000], Loss = 0.0911\n",
      "Epoch [13/150], Step [1001/5000], Loss = 0.3871\n",
      "Epoch [13/150], Step [1101/5000], Loss = 0.0080\n",
      "Epoch [13/150], Step [1201/5000], Loss = 0.3069\n",
      "Epoch [13/150], Step [1301/5000], Loss = 0.0200\n",
      "Epoch [13/150], Step [1401/5000], Loss = 0.4846\n",
      "Epoch [13/150], Step [1501/5000], Loss = 0.5025\n",
      "Epoch [13/150], Step [1601/5000], Loss = 0.0362\n",
      "Epoch [13/150], Step [1701/5000], Loss = 0.2667\n",
      "Epoch [13/150], Step [1801/5000], Loss = 0.6065\n",
      "Epoch [13/150], Step [1901/5000], Loss = 0.2557\n",
      "Epoch [13/150], Step [2001/5000], Loss = 0.7825\n",
      "Epoch [13/150], Step [2101/5000], Loss = 0.3368\n",
      "Epoch [13/150], Step [2201/5000], Loss = 0.8299\n",
      "Epoch [13/150], Step [2301/5000], Loss = 0.2735\n",
      "Epoch [13/150], Step [2401/5000], Loss = 0.1425\n",
      "Epoch [13/150], Step [2501/5000], Loss = 0.2151\n",
      "Epoch [13/150], Step [2601/5000], Loss = 0.0661\n",
      "Epoch [13/150], Step [2701/5000], Loss = 0.6064\n",
      "Epoch [13/150], Step [2801/5000], Loss = 0.0922\n",
      "Epoch [13/150], Step [2901/5000], Loss = 0.4545\n",
      "Epoch [13/150], Step [3001/5000], Loss = 0.1796\n",
      "Epoch [13/150], Step [3101/5000], Loss = 0.3700\n",
      "Epoch [13/150], Step [3201/5000], Loss = 0.3508\n",
      "Epoch [13/150], Step [3301/5000], Loss = 0.8143\n",
      "Epoch [13/150], Step [3401/5000], Loss = 0.1885\n",
      "Epoch [13/150], Step [3501/5000], Loss = 0.2836\n",
      "Epoch [13/150], Step [3601/5000], Loss = 0.4121\n",
      "Epoch [13/150], Step [3701/5000], Loss = 0.1978\n",
      "Epoch [13/150], Step [3801/5000], Loss = 0.1033\n",
      "Epoch [13/150], Step [3901/5000], Loss = 0.1480\n",
      "Epoch [13/150], Step [4001/5000], Loss = 0.2204\n",
      "Epoch [13/150], Step [4101/5000], Loss = 0.3250\n",
      "Epoch [13/150], Step [4201/5000], Loss = 1.4770\n",
      "Epoch [13/150], Step [4301/5000], Loss = 0.1205\n",
      "Epoch [13/150], Step [4401/5000], Loss = 0.2329\n",
      "Epoch [13/150], Step [4501/5000], Loss = 0.0747\n",
      "Epoch [13/150], Step [4601/5000], Loss = 0.2747\n",
      "Epoch [13/150], Step [4701/5000], Loss = 0.2814\n",
      "Epoch [13/150], Step [4801/5000], Loss = 0.2207\n",
      "Epoch [13/150], Step [4901/5000], Loss = 0.9497\n",
      "Epoch [13/150], Acc = 50.0000\n",
      "Epoch [14/150], Step [1/5000], Loss = 0.2284\n",
      "Epoch [14/150], Step [101/5000], Loss = 0.6060\n",
      "Epoch [14/150], Step [201/5000], Loss = 0.1327\n",
      "Epoch [14/150], Step [301/5000], Loss = 0.4230\n",
      "Epoch [14/150], Step [401/5000], Loss = 0.0638\n",
      "Epoch [14/150], Step [501/5000], Loss = 0.1087\n",
      "Epoch [14/150], Step [601/5000], Loss = 0.0152\n",
      "Epoch [14/150], Step [701/5000], Loss = 0.2063\n",
      "Epoch [14/150], Step [801/5000], Loss = 0.2660\n",
      "Epoch [14/150], Step [901/5000], Loss = 0.1996\n",
      "Epoch [14/150], Step [1001/5000], Loss = 0.3254\n",
      "Epoch [14/150], Step [1101/5000], Loss = 0.1291\n",
      "Epoch [14/150], Step [1201/5000], Loss = 0.4146\n",
      "Epoch [14/150], Step [1301/5000], Loss = 0.1232\n",
      "Epoch [14/150], Step [1401/5000], Loss = 0.1440\n",
      "Epoch [14/150], Step [1501/5000], Loss = 0.3225\n",
      "Epoch [14/150], Step [1601/5000], Loss = 0.2755\n",
      "Epoch [14/150], Step [1701/5000], Loss = 0.4131\n",
      "Epoch [14/150], Step [1801/5000], Loss = 0.0677\n",
      "Epoch [14/150], Step [1901/5000], Loss = 0.0865\n",
      "Epoch [14/150], Step [2001/5000], Loss = 0.0526\n",
      "Epoch [14/150], Step [2101/5000], Loss = 0.6897\n",
      "Epoch [14/150], Step [2201/5000], Loss = 0.0229\n",
      "Epoch [14/150], Step [2301/5000], Loss = 0.3503\n",
      "Epoch [14/150], Step [2401/5000], Loss = 0.4946\n",
      "Epoch [14/150], Step [2501/5000], Loss = 0.0575\n",
      "Epoch [14/150], Step [2601/5000], Loss = 0.1796\n",
      "Epoch [14/150], Step [2701/5000], Loss = 0.2606\n",
      "Epoch [14/150], Step [2801/5000], Loss = 0.0990\n",
      "Epoch [14/150], Step [2901/5000], Loss = 0.1430\n",
      "Epoch [14/150], Step [3001/5000], Loss = 0.1264\n",
      "Epoch [14/150], Step [3101/5000], Loss = 0.0110\n",
      "Epoch [14/150], Step [3201/5000], Loss = 0.3154\n",
      "Epoch [14/150], Step [3301/5000], Loss = 0.2153\n",
      "Epoch [14/150], Step [3401/5000], Loss = 0.5886\n",
      "Epoch [14/150], Step [3501/5000], Loss = 0.0845\n",
      "Epoch [14/150], Step [3601/5000], Loss = 0.4054\n",
      "Epoch [14/150], Step [3701/5000], Loss = 0.1466\n",
      "Epoch [14/150], Step [3801/5000], Loss = 0.2524\n",
      "Epoch [14/150], Step [3901/5000], Loss = 0.3188\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [14/150], Step [4001/5000], Loss = 0.5348\n",
      "Epoch [14/150], Step [4101/5000], Loss = 0.1145\n",
      "Epoch [14/150], Step [4201/5000], Loss = 0.1189\n",
      "Epoch [14/150], Step [4301/5000], Loss = 0.0440\n",
      "Epoch [14/150], Step [4401/5000], Loss = 0.0502\n",
      "Epoch [14/150], Step [4501/5000], Loss = 0.1077\n",
      "Epoch [14/150], Step [4601/5000], Loss = 0.2574\n",
      "Epoch [14/150], Step [4701/5000], Loss = 0.0408\n",
      "Epoch [14/150], Step [4801/5000], Loss = 0.5160\n",
      "Epoch [14/150], Step [4901/5000], Loss = 0.6352\n",
      "Epoch [14/150], Acc = 50.0000\n",
      "Epoch [15/150], Step [1/5000], Loss = 0.2026\n",
      "Epoch [15/150], Step [101/5000], Loss = 0.2444\n",
      "Epoch [15/150], Step [201/5000], Loss = 0.0930\n",
      "Epoch [15/150], Step [301/5000], Loss = 0.0731\n",
      "Epoch [15/150], Step [401/5000], Loss = 0.2111\n",
      "Epoch [15/150], Step [501/5000], Loss = 0.0167\n",
      "Epoch [15/150], Step [601/5000], Loss = 0.1211\n",
      "Epoch [15/150], Step [701/5000], Loss = 0.1651\n",
      "Epoch [15/150], Step [801/5000], Loss = 0.0135\n",
      "Epoch [15/150], Step [901/5000], Loss = 0.0906\n",
      "Epoch [15/150], Step [1001/5000], Loss = 0.0418\n",
      "Epoch [15/150], Step [1101/5000], Loss = 0.0880\n",
      "Epoch [15/150], Step [1201/5000], Loss = 0.2160\n",
      "Epoch [15/150], Step [1301/5000], Loss = 0.0921\n",
      "Epoch [15/150], Step [1401/5000], Loss = 0.1880\n",
      "Epoch [15/150], Step [1501/5000], Loss = 0.1253\n",
      "Epoch [15/150], Step [1601/5000], Loss = 0.0820\n",
      "Epoch [15/150], Step [1701/5000], Loss = 0.0110\n",
      "Epoch [15/150], Step [1801/5000], Loss = 0.1570\n",
      "Epoch [15/150], Step [1901/5000], Loss = 0.6521\n",
      "Epoch [15/150], Step [2001/5000], Loss = 0.8003\n",
      "Epoch [15/150], Step [2101/5000], Loss = 0.5516\n",
      "Epoch [15/150], Step [2201/5000], Loss = 0.4524\n",
      "Epoch [15/150], Step [2301/5000], Loss = 0.0745\n",
      "Epoch [15/150], Step [2401/5000], Loss = 0.2558\n",
      "Epoch [15/150], Step [2501/5000], Loss = 0.1013\n",
      "Epoch [15/150], Step [2601/5000], Loss = 0.0383\n",
      "Epoch [15/150], Step [2701/5000], Loss = 0.1234\n",
      "Epoch [15/150], Step [2801/5000], Loss = 0.0972\n",
      "Epoch [15/150], Step [2901/5000], Loss = 0.2718\n",
      "Epoch [15/150], Step [3001/5000], Loss = 0.4150\n",
      "Epoch [15/150], Step [3101/5000], Loss = 0.4613\n",
      "Epoch [15/150], Step [3201/5000], Loss = 0.0135\n",
      "Epoch [15/150], Step [3301/5000], Loss = 0.0244\n",
      "Epoch [15/150], Step [3401/5000], Loss = 0.3148\n",
      "Epoch [15/150], Step [3501/5000], Loss = 0.0324\n",
      "Epoch [15/150], Step [3601/5000], Loss = 0.4227\n",
      "Epoch [15/150], Step [3701/5000], Loss = 0.0947\n",
      "Epoch [15/150], Step [3801/5000], Loss = 0.0820\n",
      "Epoch [15/150], Step [3901/5000], Loss = 0.5187\n",
      "Epoch [15/150], Step [4001/5000], Loss = 0.1172\n",
      "Epoch [15/150], Step [4101/5000], Loss = 0.1741\n",
      "Epoch [15/150], Step [4201/5000], Loss = 0.0333\n",
      "Epoch [15/150], Step [4301/5000], Loss = 0.3153\n",
      "Epoch [15/150], Step [4401/5000], Loss = 0.0189\n",
      "Epoch [15/150], Step [4501/5000], Loss = 0.1519\n",
      "Epoch [15/150], Step [4601/5000], Loss = 0.0564\n",
      "Epoch [15/150], Step [4701/5000], Loss = 0.0450\n",
      "Epoch [15/150], Step [4801/5000], Loss = 0.0866\n",
      "Epoch [15/150], Step [4901/5000], Loss = 0.5340\n",
      "Epoch [15/150], Acc = 70.0000\n",
      "Epoch [16/150], Step [1/5000], Loss = 0.1284\n",
      "Epoch [16/150], Step [101/5000], Loss = 0.0577\n",
      "Epoch [16/150], Step [201/5000], Loss = 0.0540\n",
      "Epoch [16/150], Step [301/5000], Loss = 0.1783\n",
      "Epoch [16/150], Step [401/5000], Loss = 0.1929\n",
      "Epoch [16/150], Step [501/5000], Loss = 0.0564\n",
      "Epoch [16/150], Step [601/5000], Loss = 0.0300\n",
      "Epoch [16/150], Step [701/5000], Loss = 0.1857\n",
      "Epoch [16/150], Step [801/5000], Loss = 0.2279\n",
      "Epoch [16/150], Step [901/5000], Loss = 0.1085\n",
      "Epoch [16/150], Step [1001/5000], Loss = 0.4045\n",
      "Epoch [16/150], Step [1101/5000], Loss = 0.4790\n",
      "Epoch [16/150], Step [1201/5000], Loss = 0.2071\n",
      "Epoch [16/150], Step [1301/5000], Loss = 0.3485\n",
      "Epoch [16/150], Step [1401/5000], Loss = 0.4493\n",
      "Epoch [16/150], Step [1501/5000], Loss = 0.0552\n",
      "Epoch [16/150], Step [1601/5000], Loss = 0.3155\n",
      "Epoch [16/150], Step [1701/5000], Loss = 0.1038\n",
      "Epoch [16/150], Step [1801/5000], Loss = 0.3003\n",
      "Epoch [16/150], Step [1901/5000], Loss = 0.4185\n",
      "Epoch [16/150], Step [2001/5000], Loss = 0.2154\n",
      "Epoch [16/150], Step [2101/5000], Loss = 0.2482\n",
      "Epoch [16/150], Step [2201/5000], Loss = 0.4741\n",
      "Epoch [16/150], Step [2301/5000], Loss = 0.0051\n",
      "Epoch [16/150], Step [2401/5000], Loss = 0.2221\n",
      "Epoch [16/150], Step [2501/5000], Loss = 0.0689\n",
      "Epoch [16/150], Step [2601/5000], Loss = 0.1852\n",
      "Epoch [16/150], Step [2701/5000], Loss = 0.1337\n",
      "Epoch [16/150], Step [2801/5000], Loss = 0.1038\n",
      "Epoch [16/150], Step [2901/5000], Loss = 0.1444\n",
      "Epoch [16/150], Step [3001/5000], Loss = 0.0913\n",
      "Epoch [16/150], Step [3101/5000], Loss = 0.0329\n",
      "Epoch [16/150], Step [3201/5000], Loss = 0.1581\n",
      "Epoch [16/150], Step [3301/5000], Loss = 0.1870\n",
      "Epoch [16/150], Step [3401/5000], Loss = 0.0981\n",
      "Epoch [16/150], Step [3501/5000], Loss = 0.0496\n",
      "Epoch [16/150], Step [3601/5000], Loss = 0.0785\n",
      "Epoch [16/150], Step [3701/5000], Loss = 0.4790\n",
      "Epoch [16/150], Step [3801/5000], Loss = 0.2521\n",
      "Epoch [16/150], Step [3901/5000], Loss = 0.1541\n",
      "Epoch [16/150], Step [4001/5000], Loss = 0.2297\n",
      "Epoch [16/150], Step [4101/5000], Loss = 0.2070\n",
      "Epoch [16/150], Step [4201/5000], Loss = 0.0713\n",
      "Epoch [16/150], Step [4301/5000], Loss = 0.0040\n",
      "Epoch [16/150], Step [4401/5000], Loss = 0.0954\n",
      "Epoch [16/150], Step [4501/5000], Loss = 0.1355\n",
      "Epoch [16/150], Step [4601/5000], Loss = 0.1026\n",
      "Epoch [16/150], Step [4701/5000], Loss = 0.0271\n",
      "Epoch [16/150], Step [4801/5000], Loss = 0.1612\n",
      "Epoch [16/150], Step [4901/5000], Loss = 0.1833\n",
      "Epoch [16/150], Acc = 70.0000\n",
      "Epoch [17/150], Step [1/5000], Loss = 0.1124\n",
      "Epoch [17/150], Step [101/5000], Loss = 0.0774\n",
      "Epoch [17/150], Step [201/5000], Loss = 0.1777\n",
      "Epoch [17/150], Step [301/5000], Loss = 0.0808\n",
      "Epoch [17/150], Step [401/5000], Loss = 0.2952\n",
      "Epoch [17/150], Step [501/5000], Loss = 0.3772\n",
      "Epoch [17/150], Step [601/5000], Loss = 0.3065\n",
      "Epoch [17/150], Step [701/5000], Loss = 0.0986\n",
      "Epoch [17/150], Step [801/5000], Loss = 0.0159\n",
      "Epoch [17/150], Step [901/5000], Loss = 0.1948\n",
      "Epoch [17/150], Step [1001/5000], Loss = 0.0879\n",
      "Epoch [17/150], Step [1101/5000], Loss = 0.0152\n",
      "Epoch [17/150], Step [1201/5000], Loss = 0.1058\n",
      "Epoch [17/150], Step [1301/5000], Loss = 0.0697\n",
      "Epoch [17/150], Step [1401/5000], Loss = 0.0517\n",
      "Epoch [17/150], Step [1501/5000], Loss = 0.2677\n",
      "Epoch [17/150], Step [1601/5000], Loss = 0.0607\n",
      "Epoch [17/150], Step [1701/5000], Loss = 0.1777\n",
      "Epoch [17/150], Step [1801/5000], Loss = 0.2160\n",
      "Epoch [17/150], Step [1901/5000], Loss = 0.0039\n",
      "Epoch [17/150], Step [2001/5000], Loss = 0.1310\n",
      "Epoch [17/150], Step [2101/5000], Loss = 0.0207\n",
      "Epoch [17/150], Step [2201/5000], Loss = 0.0221\n",
      "Epoch [17/150], Step [2301/5000], Loss = 0.2967\n",
      "Epoch [17/150], Step [2401/5000], Loss = 0.1092\n",
      "Epoch [17/150], Step [2501/5000], Loss = 0.0719\n",
      "Epoch [17/150], Step [2601/5000], Loss = 0.0618\n",
      "Epoch [17/150], Step [2701/5000], Loss = 0.1026\n",
      "Epoch [17/150], Step [2801/5000], Loss = 0.3003\n",
      "Epoch [17/150], Step [2901/5000], Loss = 0.0140\n",
      "Epoch [17/150], Step [3001/5000], Loss = 0.0439\n",
      "Epoch [17/150], Step [3101/5000], Loss = 0.0561\n",
      "Epoch [17/150], Step [3201/5000], Loss = 0.0909\n",
      "Epoch [17/150], Step [3301/5000], Loss = 0.0376\n",
      "Epoch [17/150], Step [3401/5000], Loss = 0.3153\n",
      "Epoch [17/150], Step [3501/5000], Loss = 0.0636\n",
      "Epoch [17/150], Step [3601/5000], Loss = 0.2145\n",
      "Epoch [17/150], Step [3701/5000], Loss = 0.3267\n",
      "Epoch [17/150], Step [3801/5000], Loss = 0.1351\n",
      "Epoch [17/150], Step [3901/5000], Loss = 0.1744\n",
      "Epoch [17/150], Step [4001/5000], Loss = 0.1030\n",
      "Epoch [17/150], Step [4101/5000], Loss = 0.0199\n",
      "Epoch [17/150], Step [4201/5000], Loss = 0.2168\n",
      "Epoch [17/150], Step [4301/5000], Loss = 0.7252\n",
      "Epoch [17/150], Step [4401/5000], Loss = 0.6998\n",
      "Epoch [17/150], Step [4501/5000], Loss = 0.1918\n",
      "Epoch [17/150], Step [4601/5000], Loss = 0.1973\n",
      "Epoch [17/150], Step [4701/5000], Loss = 0.4221\n",
      "Epoch [17/150], Step [4801/5000], Loss = 0.1562\n",
      "Epoch [17/150], Step [4901/5000], Loss = 0.0069\n",
      "Epoch [17/150], Acc = 70.0000\n",
      "Epoch [18/150], Step [1/5000], Loss = 0.2029\n",
      "Epoch [18/150], Step [101/5000], Loss = 0.0539\n",
      "Epoch [18/150], Step [201/5000], Loss = 0.0786\n",
      "Epoch [18/150], Step [301/5000], Loss = 0.1073\n",
      "Epoch [18/150], Step [401/5000], Loss = 0.2304\n",
      "Epoch [18/150], Step [501/5000], Loss = 0.4028\n",
      "Epoch [18/150], Step [601/5000], Loss = 0.1189\n",
      "Epoch [18/150], Step [701/5000], Loss = 0.2360\n",
      "Epoch [18/150], Step [801/5000], Loss = 0.0255\n",
      "Epoch [18/150], Step [901/5000], Loss = 0.0780\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [18/150], Step [1001/5000], Loss = 0.0093\n",
      "Epoch [18/150], Step [1101/5000], Loss = 0.1543\n",
      "Epoch [18/150], Step [1201/5000], Loss = 0.2673\n",
      "Epoch [18/150], Step [1301/5000], Loss = 0.2011\n",
      "Epoch [18/150], Step [1401/5000], Loss = 0.1680\n",
      "Epoch [18/150], Step [1501/5000], Loss = 0.2071\n",
      "Epoch [18/150], Step [1601/5000], Loss = 0.2157\n",
      "Epoch [18/150], Step [1701/5000], Loss = 0.0053\n",
      "Epoch [18/150], Step [1801/5000], Loss = 0.0838\n",
      "Epoch [18/150], Step [1901/5000], Loss = 0.1903\n",
      "Epoch [18/150], Step [2001/5000], Loss = 0.3356\n",
      "Epoch [18/150], Step [2101/5000], Loss = 0.0265\n",
      "Epoch [18/150], Step [2201/5000], Loss = 0.2226\n",
      "Epoch [18/150], Step [2301/5000], Loss = 0.4436\n",
      "Epoch [18/150], Step [2401/5000], Loss = 0.2290\n",
      "Epoch [18/150], Step [2501/5000], Loss = 0.3183\n",
      "Epoch [18/150], Step [2601/5000], Loss = 0.1212\n",
      "Epoch [18/150], Step [2701/5000], Loss = 0.0807\n",
      "Epoch [18/150], Step [2801/5000], Loss = 0.1022\n",
      "Epoch [18/150], Step [2901/5000], Loss = 0.0066\n",
      "Epoch [18/150], Step [3001/5000], Loss = 0.2705\n",
      "Epoch [18/150], Step [3101/5000], Loss = 0.8207\n",
      "Epoch [18/150], Step [3201/5000], Loss = 0.0495\n",
      "Epoch [18/150], Step [3301/5000], Loss = 0.9038\n",
      "Epoch [18/150], Step [3401/5000], Loss = 0.0031\n",
      "Epoch [18/150], Step [3501/5000], Loss = 0.0510\n",
      "Epoch [18/150], Step [3601/5000], Loss = 0.4803\n",
      "Epoch [18/150], Step [3701/5000], Loss = 0.0750\n",
      "Epoch [18/150], Step [3801/5000], Loss = 0.1040\n",
      "Epoch [18/150], Step [3901/5000], Loss = 0.0295\n",
      "Epoch [18/150], Step [4001/5000], Loss = 0.1253\n",
      "Epoch [18/150], Step [4101/5000], Loss = 0.0204\n",
      "Epoch [18/150], Step [4201/5000], Loss = 0.3949\n",
      "Epoch [18/150], Step [4301/5000], Loss = 0.0372\n",
      "Epoch [18/150], Step [4401/5000], Loss = 0.0361\n",
      "Epoch [18/150], Step [4501/5000], Loss = 0.0387\n",
      "Epoch [18/150], Step [4601/5000], Loss = 0.0808\n",
      "Epoch [18/150], Step [4701/5000], Loss = 0.2367\n",
      "Epoch [18/150], Step [4801/5000], Loss = 0.2811\n",
      "Epoch [18/150], Step [4901/5000], Loss = 0.1539\n",
      "Epoch [18/150], Acc = 80.0000\n",
      "Epoch [19/150], Step [1/5000], Loss = 0.0271\n",
      "Epoch [19/150], Step [101/5000], Loss = 0.2651\n",
      "Epoch [19/150], Step [201/5000], Loss = 0.0297\n",
      "Epoch [19/150], Step [301/5000], Loss = 0.1325\n",
      "Epoch [19/150], Step [401/5000], Loss = 0.1084\n",
      "Epoch [19/150], Step [501/5000], Loss = 0.4017\n",
      "Epoch [19/150], Step [601/5000], Loss = 0.0527\n",
      "Epoch [19/150], Step [701/5000], Loss = 0.0736\n",
      "Epoch [19/150], Step [801/5000], Loss = 0.7753\n",
      "Epoch [19/150], Step [901/5000], Loss = 0.0093\n",
      "Epoch [19/150], Step [1001/5000], Loss = 0.1340\n",
      "Epoch [19/150], Step [1101/5000], Loss = 0.0178\n",
      "Epoch [19/150], Step [1201/5000], Loss = 0.2472\n",
      "Epoch [19/150], Step [1301/5000], Loss = 0.1500\n",
      "Epoch [19/150], Step [1401/5000], Loss = 0.2430\n",
      "Epoch [19/150], Step [1501/5000], Loss = 0.0019\n",
      "Epoch [19/150], Step [1601/5000], Loss = 0.1497\n",
      "Epoch [19/150], Step [1701/5000], Loss = 0.0238\n",
      "Epoch [19/150], Step [1801/5000], Loss = 0.0439\n",
      "Epoch [19/150], Step [1901/5000], Loss = 0.0567\n",
      "Epoch [19/150], Step [2001/5000], Loss = 0.3950\n",
      "Epoch [19/150], Step [2101/5000], Loss = 0.0463\n",
      "Epoch [19/150], Step [2201/5000], Loss = 1.0395\n",
      "Epoch [19/150], Step [2301/5000], Loss = 0.0852\n",
      "Epoch [19/150], Step [2401/5000], Loss = 0.0590\n",
      "Epoch [19/150], Step [2501/5000], Loss = 0.0108\n",
      "Epoch [19/150], Step [2601/5000], Loss = 0.0120\n",
      "Epoch [19/150], Step [2701/5000], Loss = 0.0703\n",
      "Epoch [19/150], Step [2801/5000], Loss = 0.0689\n",
      "Epoch [19/150], Step [2901/5000], Loss = 0.1006\n",
      "Epoch [19/150], Step [3001/5000], Loss = 0.0454\n",
      "Epoch [19/150], Step [3101/5000], Loss = 0.1218\n",
      "Epoch [19/150], Step [3201/5000], Loss = 0.0182\n",
      "Epoch [19/150], Step [3301/5000], Loss = 0.0376\n",
      "Epoch [19/150], Step [3401/5000], Loss = 0.0690\n",
      "Epoch [19/150], Step [3501/5000], Loss = 0.0047\n",
      "Epoch [19/150], Step [3601/5000], Loss = 0.0063\n",
      "Epoch [19/150], Step [3701/5000], Loss = 0.0967\n",
      "Epoch [19/150], Step [3801/5000], Loss = 0.2252\n",
      "Epoch [19/150], Step [3901/5000], Loss = 0.5859\n",
      "Epoch [19/150], Step [4001/5000], Loss = 0.4785\n",
      "Epoch [19/150], Step [4101/5000], Loss = 0.0775\n",
      "Epoch [19/150], Step [4201/5000], Loss = 0.0434\n",
      "Epoch [19/150], Step [4301/5000], Loss = 0.1361\n",
      "Epoch [19/150], Step [4401/5000], Loss = 0.0858\n",
      "Epoch [19/150], Step [4501/5000], Loss = 0.0415\n",
      "Epoch [19/150], Step [4601/5000], Loss = 0.2531\n",
      "Epoch [19/150], Step [4701/5000], Loss = 0.2420\n",
      "Epoch [19/150], Step [4801/5000], Loss = 0.2571\n",
      "Epoch [19/150], Step [4901/5000], Loss = 0.4338\n",
      "Epoch [19/150], Acc = 70.0000\n",
      "Epoch [20/150], Step [1/5000], Loss = 0.0021\n",
      "Epoch [20/150], Step [101/5000], Loss = 0.0867\n",
      "Epoch [20/150], Step [201/5000], Loss = 0.0126\n",
      "Epoch [20/150], Step [301/5000], Loss = 0.0100\n",
      "Epoch [20/150], Step [401/5000], Loss = 0.0827\n",
      "Epoch [20/150], Step [501/5000], Loss = 0.0440\n",
      "Epoch [20/150], Step [601/5000], Loss = 0.2686\n",
      "Epoch [20/150], Step [701/5000], Loss = 0.4062\n",
      "Epoch [20/150], Step [801/5000], Loss = 0.3112\n",
      "Epoch [20/150], Step [901/5000], Loss = 0.0697\n",
      "Epoch [20/150], Step [1001/5000], Loss = 0.3247\n",
      "Epoch [20/150], Step [1101/5000], Loss = 0.0127\n",
      "Epoch [20/150], Step [1201/5000], Loss = 0.2027\n",
      "Epoch [20/150], Step [1301/5000], Loss = 0.1113\n",
      "Epoch [20/150], Step [1401/5000], Loss = 0.0299\n",
      "Epoch [20/150], Step [1501/5000], Loss = 0.0456\n",
      "Epoch [20/150], Step [1601/5000], Loss = 0.1677\n",
      "Epoch [20/150], Step [1701/5000], Loss = 0.1109\n",
      "Epoch [20/150], Step [1801/5000], Loss = 0.0061\n",
      "Epoch [20/150], Step [1901/5000], Loss = 0.0888\n",
      "Epoch [20/150], Step [2001/5000], Loss = 0.0071\n",
      "Epoch [20/150], Step [2101/5000], Loss = 0.0271\n",
      "Epoch [20/150], Step [2201/5000], Loss = 0.0373\n",
      "Epoch [20/150], Step [2301/5000], Loss = 0.0175\n",
      "Epoch [20/150], Step [2401/5000], Loss = 0.1844\n",
      "Epoch [20/150], Step [2501/5000], Loss = 0.0228\n",
      "Epoch [20/150], Step [2601/5000], Loss = 0.2146\n",
      "Epoch [20/150], Step [2701/5000], Loss = 0.0106\n",
      "Epoch [20/150], Step [2801/5000], Loss = 0.0181\n",
      "Epoch [20/150], Step [2901/5000], Loss = 0.3988\n",
      "Epoch [20/150], Step [3001/5000], Loss = 0.1869\n",
      "Epoch [20/150], Step [3101/5000], Loss = 0.0073\n",
      "Epoch [20/150], Step [3201/5000], Loss = 0.1534\n",
      "Epoch [20/150], Step [3301/5000], Loss = 0.1573\n",
      "Epoch [20/150], Step [3401/5000], Loss = 0.6434\n",
      "Epoch [20/150], Step [3501/5000], Loss = 0.0070\n",
      "Epoch [20/150], Step [3601/5000], Loss = 0.0642\n",
      "Epoch [20/150], Step [3701/5000], Loss = 0.0590\n",
      "Epoch [20/150], Step [3801/5000], Loss = 0.0207\n",
      "Epoch [20/150], Step [3901/5000], Loss = 0.0295\n",
      "Epoch [20/150], Step [4001/5000], Loss = 0.0009\n",
      "Epoch [20/150], Step [4101/5000], Loss = 0.0289\n",
      "Epoch [20/150], Step [4201/5000], Loss = 0.0334\n",
      "Epoch [20/150], Step [4301/5000], Loss = 0.0082\n",
      "Epoch [20/150], Step [4401/5000], Loss = 0.0650\n",
      "Epoch [20/150], Step [4501/5000], Loss = 0.2287\n",
      "Epoch [20/150], Step [4601/5000], Loss = 0.1753\n",
      "Epoch [20/150], Step [4701/5000], Loss = 0.1226\n",
      "Epoch [20/150], Step [4801/5000], Loss = 0.0498\n",
      "Epoch [20/150], Step [4901/5000], Loss = 0.0280\n",
      "Epoch [20/150], Acc = 80.0000\n",
      "Epoch [21/150], Step [1/5000], Loss = 0.1407\n",
      "Epoch [21/150], Step [101/5000], Loss = 0.0117\n",
      "Epoch [21/150], Step [201/5000], Loss = 0.2040\n",
      "Epoch [21/150], Step [301/5000], Loss = 0.0088\n",
      "Epoch [21/150], Step [401/5000], Loss = 0.0119\n",
      "Epoch [21/150], Step [501/5000], Loss = 0.0740\n",
      "Epoch [21/150], Step [601/5000], Loss = 0.0303\n",
      "Epoch [21/150], Step [701/5000], Loss = 0.1916\n",
      "Epoch [21/150], Step [801/5000], Loss = 0.0747\n",
      "Epoch [21/150], Step [901/5000], Loss = 0.0463\n",
      "Epoch [21/150], Step [1001/5000], Loss = 0.5025\n",
      "Epoch [21/150], Step [1101/5000], Loss = 0.0800\n",
      "Epoch [21/150], Step [1201/5000], Loss = 0.0246\n",
      "Epoch [21/150], Step [1301/5000], Loss = 0.0104\n",
      "Epoch [21/150], Step [1401/5000], Loss = 0.0421\n",
      "Epoch [21/150], Step [1501/5000], Loss = 0.0030\n",
      "Epoch [21/150], Step [1601/5000], Loss = 0.0018\n",
      "Epoch [21/150], Step [1701/5000], Loss = 0.4042\n",
      "Epoch [21/150], Step [1801/5000], Loss = 0.4541\n",
      "Epoch [21/150], Step [1901/5000], Loss = 0.2667\n",
      "Epoch [21/150], Step [2001/5000], Loss = 0.0258\n",
      "Epoch [21/150], Step [2101/5000], Loss = 0.0477\n",
      "Epoch [21/150], Step [2201/5000], Loss = 0.0268\n",
      "Epoch [21/150], Step [2301/5000], Loss = 0.3919\n",
      "Epoch [21/150], Step [2401/5000], Loss = 0.1136\n",
      "Epoch [21/150], Step [2501/5000], Loss = 0.5644\n",
      "Epoch [21/150], Step [2601/5000], Loss = 0.0010\n",
      "Epoch [21/150], Step [2701/5000], Loss = 0.0066\n",
      "Epoch [21/150], Step [2801/5000], Loss = 0.0110\n",
      "Epoch [21/150], Step [2901/5000], Loss = 0.0258\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [21/150], Step [3001/5000], Loss = 0.0759\n",
      "Epoch [21/150], Step [3101/5000], Loss = 0.0133\n",
      "Epoch [21/150], Step [3201/5000], Loss = 0.0150\n",
      "Epoch [21/150], Step [3301/5000], Loss = 0.0100\n",
      "Epoch [21/150], Step [3401/5000], Loss = 0.3636\n",
      "Epoch [21/150], Step [3501/5000], Loss = 0.0141\n",
      "Epoch [21/150], Step [3601/5000], Loss = 0.0215\n",
      "Epoch [21/150], Step [3701/5000], Loss = 0.0337\n",
      "Epoch [21/150], Step [3801/5000], Loss = 0.1005\n",
      "Epoch [21/150], Step [3901/5000], Loss = 0.0384\n",
      "Epoch [21/150], Step [4001/5000], Loss = 0.0782\n",
      "Epoch [21/150], Step [4101/5000], Loss = 0.0107\n",
      "Epoch [21/150], Step [4201/5000], Loss = 0.0712\n",
      "Epoch [21/150], Step [4301/5000], Loss = 0.0113\n",
      "Epoch [21/150], Step [4401/5000], Loss = 0.5995\n",
      "Epoch [21/150], Step [4501/5000], Loss = 0.0062\n",
      "Epoch [21/150], Step [4601/5000], Loss = 0.0610\n",
      "Epoch [21/150], Step [4701/5000], Loss = 0.0991\n",
      "Epoch [21/150], Step [4801/5000], Loss = 0.0452\n",
      "Epoch [21/150], Step [4901/5000], Loss = 0.0188\n",
      "Epoch [21/150], Acc = 90.0000\n",
      "Epoch [22/150], Step [1/5000], Loss = 0.0583\n",
      "Epoch [22/150], Step [101/5000], Loss = 0.0009\n",
      "Epoch [22/150], Step [201/5000], Loss = 0.0119\n",
      "Epoch [22/150], Step [301/5000], Loss = 0.0063\n",
      "Epoch [22/150], Step [401/5000], Loss = 0.0097\n",
      "Epoch [22/150], Step [501/5000], Loss = 0.2333\n",
      "Epoch [22/150], Step [601/5000], Loss = 0.0004\n",
      "Epoch [22/150], Step [701/5000], Loss = 0.0989\n",
      "Epoch [22/150], Step [801/5000], Loss = 0.0843\n",
      "Epoch [22/150], Step [901/5000], Loss = 0.0095\n",
      "Epoch [22/150], Step [1001/5000], Loss = 0.1639\n",
      "Epoch [22/150], Step [1101/5000], Loss = 0.0172\n",
      "Epoch [22/150], Step [1201/5000], Loss = 0.0766\n",
      "Epoch [22/150], Step [1301/5000], Loss = 0.0900\n",
      "Epoch [22/150], Step [1401/5000], Loss = 0.1030\n",
      "Epoch [22/150], Step [1501/5000], Loss = 0.0773\n",
      "Epoch [22/150], Step [1601/5000], Loss = 0.0462\n",
      "Epoch [22/150], Step [1701/5000], Loss = 0.0092\n",
      "Epoch [22/150], Step [1801/5000], Loss = 0.0021\n",
      "Epoch [22/150], Step [1901/5000], Loss = 0.3340\n",
      "Epoch [22/150], Step [2001/5000], Loss = 0.0035\n",
      "Epoch [22/150], Step [2101/5000], Loss = 0.0764\n",
      "Epoch [22/150], Step [2201/5000], Loss = 0.0470\n",
      "Epoch [22/150], Step [2301/5000], Loss = 0.0253\n",
      "Epoch [22/150], Step [2401/5000], Loss = 0.0159\n",
      "Epoch [22/150], Step [2501/5000], Loss = 0.0248\n",
      "Epoch [22/150], Step [2601/5000], Loss = 0.0203\n",
      "Epoch [22/150], Step [2701/5000], Loss = 0.0187\n",
      "Epoch [22/150], Step [2801/5000], Loss = 0.1020\n",
      "Epoch [22/150], Step [2901/5000], Loss = 0.1358\n",
      "Epoch [22/150], Step [3001/5000], Loss = 0.1608\n",
      "Epoch [22/150], Step [3101/5000], Loss = 0.0384\n",
      "Epoch [22/150], Step [3201/5000], Loss = 0.0027\n",
      "Epoch [22/150], Step [3301/5000], Loss = 0.5001\n",
      "Epoch [22/150], Step [3401/5000], Loss = 0.0548\n",
      "Epoch [22/150], Step [3501/5000], Loss = 0.0105\n",
      "Epoch [22/150], Step [3601/5000], Loss = 0.0104\n",
      "Epoch [22/150], Step [3701/5000], Loss = 0.0123\n",
      "Epoch [22/150], Step [3801/5000], Loss = 0.0899\n",
      "Epoch [22/150], Step [3901/5000], Loss = 0.0075\n",
      "Epoch [22/150], Step [4001/5000], Loss = 0.0668\n",
      "Epoch [22/150], Step [4101/5000], Loss = 0.0016\n",
      "Epoch [22/150], Step [4201/5000], Loss = 0.3167\n",
      "Epoch [22/150], Step [4301/5000], Loss = 0.0054\n",
      "Epoch [22/150], Step [4401/5000], Loss = 0.2984\n",
      "Epoch [22/150], Step [4501/5000], Loss = 0.0222\n",
      "Epoch [22/150], Step [4601/5000], Loss = 0.1986\n",
      "Epoch [22/150], Step [4701/5000], Loss = 0.0042\n",
      "Epoch [22/150], Step [4801/5000], Loss = 0.0721\n",
      "Epoch [22/150], Step [4901/5000], Loss = 0.0036\n",
      "Epoch [22/150], Acc = 60.0000\n",
      "Epoch [23/150], Step [1/5000], Loss = 0.6386\n",
      "Epoch [23/150], Step [101/5000], Loss = 0.0012\n",
      "Epoch [23/150], Step [201/5000], Loss = 0.0036\n",
      "Epoch [23/150], Step [301/5000], Loss = 0.1372\n",
      "Epoch [23/150], Step [401/5000], Loss = 0.1746\n",
      "Epoch [23/150], Step [501/5000], Loss = 0.0715\n",
      "Epoch [23/150], Step [601/5000], Loss = 0.0719\n",
      "Epoch [23/150], Step [701/5000], Loss = 0.2989\n",
      "Epoch [23/150], Step [801/5000], Loss = 0.0256\n",
      "Epoch [23/150], Step [901/5000], Loss = 0.0243\n",
      "Epoch [23/150], Step [1001/5000], Loss = 0.0173\n",
      "Epoch [23/150], Step [1101/5000], Loss = 0.0020\n",
      "Epoch [23/150], Step [1201/5000], Loss = 0.0050\n",
      "Epoch [23/150], Step [1301/5000], Loss = 0.0054\n",
      "Epoch [23/150], Step [1401/5000], Loss = 0.1090\n",
      "Epoch [23/150], Step [1501/5000], Loss = 0.0254\n",
      "Epoch [23/150], Step [1601/5000], Loss = 0.1083\n",
      "Epoch [23/150], Step [1701/5000], Loss = 0.0488\n",
      "Epoch [23/150], Step [1801/5000], Loss = 0.0543\n",
      "Epoch [23/150], Step [1901/5000], Loss = 0.1628\n",
      "Epoch [23/150], Step [2001/5000], Loss = 0.3179\n",
      "Epoch [23/150], Step [2101/5000], Loss = 0.0186\n",
      "Epoch [23/150], Step [2201/5000], Loss = 0.3130\n",
      "Epoch [23/150], Step [2301/5000], Loss = 0.7801\n",
      "Epoch [23/150], Step [2401/5000], Loss = 0.0225\n",
      "Epoch [23/150], Step [2501/5000], Loss = 0.0042\n",
      "Epoch [23/150], Step [2601/5000], Loss = 0.5160\n",
      "Epoch [23/150], Step [2701/5000], Loss = 0.0932\n",
      "Epoch [23/150], Step [2801/5000], Loss = 0.0061\n",
      "Epoch [23/150], Step [2901/5000], Loss = 0.0161\n",
      "Epoch [23/150], Step [3001/5000], Loss = 0.0430\n",
      "Epoch [23/150], Step [3101/5000], Loss = 0.1708\n",
      "Epoch [23/150], Step [3201/5000], Loss = 0.2061\n",
      "Epoch [23/150], Step [3301/5000], Loss = 0.4409\n",
      "Epoch [23/150], Step [3401/5000], Loss = 0.2256\n",
      "Epoch [23/150], Step [3501/5000], Loss = 0.0795\n",
      "Epoch [23/150], Step [3601/5000], Loss = 0.2659\n",
      "Epoch [23/150], Step [3701/5000], Loss = 0.0195\n",
      "Epoch [23/150], Step [3801/5000], Loss = 0.0128\n",
      "Epoch [23/150], Step [3901/5000], Loss = 0.0036\n",
      "Epoch [23/150], Step [4001/5000], Loss = 0.0490\n",
      "Epoch [23/150], Step [4101/5000], Loss = 0.0836\n",
      "Epoch [23/150], Step [4201/5000], Loss = 0.0270\n",
      "Epoch [23/150], Step [4301/5000], Loss = 0.0217\n",
      "Epoch [23/150], Step [4401/5000], Loss = 0.0373\n",
      "Epoch [23/150], Step [4501/5000], Loss = 0.0471\n",
      "Epoch [23/150], Step [4601/5000], Loss = 0.0914\n",
      "Epoch [23/150], Step [4701/5000], Loss = 0.0236\n",
      "Epoch [23/150], Step [4801/5000], Loss = 0.1498\n",
      "Epoch [23/150], Step [4901/5000], Loss = 0.2383\n",
      "Epoch [23/150], Acc = 70.0000\n",
      "Epoch [24/150], Step [1/5000], Loss = 0.0119\n",
      "Epoch [24/150], Step [101/5000], Loss = 0.0329\n",
      "Epoch [24/150], Step [201/5000], Loss = 0.0040\n",
      "Epoch [24/150], Step [301/5000], Loss = 0.0820\n",
      "Epoch [24/150], Step [401/5000], Loss = 0.0082\n",
      "Epoch [24/150], Step [501/5000], Loss = 0.0048\n",
      "Epoch [24/150], Step [601/5000], Loss = 0.0007\n",
      "Epoch [24/150], Step [701/5000], Loss = 0.0181\n",
      "Epoch [24/150], Step [801/5000], Loss = 0.0772\n",
      "Epoch [24/150], Step [901/5000], Loss = 0.0131\n",
      "Epoch [24/150], Step [1001/5000], Loss = 0.0811\n",
      "Epoch [24/150], Step [1101/5000], Loss = 0.0025\n",
      "Epoch [24/150], Step [1201/5000], Loss = 0.0020\n",
      "Epoch [24/150], Step [1301/5000], Loss = 0.0000\n",
      "Epoch [24/150], Step [1401/5000], Loss = 0.1615\n",
      "Epoch [24/150], Step [1501/5000], Loss = 0.3153\n",
      "Epoch [24/150], Step [1601/5000], Loss = 0.1112\n",
      "Epoch [24/150], Step [1701/5000], Loss = 0.0896\n",
      "Epoch [24/150], Step [1801/5000], Loss = 0.1473\n",
      "Epoch [24/150], Step [1901/5000], Loss = 0.0058\n",
      "Epoch [24/150], Step [2001/5000], Loss = 0.0120\n",
      "Epoch [24/150], Step [2101/5000], Loss = 0.0043\n",
      "Epoch [24/150], Step [2201/5000], Loss = 0.0783\n",
      "Epoch [24/150], Step [2301/5000], Loss = 0.0012\n",
      "Epoch [24/150], Step [2401/5000], Loss = 0.0015\n",
      "Epoch [24/150], Step [2501/5000], Loss = 0.0052\n",
      "Epoch [24/150], Step [2601/5000], Loss = 0.0675\n",
      "Epoch [24/150], Step [2701/5000], Loss = 0.1660\n",
      "Epoch [24/150], Step [2801/5000], Loss = 0.0195\n",
      "Epoch [24/150], Step [2901/5000], Loss = 0.1045\n",
      "Epoch [24/150], Step [3001/5000], Loss = 0.0493\n",
      "Epoch [24/150], Step [3101/5000], Loss = 0.0030\n",
      "Epoch [24/150], Step [3201/5000], Loss = 0.0083\n",
      "Epoch [24/150], Step [3301/5000], Loss = 0.0010\n",
      "Epoch [24/150], Step [3401/5000], Loss = 0.0487\n",
      "Epoch [24/150], Step [3501/5000], Loss = 0.0003\n",
      "Epoch [24/150], Step [3601/5000], Loss = 0.0428\n",
      "Epoch [24/150], Step [3701/5000], Loss = 0.3196\n",
      "Epoch [24/150], Step [3801/5000], Loss = 0.2022\n",
      "Epoch [24/150], Step [3901/5000], Loss = 0.1342\n",
      "Epoch [24/150], Step [4001/5000], Loss = 0.2235\n",
      "Epoch [24/150], Step [4101/5000], Loss = 0.0760\n",
      "Epoch [24/150], Step [4201/5000], Loss = 0.0068\n",
      "Epoch [24/150], Step [4301/5000], Loss = 0.1979\n",
      "Epoch [24/150], Step [4401/5000], Loss = 0.0734\n",
      "Epoch [24/150], Step [4501/5000], Loss = 0.0410\n",
      "Epoch [24/150], Step [4601/5000], Loss = 0.0060\n",
      "Epoch [24/150], Step [4701/5000], Loss = 0.0566\n",
      "Epoch [24/150], Step [4801/5000], Loss = 0.0192\n",
      "Epoch [24/150], Step [4901/5000], Loss = 0.0094\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [24/150], Acc = 50.0000\n",
      "Epoch [25/150], Step [1/5000], Loss = 0.0067\n",
      "Epoch [25/150], Step [101/5000], Loss = 0.0215\n",
      "Epoch [25/150], Step [201/5000], Loss = 0.1485\n",
      "Epoch [25/150], Step [301/5000], Loss = 0.5046\n",
      "Epoch [25/150], Step [401/5000], Loss = 0.0401\n",
      "Epoch [25/150], Step [501/5000], Loss = 0.2469\n",
      "Epoch [25/150], Step [601/5000], Loss = 0.0162\n",
      "Epoch [25/150], Step [701/5000], Loss = 0.4334\n",
      "Epoch [25/150], Step [801/5000], Loss = 0.0098\n",
      "Epoch [25/150], Step [901/5000], Loss = 0.0914\n",
      "Epoch [25/150], Step [1001/5000], Loss = 0.0024\n",
      "Epoch [25/150], Step [1101/5000], Loss = 0.0164\n",
      "Epoch [25/150], Step [1201/5000], Loss = 0.3268\n",
      "Epoch [25/150], Step [1301/5000], Loss = 0.3238\n",
      "Epoch [25/150], Step [1401/5000], Loss = 0.1793\n",
      "Epoch [25/150], Step [1501/5000], Loss = 0.0171\n",
      "Epoch [25/150], Step [1601/5000], Loss = 0.0091\n",
      "Epoch [25/150], Step [1701/5000], Loss = 0.0784\n",
      "Epoch [25/150], Step [1801/5000], Loss = 0.0402\n",
      "Epoch [25/150], Step [1901/5000], Loss = 0.0367\n",
      "Epoch [25/150], Step [2001/5000], Loss = 0.0116\n",
      "Epoch [25/150], Step [2101/5000], Loss = 0.1375\n",
      "Epoch [25/150], Step [2201/5000], Loss = 0.0010\n",
      "Epoch [25/150], Step [2301/5000], Loss = 0.1175\n",
      "Epoch [25/150], Step [2401/5000], Loss = 0.0413\n",
      "Epoch [25/150], Step [2501/5000], Loss = 0.0330\n",
      "Epoch [25/150], Step [2601/5000], Loss = 0.2376\n",
      "Epoch [25/150], Step [2701/5000], Loss = 0.0960\n",
      "Epoch [25/150], Step [2801/5000], Loss = 0.0483\n",
      "Epoch [25/150], Step [2901/5000], Loss = 0.0068\n",
      "Epoch [25/150], Step [3001/5000], Loss = 0.1440\n",
      "Epoch [25/150], Step [3101/5000], Loss = 0.0026\n",
      "Epoch [25/150], Step [3201/5000], Loss = 0.0163\n",
      "Epoch [25/150], Step [3301/5000], Loss = 0.0533\n",
      "Epoch [25/150], Step [3401/5000], Loss = 0.0761\n",
      "Epoch [25/150], Step [3501/5000], Loss = 0.0704\n",
      "Epoch [25/150], Step [3601/5000], Loss = 0.0208\n",
      "Epoch [25/150], Step [3701/5000], Loss = 0.0177\n",
      "Epoch [25/150], Step [3801/5000], Loss = 0.0011\n",
      "Epoch [25/150], Step [3901/5000], Loss = 0.1049\n",
      "Epoch [25/150], Step [4001/5000], Loss = 0.0672\n",
      "Epoch [25/150], Step [4101/5000], Loss = 0.0181\n",
      "Epoch [25/150], Step [4201/5000], Loss = 0.2087\n",
      "Epoch [25/150], Step [4301/5000], Loss = 0.0012\n",
      "Epoch [25/150], Step [4401/5000], Loss = 0.0132\n",
      "Epoch [25/150], Step [4501/5000], Loss = 0.2695\n",
      "Epoch [25/150], Step [4601/5000], Loss = 0.5434\n",
      "Epoch [25/150], Step [4701/5000], Loss = 0.0072\n",
      "Epoch [25/150], Step [4801/5000], Loss = 0.1027\n",
      "Epoch [25/150], Step [4901/5000], Loss = 0.0596\n",
      "Epoch [25/150], Acc = 60.0000\n",
      "Epoch [26/150], Step [1/5000], Loss = 0.0030\n",
      "Epoch [26/150], Step [101/5000], Loss = 0.0334\n",
      "Epoch [26/150], Step [201/5000], Loss = 0.0206\n",
      "Epoch [26/150], Step [301/5000], Loss = 0.0010\n",
      "Epoch [26/150], Step [401/5000], Loss = 0.0124\n",
      "Epoch [26/150], Step [501/5000], Loss = 0.0098\n",
      "Epoch [26/150], Step [601/5000], Loss = 0.0115\n",
      "Epoch [26/150], Step [701/5000], Loss = 0.0063\n",
      "Epoch [26/150], Step [801/5000], Loss = 0.1729\n",
      "Epoch [26/150], Step [901/5000], Loss = 0.0016\n",
      "Epoch [26/150], Step [1001/5000], Loss = 0.0004\n",
      "Epoch [26/150], Step [1101/5000], Loss = 0.0042\n",
      "Epoch [26/150], Step [1201/5000], Loss = 0.4094\n",
      "Epoch [26/150], Step [1301/5000], Loss = 0.0030\n",
      "Epoch [26/150], Step [1401/5000], Loss = 0.0045\n",
      "Epoch [26/150], Step [1501/5000], Loss = 0.0113\n",
      "Epoch [26/150], Step [1601/5000], Loss = 0.0369\n",
      "Epoch [26/150], Step [1701/5000], Loss = 0.0039\n",
      "Epoch [26/150], Step [1801/5000], Loss = 0.0006\n",
      "Epoch [26/150], Step [1901/5000], Loss = 0.0009\n",
      "Epoch [26/150], Step [2001/5000], Loss = 0.0325\n",
      "Epoch [26/150], Step [2101/5000], Loss = 0.1366\n",
      "Epoch [26/150], Step [2201/5000], Loss = 0.0033\n",
      "Epoch [26/150], Step [2301/5000], Loss = 0.4640\n",
      "Epoch [26/150], Step [2401/5000], Loss = 0.0592\n",
      "Epoch [26/150], Step [2501/5000], Loss = 0.0706\n",
      "Epoch [26/150], Step [2601/5000], Loss = 0.1852\n",
      "Epoch [26/150], Step [2701/5000], Loss = 0.0009\n",
      "Epoch [26/150], Step [2801/5000], Loss = 0.0061\n",
      "Epoch [26/150], Step [2901/5000], Loss = 0.0197\n",
      "Epoch [26/150], Step [3001/5000], Loss = 0.0336\n",
      "Epoch [26/150], Step [3101/5000], Loss = 0.2229\n",
      "Epoch [26/150], Step [3201/5000], Loss = 0.0053\n",
      "Epoch [26/150], Step [3301/5000], Loss = 1.0233\n",
      "Epoch [26/150], Step [3401/5000], Loss = 0.4021\n",
      "Epoch [26/150], Step [3501/5000], Loss = 0.0847\n",
      "Epoch [26/150], Step [3601/5000], Loss = 0.0137\n",
      "Epoch [26/150], Step [3701/5000], Loss = 0.1904\n",
      "Epoch [26/150], Step [3801/5000], Loss = 0.0278\n",
      "Epoch [26/150], Step [3901/5000], Loss = 0.0086\n",
      "Epoch [26/150], Step [4001/5000], Loss = 0.0433\n",
      "Epoch [26/150], Step [4101/5000], Loss = 0.2383\n",
      "Epoch [26/150], Step [4201/5000], Loss = 0.0561\n",
      "Epoch [26/150], Step [4301/5000], Loss = 0.0776\n",
      "Epoch [26/150], Step [4401/5000], Loss = 0.0349\n",
      "Epoch [26/150], Step [4501/5000], Loss = 0.0332\n",
      "Epoch [26/150], Step [4601/5000], Loss = 0.1280\n",
      "Epoch [26/150], Step [4701/5000], Loss = 0.0355\n",
      "Epoch [26/150], Step [4801/5000], Loss = 0.1976\n",
      "Epoch [26/150], Step [4901/5000], Loss = 0.0242\n",
      "Epoch [26/150], Acc = 80.0000\n",
      "Epoch [27/150], Step [1/5000], Loss = 0.0004\n",
      "Epoch [27/150], Step [101/5000], Loss = 0.0865\n",
      "Epoch [27/150], Step [201/5000], Loss = 0.0423\n",
      "Epoch [27/150], Step [301/5000], Loss = 0.0084\n",
      "Epoch [27/150], Step [401/5000], Loss = 0.0779\n",
      "Epoch [27/150], Step [501/5000], Loss = 0.0189\n",
      "Epoch [27/150], Step [601/5000], Loss = 0.0040\n",
      "Epoch [27/150], Step [701/5000], Loss = 0.0106\n",
      "Epoch [27/150], Step [801/5000], Loss = 0.0349\n",
      "Epoch [27/150], Step [901/5000], Loss = 0.0675\n",
      "Epoch [27/150], Step [1001/5000], Loss = 0.0085\n",
      "Epoch [27/150], Step [1101/5000], Loss = 0.0393\n",
      "Epoch [27/150], Step [1201/5000], Loss = 0.0010\n",
      "Epoch [27/150], Step [1301/5000], Loss = 0.0101\n",
      "Epoch [27/150], Step [1401/5000], Loss = 0.0020\n",
      "Epoch [27/150], Step [1501/5000], Loss = 0.0480\n",
      "Epoch [27/150], Step [1601/5000], Loss = 0.0754\n",
      "Epoch [27/150], Step [1701/5000], Loss = 0.0181\n",
      "Epoch [27/150], Step [1801/5000], Loss = 0.0338\n",
      "Epoch [27/150], Step [1901/5000], Loss = 0.5250\n",
      "Epoch [27/150], Step [2001/5000], Loss = 0.0004\n",
      "Epoch [27/150], Step [2101/5000], Loss = 0.0205\n",
      "Epoch [27/150], Step [2201/5000], Loss = 0.0081\n",
      "Epoch [27/150], Step [2301/5000], Loss = 0.0176\n",
      "Epoch [27/150], Step [2401/5000], Loss = 0.0811\n",
      "Epoch [27/150], Step [2501/5000], Loss = 0.1009\n",
      "Epoch [27/150], Step [2601/5000], Loss = 0.1047\n",
      "Epoch [27/150], Step [2701/5000], Loss = 0.6202\n",
      "Epoch [27/150], Step [2801/5000], Loss = 0.0790\n",
      "Epoch [27/150], Step [2901/5000], Loss = 0.2887\n",
      "Epoch [27/150], Step [3001/5000], Loss = 0.0397\n",
      "Epoch [27/150], Step [3101/5000], Loss = 0.0134\n",
      "Epoch [27/150], Step [3201/5000], Loss = 0.1732\n",
      "Epoch [27/150], Step [3301/5000], Loss = 0.0082\n",
      "Epoch [27/150], Step [3401/5000], Loss = 0.1636\n",
      "Epoch [27/150], Step [3501/5000], Loss = 0.0292\n",
      "Epoch [27/150], Step [3601/5000], Loss = 0.0646\n",
      "Epoch [27/150], Step [3701/5000], Loss = 0.0484\n",
      "Epoch [27/150], Step [3801/5000], Loss = 0.0044\n",
      "Epoch [27/150], Step [3901/5000], Loss = 0.0177\n",
      "Epoch [27/150], Step [4001/5000], Loss = 0.1427\n",
      "Epoch [27/150], Step [4101/5000], Loss = 0.0314\n",
      "Epoch [27/150], Step [4201/5000], Loss = 0.1902\n",
      "Epoch [27/150], Step [4301/5000], Loss = 0.0067\n",
      "Epoch [27/150], Step [4401/5000], Loss = 0.0026\n",
      "Epoch [27/150], Step [4501/5000], Loss = 0.0002\n",
      "Epoch [27/150], Step [4601/5000], Loss = 0.0056\n",
      "Epoch [27/150], Step [4701/5000], Loss = 0.0297\n",
      "Epoch [27/150], Step [4801/5000], Loss = 0.0068\n",
      "Epoch [27/150], Step [4901/5000], Loss = 0.6746\n",
      "Epoch [27/150], Acc = 70.0000\n",
      "Epoch [28/150], Step [1/5000], Loss = 0.0749\n",
      "Epoch [28/150], Step [101/5000], Loss = 0.1563\n",
      "Epoch [28/150], Step [201/5000], Loss = 0.0059\n",
      "Epoch [28/150], Step [301/5000], Loss = 0.0127\n",
      "Epoch [28/150], Step [401/5000], Loss = 0.0382\n",
      "Epoch [28/150], Step [501/5000], Loss = 0.1210\n",
      "Epoch [28/150], Step [601/5000], Loss = 0.0013\n",
      "Epoch [28/150], Step [701/5000], Loss = 0.0028\n",
      "Epoch [28/150], Step [801/5000], Loss = 0.0005\n",
      "Epoch [28/150], Step [901/5000], Loss = 0.0021\n",
      "Epoch [28/150], Step [1001/5000], Loss = 0.0185\n",
      "Epoch [28/150], Step [1101/5000], Loss = 0.0258\n",
      "Epoch [28/150], Step [1201/5000], Loss = 0.0400\n",
      "Epoch [28/150], Step [1301/5000], Loss = 0.0029\n",
      "Epoch [28/150], Step [1401/5000], Loss = 0.1022\n",
      "Epoch [28/150], Step [1501/5000], Loss = 0.0298\n",
      "Epoch [28/150], Step [1601/5000], Loss = 0.0838\n",
      "Epoch [28/150], Step [1701/5000], Loss = 0.1241\n",
      "Epoch [28/150], Step [1801/5000], Loss = 0.0023\n",
      "Epoch [28/150], Step [1901/5000], Loss = 0.0362\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [28/150], Step [2001/5000], Loss = 0.0021\n",
      "Epoch [28/150], Step [2101/5000], Loss = 0.0148\n",
      "Epoch [28/150], Step [2201/5000], Loss = 0.0060\n",
      "Epoch [28/150], Step [2301/5000], Loss = 0.0055\n",
      "Epoch [28/150], Step [2401/5000], Loss = 0.0025\n",
      "Epoch [28/150], Step [2501/5000], Loss = 0.1697\n",
      "Epoch [28/150], Step [2601/5000], Loss = 0.2942\n",
      "Epoch [28/150], Step [2701/5000], Loss = 0.0001\n",
      "Epoch [28/150], Step [2801/5000], Loss = 0.4689\n",
      "Epoch [28/150], Step [2901/5000], Loss = 0.0080\n",
      "Epoch [28/150], Step [3001/5000], Loss = 0.0006\n",
      "Epoch [28/150], Step [3101/5000], Loss = 0.0076\n",
      "Epoch [28/150], Step [3201/5000], Loss = 0.0430\n",
      "Epoch [28/150], Step [3301/5000], Loss = 0.0049\n",
      "Epoch [28/150], Step [3401/5000], Loss = 0.2287\n",
      "Epoch [28/150], Step [3501/5000], Loss = 0.0280\n",
      "Epoch [28/150], Step [3601/5000], Loss = 0.0126\n",
      "Epoch [28/150], Step [3701/5000], Loss = 0.0056\n",
      "Epoch [28/150], Step [3801/5000], Loss = 0.0054\n",
      "Epoch [28/150], Step [3901/5000], Loss = 0.0026\n",
      "Epoch [28/150], Step [4001/5000], Loss = 0.0002\n",
      "Epoch [28/150], Step [4101/5000], Loss = 0.1700\n",
      "Epoch [28/150], Step [4201/5000], Loss = 0.0081\n",
      "Epoch [28/150], Step [4301/5000], Loss = 0.0001\n",
      "Epoch [28/150], Step [4401/5000], Loss = 0.1033\n",
      "Epoch [28/150], Step [4501/5000], Loss = 0.3176\n",
      "Epoch [28/150], Step [4601/5000], Loss = 0.0014\n",
      "Epoch [28/150], Step [4701/5000], Loss = 0.1386\n",
      "Epoch [28/150], Step [4801/5000], Loss = 0.0388\n",
      "Epoch [28/150], Step [4901/5000], Loss = 0.1151\n",
      "Epoch [28/150], Acc = 70.0000\n",
      "Epoch [29/150], Step [1/5000], Loss = 0.0004\n",
      "Epoch [29/150], Step [101/5000], Loss = 0.0431\n",
      "Epoch [29/150], Step [201/5000], Loss = 0.1796\n",
      "Epoch [29/150], Step [301/5000], Loss = 0.0015\n",
      "Epoch [29/150], Step [401/5000], Loss = 0.0231\n",
      "Epoch [29/150], Step [501/5000], Loss = 0.0004\n",
      "Epoch [29/150], Step [601/5000], Loss = 0.0611\n",
      "Epoch [29/150], Step [701/5000], Loss = 0.0502\n",
      "Epoch [29/150], Step [801/5000], Loss = 0.0003\n",
      "Epoch [29/150], Step [901/5000], Loss = 0.0012\n",
      "Epoch [29/150], Step [1001/5000], Loss = 0.0062\n",
      "Epoch [29/150], Step [1101/5000], Loss = 0.0650\n",
      "Epoch [29/150], Step [1201/5000], Loss = 0.0149\n",
      "Epoch [29/150], Step [1301/5000], Loss = 0.0010\n",
      "Epoch [29/150], Step [1401/5000], Loss = 0.0019\n",
      "Epoch [29/150], Step [1501/5000], Loss = 0.0117\n",
      "Epoch [29/150], Step [1601/5000], Loss = 0.0017\n",
      "Epoch [29/150], Step [1701/5000], Loss = 0.0853\n",
      "Epoch [29/150], Step [1801/5000], Loss = 0.0077\n",
      "Epoch [29/150], Step [1901/5000], Loss = 0.0383\n",
      "Epoch [29/150], Step [2001/5000], Loss = 0.0008\n",
      "Epoch [29/150], Step [2101/5000], Loss = 0.0036\n",
      "Epoch [29/150], Step [2201/5000], Loss = 0.0801\n",
      "Epoch [29/150], Step [2301/5000], Loss = 0.0154\n",
      "Epoch [29/150], Step [2401/5000], Loss = 0.0024\n",
      "Epoch [29/150], Step [2501/5000], Loss = 0.3258\n",
      "Epoch [29/150], Step [2601/5000], Loss = 0.1186\n",
      "Epoch [29/150], Step [2701/5000], Loss = 0.0045\n",
      "Epoch [29/150], Step [2801/5000], Loss = 0.0154\n",
      "Epoch [29/150], Step [2901/5000], Loss = 0.0770\n",
      "Epoch [29/150], Step [3001/5000], Loss = 0.0048\n",
      "Epoch [29/150], Step [3101/5000], Loss = 0.0202\n",
      "Epoch [29/150], Step [3201/5000], Loss = 0.0716\n",
      "Epoch [29/150], Step [3301/5000], Loss = 0.1008\n",
      "Epoch [29/150], Step [3401/5000], Loss = 0.0185\n",
      "Epoch [29/150], Step [3501/5000], Loss = 0.0566\n",
      "Epoch [29/150], Step [3601/5000], Loss = 0.1318\n",
      "Epoch [29/150], Step [3701/5000], Loss = 0.0109\n",
      "Epoch [29/150], Step [3801/5000], Loss = 0.0459\n",
      "Epoch [29/150], Step [3901/5000], Loss = 0.0268\n",
      "Epoch [29/150], Step [4001/5000], Loss = 0.1407\n",
      "Epoch [29/150], Step [4101/5000], Loss = 0.0229\n",
      "Epoch [29/150], Step [4201/5000], Loss = 0.2563\n",
      "Epoch [29/150], Step [4301/5000], Loss = 0.4900\n",
      "Epoch [29/150], Step [4401/5000], Loss = 0.1851\n",
      "Epoch [29/150], Step [4501/5000], Loss = 0.0105\n",
      "Epoch [29/150], Step [4601/5000], Loss = 0.0682\n",
      "Epoch [29/150], Step [4701/5000], Loss = 0.0096\n",
      "Epoch [29/150], Step [4801/5000], Loss = 0.0021\n",
      "Epoch [29/150], Step [4901/5000], Loss = 0.0362\n",
      "Epoch [29/150], Acc = 70.0000\n",
      "Epoch [30/150], Step [1/5000], Loss = 0.0181\n",
      "Epoch [30/150], Step [101/5000], Loss = 0.0117\n",
      "Epoch [30/150], Step [201/5000], Loss = 0.0031\n",
      "Epoch [30/150], Step [301/5000], Loss = 0.0065\n",
      "Epoch [30/150], Step [401/5000], Loss = 0.0018\n",
      "Epoch [30/150], Step [501/5000], Loss = 0.0233\n",
      "Epoch [30/150], Step [601/5000], Loss = 0.0053\n",
      "Epoch [30/150], Step [701/5000], Loss = 0.0214\n",
      "Epoch [30/150], Step [801/5000], Loss = 0.0003\n",
      "Epoch [30/150], Step [901/5000], Loss = 0.0093\n",
      "Epoch [30/150], Step [1001/5000], Loss = 0.0072\n",
      "Epoch [30/150], Step [1101/5000], Loss = 0.0069\n",
      "Epoch [30/150], Step [1201/5000], Loss = 0.0400\n",
      "Epoch [30/150], Step [1301/5000], Loss = 0.0561\n",
      "Epoch [30/150], Step [1401/5000], Loss = 0.0031\n",
      "Epoch [30/150], Step [1501/5000], Loss = 0.0009\n",
      "Epoch [30/150], Step [1601/5000], Loss = 0.0447\n",
      "Epoch [30/150], Step [1701/5000], Loss = 0.0006\n",
      "Epoch [30/150], Step [1801/5000], Loss = 0.3565\n",
      "Epoch [30/150], Step [1901/5000], Loss = 0.0150\n",
      "Epoch [30/150], Step [2001/5000], Loss = 0.0475\n",
      "Epoch [30/150], Step [2101/5000], Loss = 0.0693\n",
      "Epoch [30/150], Step [2201/5000], Loss = 0.3537\n",
      "Epoch [30/150], Step [2301/5000], Loss = 0.0049\n",
      "Epoch [30/150], Step [2401/5000], Loss = 0.0190\n",
      "Epoch [30/150], Step [2501/5000], Loss = 0.1674\n",
      "Epoch [30/150], Step [2601/5000], Loss = 0.0295\n",
      "Epoch [30/150], Step [2701/5000], Loss = 0.0352\n",
      "Epoch [30/150], Step [2801/5000], Loss = 0.2651\n",
      "Epoch [30/150], Step [2901/5000], Loss = 0.1545\n",
      "Epoch [30/150], Step [3001/5000], Loss = 0.0007\n",
      "Epoch [30/150], Step [3101/5000], Loss = 0.2589\n",
      "Epoch [30/150], Step [3201/5000], Loss = 0.1819\n",
      "Epoch [30/150], Step [3301/5000], Loss = 0.0010\n",
      "Epoch [30/150], Step [3401/5000], Loss = 0.0007\n",
      "Epoch [30/150], Step [3501/5000], Loss = 0.0444\n",
      "Epoch [30/150], Step [3601/5000], Loss = 0.0030\n",
      "Epoch [30/150], Step [3701/5000], Loss = 0.2067\n",
      "Epoch [30/150], Step [3801/5000], Loss = 0.0147\n",
      "Epoch [30/150], Step [3901/5000], Loss = 0.0069\n",
      "Epoch [30/150], Step [4001/5000], Loss = 0.0174\n",
      "Epoch [30/150], Step [4101/5000], Loss = 0.0278\n",
      "Epoch [30/150], Step [4201/5000], Loss = 0.0034\n",
      "Epoch [30/150], Step [4301/5000], Loss = 0.3920\n",
      "Epoch [30/150], Step [4401/5000], Loss = 0.2328\n",
      "Epoch [30/150], Step [4501/5000], Loss = 0.4450\n",
      "Epoch [30/150], Step [4601/5000], Loss = 0.0203\n",
      "Epoch [30/150], Step [4701/5000], Loss = 0.0006\n",
      "Epoch [30/150], Step [4801/5000], Loss = 0.0472\n",
      "Epoch [30/150], Step [4901/5000], Loss = 0.0042\n",
      "Epoch [30/150], Acc = 70.0000\n",
      "Epoch [31/150], Step [1/5000], Loss = 0.1737\n",
      "Epoch [31/150], Step [101/5000], Loss = 0.0097\n",
      "Epoch [31/150], Step [201/5000], Loss = 0.0125\n",
      "Epoch [31/150], Step [301/5000], Loss = 0.0188\n",
      "Epoch [31/150], Step [401/5000], Loss = 0.0034\n",
      "Epoch [31/150], Step [501/5000], Loss = 0.0020\n",
      "Epoch [31/150], Step [601/5000], Loss = 0.4177\n",
      "Epoch [31/150], Step [701/5000], Loss = 0.0016\n",
      "Epoch [31/150], Step [801/5000], Loss = 0.3976\n",
      "Epoch [31/150], Step [901/5000], Loss = 0.0005\n",
      "Epoch [31/150], Step [1001/5000], Loss = 0.0125\n",
      "Epoch [31/150], Step [1101/5000], Loss = 0.0045\n",
      "Epoch [31/150], Step [1201/5000], Loss = 0.1081\n",
      "Epoch [31/150], Step [1301/5000], Loss = 0.2019\n",
      "Epoch [31/150], Step [1401/5000], Loss = 0.0003\n",
      "Epoch [31/150], Step [1501/5000], Loss = 0.0786\n",
      "Epoch [31/150], Step [1601/5000], Loss = 0.0023\n",
      "Epoch [31/150], Step [1701/5000], Loss = 0.0269\n",
      "Epoch [31/150], Step [1801/5000], Loss = 0.0088\n",
      "Epoch [31/150], Step [1901/5000], Loss = 0.0032\n",
      "Epoch [31/150], Step [2001/5000], Loss = 0.0058\n",
      "Epoch [31/150], Step [2101/5000], Loss = 0.0133\n",
      "Epoch [31/150], Step [2201/5000], Loss = 0.0133\n",
      "Epoch [31/150], Step [2301/5000], Loss = 0.0502\n",
      "Epoch [31/150], Step [2401/5000], Loss = 0.0467\n",
      "Epoch [31/150], Step [2501/5000], Loss = 0.0861\n",
      "Epoch [31/150], Step [2601/5000], Loss = 0.0052\n",
      "Epoch [31/150], Step [2701/5000], Loss = 0.0107\n",
      "Epoch [31/150], Step [2801/5000], Loss = 0.0019\n",
      "Epoch [31/150], Step [2901/5000], Loss = 0.0237\n",
      "Epoch [31/150], Step [3001/5000], Loss = 0.0024\n",
      "Epoch [31/150], Step [3101/5000], Loss = 0.0424\n",
      "Epoch [31/150], Step [3201/5000], Loss = 0.0080\n",
      "Epoch [31/150], Step [3301/5000], Loss = 0.0009\n",
      "Epoch [31/150], Step [3401/5000], Loss = 0.0143\n",
      "Epoch [31/150], Step [3501/5000], Loss = 0.0060\n",
      "Epoch [31/150], Step [3601/5000], Loss = 0.0696\n",
      "Epoch [31/150], Step [3701/5000], Loss = 0.1361\n",
      "Epoch [31/150], Step [3801/5000], Loss = 0.0096\n",
      "Epoch [31/150], Step [3901/5000], Loss = 0.0130\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [31/150], Step [4001/5000], Loss = 0.0015\n",
      "Epoch [31/150], Step [4101/5000], Loss = 0.0064\n",
      "Epoch [31/150], Step [4201/5000], Loss = 0.1766\n",
      "Epoch [31/150], Step [4301/5000], Loss = 0.1498\n",
      "Epoch [31/150], Step [4401/5000], Loss = 0.0244\n",
      "Epoch [31/150], Step [4501/5000], Loss = 0.0057\n",
      "Epoch [31/150], Step [4601/5000], Loss = 0.0002\n",
      "Epoch [31/150], Step [4701/5000], Loss = 0.0028\n",
      "Epoch [31/150], Step [4801/5000], Loss = 0.2050\n",
      "Epoch [31/150], Step [4901/5000], Loss = 0.0928\n",
      "Epoch [31/150], Acc = 50.0000\n",
      "Epoch [32/150], Step [1/5000], Loss = 0.0590\n",
      "Epoch [32/150], Step [101/5000], Loss = 0.0070\n",
      "Epoch [32/150], Step [201/5000], Loss = 0.0002\n",
      "Epoch [32/150], Step [301/5000], Loss = 0.0074\n",
      "Epoch [32/150], Step [401/5000], Loss = 0.0500\n",
      "Epoch [32/150], Step [501/5000], Loss = 0.0116\n",
      "Epoch [32/150], Step [601/5000], Loss = 0.0469\n",
      "Epoch [32/150], Step [701/5000], Loss = 0.0830\n",
      "Epoch [32/150], Step [801/5000], Loss = 0.0056\n",
      "Epoch [32/150], Step [901/5000], Loss = 0.2796\n",
      "Epoch [32/150], Step [1001/5000], Loss = 0.0357\n",
      "Epoch [32/150], Step [1101/5000], Loss = 0.0120\n",
      "Epoch [32/150], Step [1201/5000], Loss = 0.1693\n",
      "Epoch [32/150], Step [1301/5000], Loss = 0.1643\n",
      "Epoch [32/150], Step [1401/5000], Loss = 0.0776\n",
      "Epoch [32/150], Step [1501/5000], Loss = 0.0013\n",
      "Epoch [32/150], Step [1601/5000], Loss = 0.0039\n",
      "Epoch [32/150], Step [1701/5000], Loss = 0.0010\n",
      "Epoch [32/150], Step [1801/5000], Loss = 0.0025\n",
      "Epoch [32/150], Step [1901/5000], Loss = 0.0738\n",
      "Epoch [32/150], Step [2001/5000], Loss = 0.0019\n",
      "Epoch [32/150], Step [2101/5000], Loss = 0.0249\n",
      "Epoch [32/150], Step [2201/5000], Loss = 0.0502\n",
      "Epoch [32/150], Step [2301/5000], Loss = 0.0066\n",
      "Epoch [32/150], Step [2401/5000], Loss = 0.0046\n",
      "Epoch [32/150], Step [2501/5000], Loss = 0.0160\n",
      "Epoch [32/150], Step [2601/5000], Loss = 0.0379\n",
      "Epoch [32/150], Step [2701/5000], Loss = 0.0068\n",
      "Epoch [32/150], Step [2801/5000], Loss = 0.0105\n",
      "Epoch [32/150], Step [2901/5000], Loss = 0.0729\n",
      "Epoch [32/150], Step [3001/5000], Loss = 0.9989\n",
      "Epoch [32/150], Step [3101/5000], Loss = 0.0007\n",
      "Epoch [32/150], Step [3201/5000], Loss = 0.0009\n",
      "Epoch [32/150], Step [3301/5000], Loss = 0.0022\n",
      "Epoch [32/150], Step [3401/5000], Loss = 0.0121\n",
      "Epoch [32/150], Step [3501/5000], Loss = 0.0280\n",
      "Epoch [32/150], Step [3601/5000], Loss = 0.0021\n",
      "Epoch [32/150], Step [3701/5000], Loss = 0.0197\n",
      "Epoch [32/150], Step [3801/5000], Loss = 0.0009\n",
      "Epoch [32/150], Step [3901/5000], Loss = 0.0012\n",
      "Epoch [32/150], Step [4001/5000], Loss = 0.0609\n",
      "Epoch [32/150], Step [4101/5000], Loss = 0.0247\n",
      "Epoch [32/150], Step [4201/5000], Loss = 0.0261\n",
      "Epoch [32/150], Step [4301/5000], Loss = 0.0066\n",
      "Epoch [32/150], Step [4401/5000], Loss = 0.0348\n",
      "Epoch [32/150], Step [4501/5000], Loss = 0.0009\n",
      "Epoch [32/150], Step [4601/5000], Loss = 0.0012\n",
      "Epoch [32/150], Step [4701/5000], Loss = 0.0011\n",
      "Epoch [32/150], Step [4801/5000], Loss = 0.0006\n",
      "Epoch [32/150], Step [4901/5000], Loss = 0.0094\n",
      "Epoch [32/150], Acc = 60.0000\n",
      "Epoch [33/150], Step [1/5000], Loss = 0.0039\n",
      "Epoch [33/150], Step [101/5000], Loss = 0.0029\n",
      "Epoch [33/150], Step [201/5000], Loss = 0.1434\n",
      "Epoch [33/150], Step [301/5000], Loss = 0.0042\n",
      "Epoch [33/150], Step [401/5000], Loss = 0.0008\n",
      "Epoch [33/150], Step [501/5000], Loss = 0.0063\n",
      "Epoch [33/150], Step [601/5000], Loss = 0.1380\n",
      "Epoch [33/150], Step [701/5000], Loss = 0.1671\n",
      "Epoch [33/150], Step [801/5000], Loss = 0.0157\n",
      "Epoch [33/150], Step [901/5000], Loss = 0.0055\n",
      "Epoch [33/150], Step [1001/5000], Loss = 0.0044\n",
      "Epoch [33/150], Step [1101/5000], Loss = 0.0032\n",
      "Epoch [33/150], Step [1201/5000], Loss = 0.0027\n",
      "Epoch [33/150], Step [1301/5000], Loss = 0.4381\n",
      "Epoch [33/150], Step [1401/5000], Loss = 0.2740\n",
      "Epoch [33/150], Step [1501/5000], Loss = 0.0020\n",
      "Epoch [33/150], Step [1601/5000], Loss = 0.0036\n",
      "Epoch [33/150], Step [1701/5000], Loss = 0.0021\n",
      "Epoch [33/150], Step [1801/5000], Loss = 0.0024\n",
      "Epoch [33/150], Step [1901/5000], Loss = 0.4568\n",
      "Epoch [33/150], Step [2001/5000], Loss = 0.0066\n",
      "Epoch [33/150], Step [2101/5000], Loss = 0.0014\n",
      "Epoch [33/150], Step [2201/5000], Loss = 0.0019\n",
      "Epoch [33/150], Step [2301/5000], Loss = 0.0001\n",
      "Epoch [33/150], Step [2401/5000], Loss = 0.0062\n",
      "Epoch [33/150], Step [2501/5000], Loss = 0.0540\n",
      "Epoch [33/150], Step [2601/5000], Loss = 0.5659\n",
      "Epoch [33/150], Step [2701/5000], Loss = 0.0011\n",
      "Epoch [33/150], Step [2801/5000], Loss = 0.0113\n",
      "Epoch [33/150], Step [2901/5000], Loss = 0.0017\n",
      "Epoch [33/150], Step [3001/5000], Loss = 0.0172\n",
      "Epoch [33/150], Step [3101/5000], Loss = 0.0781\n",
      "Epoch [33/150], Step [3201/5000], Loss = 0.1707\n",
      "Epoch [33/150], Step [3301/5000], Loss = 0.0282\n",
      "Epoch [33/150], Step [3401/5000], Loss = 0.0504\n",
      "Epoch [33/150], Step [3501/5000], Loss = 0.1536\n",
      "Epoch [33/150], Step [3601/5000], Loss = 0.0009\n",
      "Epoch [33/150], Step [3701/5000], Loss = 0.0006\n",
      "Epoch [33/150], Step [3801/5000], Loss = 0.0057\n",
      "Epoch [33/150], Step [3901/5000], Loss = 0.0063\n",
      "Epoch [33/150], Step [4001/5000], Loss = 0.0126\n",
      "Epoch [33/150], Step [4101/5000], Loss = 0.1016\n",
      "Epoch [33/150], Step [4201/5000], Loss = 0.0715\n",
      "Epoch [33/150], Step [4301/5000], Loss = 0.0082\n",
      "Epoch [33/150], Step [4401/5000], Loss = 0.0494\n",
      "Epoch [33/150], Step [4501/5000], Loss = 0.0548\n",
      "Epoch [33/150], Step [4601/5000], Loss = 0.0211\n",
      "Epoch [33/150], Step [4701/5000], Loss = 0.0179\n",
      "Epoch [33/150], Step [4801/5000], Loss = 0.0007\n",
      "Epoch [33/150], Step [4901/5000], Loss = 0.0647\n",
      "Epoch [33/150], Acc = 80.0000\n",
      "Epoch [34/150], Step [1/5000], Loss = 0.0003\n",
      "Epoch [34/150], Step [101/5000], Loss = 0.0221\n",
      "Epoch [34/150], Step [201/5000], Loss = 0.0156\n",
      "Epoch [34/150], Step [301/5000], Loss = 0.0013\n",
      "Epoch [34/150], Step [401/5000], Loss = 0.0201\n",
      "Epoch [34/150], Step [501/5000], Loss = 0.0899\n",
      "Epoch [34/150], Step [601/5000], Loss = 0.0002\n",
      "Epoch [34/150], Step [701/5000], Loss = 0.0001\n",
      "Epoch [34/150], Step [801/5000], Loss = 0.0003\n",
      "Epoch [34/150], Step [901/5000], Loss = 0.0117\n",
      "Epoch [34/150], Step [1001/5000], Loss = 0.0108\n",
      "Epoch [34/150], Step [1101/5000], Loss = 0.0054\n",
      "Epoch [34/150], Step [1201/5000], Loss = 0.0563\n",
      "Epoch [34/150], Step [1301/5000], Loss = 0.0087\n",
      "Epoch [34/150], Step [1401/5000], Loss = 0.0002\n",
      "Epoch [34/150], Step [1501/5000], Loss = 0.0025\n",
      "Epoch [34/150], Step [1601/5000], Loss = 0.0024\n",
      "Epoch [34/150], Step [1701/5000], Loss = 0.0008\n",
      "Epoch [34/150], Step [1801/5000], Loss = 0.0257\n",
      "Epoch [34/150], Step [1901/5000], Loss = 0.0045\n",
      "Epoch [34/150], Step [2001/5000], Loss = 0.4311\n",
      "Epoch [34/150], Step [2101/5000], Loss = 0.0006\n",
      "Epoch [34/150], Step [2201/5000], Loss = 0.0051\n",
      "Epoch [34/150], Step [2301/5000], Loss = 0.0553\n",
      "Epoch [34/150], Step [2401/5000], Loss = 0.0159\n",
      "Epoch [34/150], Step [2501/5000], Loss = 0.0006\n",
      "Epoch [34/150], Step [2601/5000], Loss = 0.0088\n",
      "Epoch [34/150], Step [2701/5000], Loss = 0.0372\n",
      "Epoch [34/150], Step [2801/5000], Loss = 0.0908\n",
      "Epoch [34/150], Step [2901/5000], Loss = 0.0046\n",
      "Epoch [34/150], Step [3001/5000], Loss = 0.0074\n",
      "Epoch [34/150], Step [3101/5000], Loss = 0.3398\n",
      "Epoch [34/150], Step [3201/5000], Loss = 0.0058\n",
      "Epoch [34/150], Step [3301/5000], Loss = 0.0065\n",
      "Epoch [34/150], Step [3401/5000], Loss = 0.1560\n",
      "Epoch [34/150], Step [3501/5000], Loss = 0.0712\n",
      "Epoch [34/150], Step [3601/5000], Loss = 0.0890\n",
      "Epoch [34/150], Step [3701/5000], Loss = 0.3160\n",
      "Epoch [34/150], Step [3801/5000], Loss = 0.0116\n",
      "Epoch [34/150], Step [3901/5000], Loss = 0.0016\n",
      "Epoch [34/150], Step [4001/5000], Loss = 0.4316\n",
      "Epoch [34/150], Step [4101/5000], Loss = 0.0076\n",
      "Epoch [34/150], Step [4201/5000], Loss = 0.0002\n",
      "Epoch [34/150], Step [4301/5000], Loss = 0.0065\n",
      "Epoch [34/150], Step [4401/5000], Loss = 0.0094\n",
      "Epoch [34/150], Step [4501/5000], Loss = 0.0933\n",
      "Epoch [34/150], Step [4601/5000], Loss = 0.1367\n",
      "Epoch [34/150], Step [4701/5000], Loss = 0.0023\n",
      "Epoch [34/150], Step [4801/5000], Loss = 0.0087\n",
      "Epoch [34/150], Step [4901/5000], Loss = 0.0013\n",
      "Epoch [34/150], Acc = 90.0000\n",
      "Epoch [35/150], Step [1/5000], Loss = 0.0090\n",
      "Epoch [35/150], Step [101/5000], Loss = 0.0076\n",
      "Epoch [35/150], Step [201/5000], Loss = 0.1257\n",
      "Epoch [35/150], Step [301/5000], Loss = 0.0034\n",
      "Epoch [35/150], Step [401/5000], Loss = 0.1690\n",
      "Epoch [35/150], Step [501/5000], Loss = 0.0020\n",
      "Epoch [35/150], Step [601/5000], Loss = 0.0514\n",
      "Epoch [35/150], Step [701/5000], Loss = 0.0041\n",
      "Epoch [35/150], Step [801/5000], Loss = 0.0012\n",
      "Epoch [35/150], Step [901/5000], Loss = 0.0002\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [35/150], Step [1001/5000], Loss = 0.2001\n",
      "Epoch [35/150], Step [1101/5000], Loss = 0.0802\n",
      "Epoch [35/150], Step [1201/5000], Loss = 0.0119\n",
      "Epoch [35/150], Step [1301/5000], Loss = 0.0004\n",
      "Epoch [35/150], Step [1401/5000], Loss = 0.0032\n",
      "Epoch [35/150], Step [1501/5000], Loss = 0.1289\n",
      "Epoch [35/150], Step [1601/5000], Loss = 0.0055\n",
      "Epoch [35/150], Step [1701/5000], Loss = 0.0013\n",
      "Epoch [35/150], Step [1801/5000], Loss = 0.0079\n",
      "Epoch [35/150], Step [1901/5000], Loss = 0.0083\n",
      "Epoch [35/150], Step [2001/5000], Loss = 0.0002\n",
      "Epoch [35/150], Step [2101/5000], Loss = 0.0174\n",
      "Epoch [35/150], Step [2201/5000], Loss = 0.0934\n",
      "Epoch [35/150], Step [2301/5000], Loss = 0.0488\n",
      "Epoch [35/150], Step [2401/5000], Loss = 0.1212\n",
      "Epoch [35/150], Step [2501/5000], Loss = 0.0011\n",
      "Epoch [35/150], Step [2601/5000], Loss = 0.0093\n",
      "Epoch [35/150], Step [2701/5000], Loss = 0.0020\n",
      "Epoch [35/150], Step [2801/5000], Loss = 0.0009\n",
      "Epoch [35/150], Step [2901/5000], Loss = 0.1196\n",
      "Epoch [35/150], Step [3001/5000], Loss = 0.0015\n",
      "Epoch [35/150], Step [3101/5000], Loss = 0.0116\n",
      "Epoch [35/150], Step [3201/5000], Loss = 0.0025\n",
      "Epoch [35/150], Step [3301/5000], Loss = 0.0018\n",
      "Epoch [35/150], Step [3401/5000], Loss = 0.0164\n",
      "Epoch [35/150], Step [3501/5000], Loss = 0.0315\n",
      "Epoch [35/150], Step [3601/5000], Loss = 0.0405\n",
      "Epoch [35/150], Step [3701/5000], Loss = 0.0104\n",
      "Epoch [35/150], Step [3801/5000], Loss = 0.1780\n",
      "Epoch [35/150], Step [3901/5000], Loss = 0.0000\n",
      "Epoch [35/150], Step [4001/5000], Loss = 0.0267\n",
      "Epoch [35/150], Step [4101/5000], Loss = 0.0001\n",
      "Epoch [35/150], Step [4201/5000], Loss = 0.0084\n",
      "Epoch [35/150], Step [4301/5000], Loss = 0.0283\n",
      "Epoch [35/150], Step [4401/5000], Loss = 0.0286\n",
      "Epoch [35/150], Step [4501/5000], Loss = 0.0008\n",
      "Epoch [35/150], Step [4601/5000], Loss = 0.0006\n",
      "Epoch [35/150], Step [4701/5000], Loss = 0.0081\n",
      "Epoch [35/150], Step [4801/5000], Loss = 0.0083\n",
      "Epoch [35/150], Step [4901/5000], Loss = 0.0007\n",
      "Epoch [35/150], Acc = 60.0000\n",
      "Epoch [36/150], Step [1/5000], Loss = 0.0028\n",
      "Epoch [36/150], Step [101/5000], Loss = 0.0180\n",
      "Epoch [36/150], Step [201/5000], Loss = 0.0929\n",
      "Epoch [36/150], Step [301/5000], Loss = 0.0032\n",
      "Epoch [36/150], Step [401/5000], Loss = 0.1961\n",
      "Epoch [36/150], Step [501/5000], Loss = 0.0010\n",
      "Epoch [36/150], Step [601/5000], Loss = 0.0752\n",
      "Epoch [36/150], Step [701/5000], Loss = 0.0064\n",
      "Epoch [36/150], Step [801/5000], Loss = 0.0098\n",
      "Epoch [36/150], Step [901/5000], Loss = 0.0003\n",
      "Epoch [36/150], Step [1001/5000], Loss = 0.0018\n",
      "Epoch [36/150], Step [1101/5000], Loss = 0.0009\n",
      "Epoch [36/150], Step [1201/5000], Loss = 0.0001\n",
      "Epoch [36/150], Step [1301/5000], Loss = 0.0015\n",
      "Epoch [36/150], Step [1401/5000], Loss = 0.0007\n",
      "Epoch [36/150], Step [1501/5000], Loss = 0.0152\n",
      "Epoch [36/150], Step [1601/5000], Loss = 0.0012\n",
      "Epoch [36/150], Step [1701/5000], Loss = 0.0322\n",
      "Epoch [36/150], Step [1801/5000], Loss = 0.0061\n",
      "Epoch [36/150], Step [1901/5000], Loss = 0.0031\n",
      "Epoch [36/150], Step [2001/5000], Loss = 0.0003\n",
      "Epoch [36/150], Step [2101/5000], Loss = 0.0070\n",
      "Epoch [36/150], Step [2201/5000], Loss = 0.0066\n",
      "Epoch [36/150], Step [2301/5000], Loss = 0.1811\n",
      "Epoch [36/150], Step [2401/5000], Loss = 0.0275\n",
      "Epoch [36/150], Step [2501/5000], Loss = 0.0070\n",
      "Epoch [36/150], Step [2601/5000], Loss = 0.0018\n",
      "Epoch [36/150], Step [2701/5000], Loss = 0.0052\n",
      "Epoch [36/150], Step [2801/5000], Loss = 0.0263\n",
      "Epoch [36/150], Step [2901/5000], Loss = 0.0262\n",
      "Epoch [36/150], Step [3001/5000], Loss = 0.0903\n",
      "Epoch [36/150], Step [3101/5000], Loss = 0.0017\n",
      "Epoch [36/150], Step [3201/5000], Loss = 0.0354\n",
      "Epoch [36/150], Step [3301/5000], Loss = 0.1022\n",
      "Epoch [36/150], Step [3401/5000], Loss = 0.2416\n",
      "Epoch [36/150], Step [3501/5000], Loss = 0.0008\n",
      "Epoch [36/150], Step [3601/5000], Loss = 0.0029\n",
      "Epoch [36/150], Step [3701/5000], Loss = 0.0017\n",
      "Epoch [36/150], Step [3801/5000], Loss = 0.0047\n",
      "Epoch [36/150], Step [3901/5000], Loss = 0.0496\n",
      "Epoch [36/150], Step [4001/5000], Loss = 0.0960\n",
      "Epoch [36/150], Step [4101/5000], Loss = 0.0183\n",
      "Epoch [36/150], Step [4201/5000], Loss = 0.0000\n",
      "Epoch [36/150], Step [4301/5000], Loss = 0.0870\n",
      "Epoch [36/150], Step [4401/5000], Loss = 0.0576\n",
      "Epoch [36/150], Step [4501/5000], Loss = 0.0043\n",
      "Epoch [36/150], Step [4601/5000], Loss = 0.0125\n",
      "Epoch [36/150], Step [4701/5000], Loss = 0.0237\n",
      "Epoch [36/150], Step [4801/5000], Loss = 0.1577\n",
      "Epoch [36/150], Step [4901/5000], Loss = 0.0006\n",
      "Epoch [36/150], Acc = 80.0000\n",
      "Epoch [37/150], Step [1/5000], Loss = 0.0030\n",
      "Epoch [37/150], Step [101/5000], Loss = 0.0002\n",
      "Epoch [37/150], Step [201/5000], Loss = 0.0000\n",
      "Epoch [37/150], Step [301/5000], Loss = 0.1732\n",
      "Epoch [37/150], Step [401/5000], Loss = 0.0001\n",
      "Epoch [37/150], Step [501/5000], Loss = 0.0014\n",
      "Epoch [37/150], Step [601/5000], Loss = 0.0052\n",
      "Epoch [37/150], Step [701/5000], Loss = 0.0009\n",
      "Epoch [37/150], Step [801/5000], Loss = 0.0039\n",
      "Epoch [37/150], Step [901/5000], Loss = 0.0101\n",
      "Epoch [37/150], Step [1001/5000], Loss = 0.0011\n",
      "Epoch [37/150], Step [1101/5000], Loss = 0.0003\n",
      "Epoch [37/150], Step [1201/5000], Loss = 0.1528\n",
      "Epoch [37/150], Step [1301/5000], Loss = 0.0058\n",
      "Epoch [37/150], Step [1401/5000], Loss = 0.0093\n",
      "Epoch [37/150], Step [1501/5000], Loss = 0.0102\n",
      "Epoch [37/150], Step [1601/5000], Loss = 0.0066\n",
      "Epoch [37/150], Step [1701/5000], Loss = 0.0082\n",
      "Epoch [37/150], Step [1801/5000], Loss = 0.0110\n",
      "Epoch [37/150], Step [1901/5000], Loss = 0.0023\n",
      "Epoch [37/150], Step [2001/5000], Loss = 0.0007\n",
      "Epoch [37/150], Step [2101/5000], Loss = 0.0310\n",
      "Epoch [37/150], Step [2201/5000], Loss = 0.0003\n",
      "Epoch [37/150], Step [2301/5000], Loss = 0.0123\n",
      "Epoch [37/150], Step [2401/5000], Loss = 0.0023\n",
      "Epoch [37/150], Step [2501/5000], Loss = 0.0685\n",
      "Epoch [37/150], Step [2601/5000], Loss = 0.0148\n",
      "Epoch [37/150], Step [2701/5000], Loss = 0.0007\n",
      "Epoch [37/150], Step [2801/5000], Loss = 0.0159\n",
      "Epoch [37/150], Step [2901/5000], Loss = 0.0037\n",
      "Epoch [37/150], Step [3001/5000], Loss = 0.0545\n",
      "Epoch [37/150], Step [3101/5000], Loss = 0.0705\n",
      "Epoch [37/150], Step [3201/5000], Loss = 0.0186\n",
      "Epoch [37/150], Step [3301/5000], Loss = 0.2434\n",
      "Epoch [37/150], Step [3401/5000], Loss = 0.0756\n",
      "Epoch [37/150], Step [3501/5000], Loss = 0.0022\n",
      "Epoch [37/150], Step [3601/5000], Loss = 0.0003\n",
      "Epoch [37/150], Step [3701/5000], Loss = 0.0311\n",
      "Epoch [37/150], Step [3801/5000], Loss = 0.0005\n",
      "Epoch [37/150], Step [3901/5000], Loss = 0.2064\n",
      "Epoch [37/150], Step [4001/5000], Loss = 0.0015\n",
      "Epoch [37/150], Step [4101/5000], Loss = 0.0042\n",
      "Epoch [37/150], Step [4201/5000], Loss = 0.0001\n",
      "Epoch [37/150], Step [4301/5000], Loss = 0.0019\n",
      "Epoch [37/150], Step [4401/5000], Loss = 0.0213\n",
      "Epoch [37/150], Step [4501/5000], Loss = 0.1578\n",
      "Epoch [37/150], Step [4601/5000], Loss = 0.0047\n",
      "Epoch [37/150], Step [4701/5000], Loss = 0.0126\n",
      "Epoch [37/150], Step [4801/5000], Loss = 0.0063\n",
      "Epoch [37/150], Step [4901/5000], Loss = 0.0073\n",
      "Epoch [37/150], Acc = 50.0000\n",
      "Epoch [38/150], Step [1/5000], Loss = 0.0150\n",
      "Epoch [38/150], Step [101/5000], Loss = 0.0013\n",
      "Epoch [38/150], Step [201/5000], Loss = 0.0047\n",
      "Epoch [38/150], Step [301/5000], Loss = 0.0023\n",
      "Epoch [38/150], Step [401/5000], Loss = 0.0391\n",
      "Epoch [38/150], Step [501/5000], Loss = 0.0011\n",
      "Epoch [38/150], Step [601/5000], Loss = 0.1147\n",
      "Epoch [38/150], Step [701/5000], Loss = 0.0045\n",
      "Epoch [38/150], Step [801/5000], Loss = 0.0010\n",
      "Epoch [38/150], Step [901/5000], Loss = 0.0007\n",
      "Epoch [38/150], Step [1001/5000], Loss = 0.0025\n",
      "Epoch [38/150], Step [1101/5000], Loss = 0.0038\n",
      "Epoch [38/150], Step [1201/5000], Loss = 0.0043\n",
      "Epoch [38/150], Step [1301/5000], Loss = 0.0118\n",
      "Epoch [38/150], Step [1401/5000], Loss = 0.0789\n",
      "Epoch [38/150], Step [1501/5000], Loss = 0.0001\n",
      "Epoch [38/150], Step [1601/5000], Loss = 0.1862\n",
      "Epoch [38/150], Step [1701/5000], Loss = 0.1460\n",
      "Epoch [38/150], Step [1801/5000], Loss = 0.0154\n",
      "Epoch [38/150], Step [1901/5000], Loss = 0.0097\n",
      "Epoch [38/150], Step [2001/5000], Loss = 0.0001\n",
      "Epoch [38/150], Step [2101/5000], Loss = 0.0178\n",
      "Epoch [38/150], Step [2201/5000], Loss = 0.0002\n",
      "Epoch [38/150], Step [2301/5000], Loss = 0.4169\n",
      "Epoch [38/150], Step [2401/5000], Loss = 0.0825\n",
      "Epoch [38/150], Step [2501/5000], Loss = 0.0023\n",
      "Epoch [38/150], Step [2601/5000], Loss = 0.5079\n",
      "Epoch [38/150], Step [2701/5000], Loss = 0.0042\n",
      "Epoch [38/150], Step [2801/5000], Loss = 0.0001\n",
      "Epoch [38/150], Step [2901/5000], Loss = 0.0089\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [38/150], Step [3001/5000], Loss = 0.0022\n",
      "Epoch [38/150], Step [3101/5000], Loss = 0.0018\n",
      "Epoch [38/150], Step [3201/5000], Loss = 0.0126\n",
      "Epoch [38/150], Step [3301/5000], Loss = 0.0023\n",
      "Epoch [38/150], Step [3401/5000], Loss = 0.1032\n",
      "Epoch [38/150], Step [3501/5000], Loss = 0.0089\n",
      "Epoch [38/150], Step [3601/5000], Loss = 0.1881\n",
      "Epoch [38/150], Step [3701/5000], Loss = 0.0020\n",
      "Epoch [38/150], Step [3801/5000], Loss = 0.0005\n",
      "Epoch [38/150], Step [3901/5000], Loss = 0.0354\n",
      "Epoch [38/150], Step [4001/5000], Loss = 0.0007\n",
      "Epoch [38/150], Step [4101/5000], Loss = 0.0004\n",
      "Epoch [38/150], Step [4201/5000], Loss = 0.1726\n",
      "Epoch [38/150], Step [4301/5000], Loss = 0.0240\n",
      "Epoch [38/150], Step [4401/5000], Loss = 0.2254\n",
      "Epoch [38/150], Step [4501/5000], Loss = 0.0460\n",
      "Epoch [38/150], Step [4601/5000], Loss = 0.0028\n",
      "Epoch [38/150], Step [4701/5000], Loss = 0.0000\n",
      "Epoch [38/150], Step [4801/5000], Loss = 0.0008\n",
      "Epoch [38/150], Step [4901/5000], Loss = 0.5162\n",
      "Epoch [38/150], Acc = 60.0000\n",
      "Epoch [39/150], Step [1/5000], Loss = 0.0064\n",
      "Epoch [39/150], Step [101/5000], Loss = 0.0111\n",
      "Epoch [39/150], Step [201/5000], Loss = 0.0281\n",
      "Epoch [39/150], Step [301/5000], Loss = 0.0017\n",
      "Epoch [39/150], Step [401/5000], Loss = 0.0712\n",
      "Epoch [39/150], Step [501/5000], Loss = 0.0026\n",
      "Epoch [39/150], Step [601/5000], Loss = 0.0021\n",
      "Epoch [39/150], Step [701/5000], Loss = 0.0749\n",
      "Epoch [39/150], Step [801/5000], Loss = 0.0014\n",
      "Epoch [39/150], Step [901/5000], Loss = 0.1579\n",
      "Epoch [39/150], Step [1001/5000], Loss = 0.0689\n",
      "Epoch [39/150], Step [1101/5000], Loss = 0.0058\n",
      "Epoch [39/150], Step [1201/5000], Loss = 0.0382\n",
      "Epoch [39/150], Step [1301/5000], Loss = 0.0002\n",
      "Epoch [39/150], Step [1401/5000], Loss = 0.0795\n",
      "Epoch [39/150], Step [1501/5000], Loss = 0.0083\n",
      "Epoch [39/150], Step [1601/5000], Loss = 0.0009\n",
      "Epoch [39/150], Step [1701/5000], Loss = 0.0002\n",
      "Epoch [39/150], Step [1801/5000], Loss = 0.0051\n",
      "Epoch [39/150], Step [1901/5000], Loss = 0.0007\n",
      "Epoch [39/150], Step [2001/5000], Loss = 0.2357\n",
      "Epoch [39/150], Step [2101/5000], Loss = 0.4115\n",
      "Epoch [39/150], Step [2201/5000], Loss = 0.0109\n",
      "Epoch [39/150], Step [2301/5000], Loss = 0.0001\n",
      "Epoch [39/150], Step [2401/5000], Loss = 0.0008\n",
      "Epoch [39/150], Step [2501/5000], Loss = 0.0002\n",
      "Epoch [39/150], Step [2601/5000], Loss = 0.0035\n",
      "Epoch [39/150], Step [2701/5000], Loss = 0.0031\n",
      "Epoch [39/150], Step [2801/5000], Loss = 0.0148\n",
      "Epoch [39/150], Step [2901/5000], Loss = 0.0283\n",
      "Epoch [39/150], Step [3001/5000], Loss = 0.0011\n",
      "Epoch [39/150], Step [3101/5000], Loss = 0.0003\n",
      "Epoch [39/150], Step [3201/5000], Loss = 0.0072\n",
      "Epoch [39/150], Step [3301/5000], Loss = 0.0096\n",
      "Epoch [39/150], Step [3401/5000], Loss = 0.0316\n",
      "Epoch [39/150], Step [3501/5000], Loss = 0.0004\n",
      "Epoch [39/150], Step [3601/5000], Loss = 0.0131\n",
      "Epoch [39/150], Step [3701/5000], Loss = 0.0004\n",
      "Epoch [39/150], Step [3801/5000], Loss = 0.0013\n",
      "Epoch [39/150], Step [3901/5000], Loss = 0.0027\n",
      "Epoch [39/150], Step [4001/5000], Loss = 0.0015\n",
      "Epoch [39/150], Step [4101/5000], Loss = 0.0047\n",
      "Epoch [39/150], Step [4201/5000], Loss = 0.0113\n",
      "Epoch [39/150], Step [4301/5000], Loss = 0.0164\n",
      "Epoch [39/150], Step [4401/5000], Loss = 0.0005\n",
      "Epoch [39/150], Step [4501/5000], Loss = 0.2892\n",
      "Epoch [39/150], Step [4601/5000], Loss = 0.0083\n",
      "Epoch [39/150], Step [4701/5000], Loss = 0.0451\n",
      "Epoch [39/150], Step [4801/5000], Loss = 0.0038\n",
      "Epoch [39/150], Step [4901/5000], Loss = 0.0386\n",
      "Epoch [39/150], Acc = 60.0000\n",
      "Epoch [40/150], Step [1/5000], Loss = 0.0017\n",
      "Epoch [40/150], Step [101/5000], Loss = 0.0011\n",
      "Epoch [40/150], Step [201/5000], Loss = 0.0128\n",
      "Epoch [40/150], Step [301/5000], Loss = 0.0379\n",
      "Epoch [40/150], Step [401/5000], Loss = 0.0084\n",
      "Epoch [40/150], Step [501/5000], Loss = 0.0012\n",
      "Epoch [40/150], Step [601/5000], Loss = 0.0130\n",
      "Epoch [40/150], Step [701/5000], Loss = 0.0036\n",
      "Epoch [40/150], Step [801/5000], Loss = 0.0004\n",
      "Epoch [40/150], Step [901/5000], Loss = 0.0005\n",
      "Epoch [40/150], Step [1001/5000], Loss = 0.0173\n",
      "Epoch [40/150], Step [1101/5000], Loss = 0.1232\n",
      "Epoch [40/150], Step [1201/5000], Loss = 0.0044\n",
      "Epoch [40/150], Step [1301/5000], Loss = 0.0021\n",
      "Epoch [40/150], Step [1401/5000], Loss = 0.0498\n",
      "Epoch [40/150], Step [1501/5000], Loss = 0.1269\n",
      "Epoch [40/150], Step [1601/5000], Loss = 0.0019\n",
      "Epoch [40/150], Step [1701/5000], Loss = 0.0026\n",
      "Epoch [40/150], Step [1801/5000], Loss = 0.0060\n",
      "Epoch [40/150], Step [1901/5000], Loss = 0.0137\n",
      "Epoch [40/150], Step [2001/5000], Loss = 0.0120\n",
      "Epoch [40/150], Step [2101/5000], Loss = 0.0239\n",
      "Epoch [40/150], Step [2201/5000], Loss = 0.0000\n",
      "Epoch [40/150], Step [2301/5000], Loss = 0.0035\n",
      "Epoch [40/150], Step [2401/5000], Loss = 0.0041\n",
      "Epoch [40/150], Step [2501/5000], Loss = 0.0020\n",
      "Epoch [40/150], Step [2601/5000], Loss = 0.0003\n",
      "Epoch [40/150], Step [2701/5000], Loss = 0.0002\n",
      "Epoch [40/150], Step [2801/5000], Loss = 0.0053\n",
      "Epoch [40/150], Step [2901/5000], Loss = 0.0547\n",
      "Epoch [40/150], Step [3001/5000], Loss = 0.0028\n",
      "Epoch [40/150], Step [3101/5000], Loss = 0.0020\n",
      "Epoch [40/150], Step [3201/5000], Loss = 0.0207\n",
      "Epoch [40/150], Step [3301/5000], Loss = 0.0012\n",
      "Epoch [40/150], Step [3401/5000], Loss = 0.0032\n",
      "Epoch [40/150], Step [3501/5000], Loss = 0.0004\n",
      "Epoch [40/150], Step [3601/5000], Loss = 0.0514\n",
      "Epoch [40/150], Step [3701/5000], Loss = 0.0108\n",
      "Epoch [40/150], Step [3801/5000], Loss = 0.0015\n",
      "Epoch [40/150], Step [3901/5000], Loss = 0.0009\n",
      "Epoch [40/150], Step [4001/5000], Loss = 0.0263\n",
      "Epoch [40/150], Step [4101/5000], Loss = 0.0245\n",
      "Epoch [40/150], Step [4201/5000], Loss = 0.0006\n",
      "Epoch [40/150], Step [4301/5000], Loss = 0.0019\n",
      "Epoch [40/150], Step [4401/5000], Loss = 0.0010\n",
      "Epoch [40/150], Step [4501/5000], Loss = 0.0010\n",
      "Epoch [40/150], Step [4601/5000], Loss = 0.0002\n",
      "Epoch [40/150], Step [4701/5000], Loss = 0.0028\n",
      "Epoch [40/150], Step [4801/5000], Loss = 0.0199\n",
      "Epoch [40/150], Step [4901/5000], Loss = 0.0017\n",
      "Epoch [40/150], Acc = 60.0000\n",
      "Epoch [41/150], Step [1/5000], Loss = 0.0105\n",
      "Epoch [41/150], Step [101/5000], Loss = 0.0040\n",
      "Epoch [41/150], Step [201/5000], Loss = 0.0267\n",
      "Epoch [41/150], Step [301/5000], Loss = 0.0297\n",
      "Epoch [41/150], Step [401/5000], Loss = 0.0030\n",
      "Epoch [41/150], Step [501/5000], Loss = 0.0256\n",
      "Epoch [41/150], Step [601/5000], Loss = 0.3793\n",
      "Epoch [41/150], Step [701/5000], Loss = 0.0038\n",
      "Epoch [41/150], Step [801/5000], Loss = 0.1231\n",
      "Epoch [41/150], Step [901/5000], Loss = 0.0079\n",
      "Epoch [41/150], Step [1001/5000], Loss = 0.0004\n",
      "Epoch [41/150], Step [1101/5000], Loss = 0.0010\n",
      "Epoch [41/150], Step [1201/5000], Loss = 0.0050\n",
      "Epoch [41/150], Step [1301/5000], Loss = 0.3962\n",
      "Epoch [41/150], Step [1401/5000], Loss = 0.0106\n",
      "Epoch [41/150], Step [1501/5000], Loss = 0.0017\n",
      "Epoch [41/150], Step [1601/5000], Loss = 0.0509\n",
      "Epoch [41/150], Step [1701/5000], Loss = 0.0013\n",
      "Epoch [41/150], Step [1801/5000], Loss = 0.0074\n",
      "Epoch [41/150], Step [1901/5000], Loss = 0.0006\n",
      "Epoch [41/150], Step [2001/5000], Loss = 0.0174\n",
      "Epoch [41/150], Step [2101/5000], Loss = 0.0022\n",
      "Epoch [41/150], Step [2201/5000], Loss = 0.0063\n",
      "Epoch [41/150], Step [2301/5000], Loss = 0.0129\n",
      "Epoch [41/150], Step [2401/5000], Loss = 0.0043\n",
      "Epoch [41/150], Step [2501/5000], Loss = 0.0635\n",
      "Epoch [41/150], Step [2601/5000], Loss = 0.0497\n",
      "Epoch [41/150], Step [2701/5000], Loss = 0.0004\n",
      "Epoch [41/150], Step [2801/5000], Loss = 0.0018\n",
      "Epoch [41/150], Step [2901/5000], Loss = 0.0009\n",
      "Epoch [41/150], Step [3001/5000], Loss = 0.0425\n",
      "Epoch [41/150], Step [3101/5000], Loss = 0.2056\n",
      "Epoch [41/150], Step [3201/5000], Loss = 0.0003\n",
      "Epoch [41/150], Step [3301/5000], Loss = 0.0016\n",
      "Epoch [41/150], Step [3401/5000], Loss = 0.0063\n",
      "Epoch [41/150], Step [3501/5000], Loss = 0.0009\n",
      "Epoch [41/150], Step [3601/5000], Loss = 0.0007\n",
      "Epoch [41/150], Step [3701/5000], Loss = 0.0127\n",
      "Epoch [41/150], Step [3801/5000], Loss = 0.0058\n",
      "Epoch [41/150], Step [3901/5000], Loss = 0.0015\n",
      "Epoch [41/150], Step [4001/5000], Loss = 0.0026\n",
      "Epoch [41/150], Step [4101/5000], Loss = 0.0003\n",
      "Epoch [41/150], Step [4201/5000], Loss = 0.0018\n",
      "Epoch [41/150], Step [4301/5000], Loss = 0.0006\n",
      "Epoch [41/150], Step [4401/5000], Loss = 0.0986\n",
      "Epoch [41/150], Step [4501/5000], Loss = 0.0290\n",
      "Epoch [41/150], Step [4601/5000], Loss = 0.0021\n",
      "Epoch [41/150], Step [4701/5000], Loss = 0.0671\n",
      "Epoch [41/150], Step [4801/5000], Loss = 0.0042\n",
      "Epoch [41/150], Step [4901/5000], Loss = 0.0321\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [41/150], Acc = 70.0000\n",
      "Epoch [42/150], Step [1/5000], Loss = 0.0000\n",
      "Epoch [42/150], Step [101/5000], Loss = 0.0179\n",
      "Epoch [42/150], Step [201/5000], Loss = 0.0005\n",
      "Epoch [42/150], Step [301/5000], Loss = 0.0020\n",
      "Epoch [42/150], Step [401/5000], Loss = 0.0786\n",
      "Epoch [42/150], Step [501/5000], Loss = 0.0055\n",
      "Epoch [42/150], Step [601/5000], Loss = 0.1446\n",
      "Epoch [42/150], Step [701/5000], Loss = 0.0001\n",
      "Epoch [42/150], Step [801/5000], Loss = 0.0168\n",
      "Epoch [42/150], Step [901/5000], Loss = 0.0001\n",
      "Epoch [42/150], Step [1001/5000], Loss = 0.0024\n",
      "Epoch [42/150], Step [1101/5000], Loss = 0.0041\n",
      "Epoch [42/150], Step [1201/5000], Loss = 0.0248\n",
      "Epoch [42/150], Step [1301/5000], Loss = 0.0011\n",
      "Epoch [42/150], Step [1401/5000], Loss = 0.0708\n",
      "Epoch [42/150], Step [1501/5000], Loss = 0.0181\n",
      "Epoch [42/150], Step [1601/5000], Loss = 0.0075\n",
      "Epoch [42/150], Step [1701/5000], Loss = 0.0020\n",
      "Epoch [42/150], Step [1801/5000], Loss = 0.0030\n",
      "Epoch [42/150], Step [1901/5000], Loss = 0.0021\n",
      "Epoch [42/150], Step [2001/5000], Loss = 0.0002\n",
      "Epoch [42/150], Step [2101/5000], Loss = 0.0110\n",
      "Epoch [42/150], Step [2201/5000], Loss = 0.0037\n",
      "Epoch [42/150], Step [2301/5000], Loss = 0.0001\n",
      "Epoch [42/150], Step [2401/5000], Loss = 0.0017\n",
      "Epoch [42/150], Step [2501/5000], Loss = 0.0021\n",
      "Epoch [42/150], Step [2601/5000], Loss = 0.0321\n",
      "Epoch [42/150], Step [2701/5000], Loss = 0.1034\n",
      "Epoch [42/150], Step [2801/5000], Loss = 0.0020\n",
      "Epoch [42/150], Step [2901/5000], Loss = 0.0008\n",
      "Epoch [42/150], Step [3001/5000], Loss = 0.0050\n",
      "Epoch [42/150], Step [3101/5000], Loss = 0.0053\n",
      "Epoch [42/150], Step [3201/5000], Loss = 0.0024\n",
      "Epoch [42/150], Step [3301/5000], Loss = 0.0033\n",
      "Epoch [42/150], Step [3401/5000], Loss = 0.0224\n",
      "Epoch [42/150], Step [3501/5000], Loss = 0.0565\n",
      "Epoch [42/150], Step [3601/5000], Loss = 0.0209\n",
      "Epoch [42/150], Step [3701/5000], Loss = 0.0046\n",
      "Epoch [42/150], Step [3801/5000], Loss = 0.0001\n",
      "Epoch [42/150], Step [3901/5000], Loss = 0.0083\n",
      "Epoch [42/150], Step [4001/5000], Loss = 0.0078\n",
      "Epoch [42/150], Step [4101/5000], Loss = 0.0028\n",
      "Epoch [42/150], Step [4201/5000], Loss = 0.0010\n",
      "Epoch [42/150], Step [4301/5000], Loss = 0.0003\n",
      "Epoch [42/150], Step [4401/5000], Loss = 0.0004\n",
      "Epoch [42/150], Step [4501/5000], Loss = 0.0087\n",
      "Epoch [42/150], Step [4601/5000], Loss = 0.0339\n",
      "Epoch [42/150], Step [4701/5000], Loss = 0.0457\n",
      "Epoch [42/150], Step [4801/5000], Loss = 0.3777\n",
      "Epoch [42/150], Step [4901/5000], Loss = 0.0022\n",
      "Epoch [42/150], Acc = 40.0000\n",
      "Epoch [43/150], Step [1/5000], Loss = 0.0005\n",
      "Epoch [43/150], Step [101/5000], Loss = 0.0019\n",
      "Epoch [43/150], Step [201/5000], Loss = 0.0011\n",
      "Epoch [43/150], Step [301/5000], Loss = 0.3673\n",
      "Epoch [43/150], Step [401/5000], Loss = 0.0001\n",
      "Epoch [43/150], Step [501/5000], Loss = 0.0033\n",
      "Epoch [43/150], Step [601/5000], Loss = 0.0096\n",
      "Epoch [43/150], Step [701/5000], Loss = 0.0040\n",
      "Epoch [43/150], Step [801/5000], Loss = 0.0007\n",
      "Epoch [43/150], Step [901/5000], Loss = 0.0044\n",
      "Epoch [43/150], Step [1001/5000], Loss = 0.0138\n",
      "Epoch [43/150], Step [1101/5000], Loss = 0.0022\n",
      "Epoch [43/150], Step [1201/5000], Loss = 0.0189\n",
      "Epoch [43/150], Step [1301/5000], Loss = 0.0008\n",
      "Epoch [43/150], Step [1401/5000], Loss = 0.0024\n",
      "Epoch [43/150], Step [1501/5000], Loss = 0.0634\n",
      "Epoch [43/150], Step [1601/5000], Loss = 0.0002\n",
      "Epoch [43/150], Step [1701/5000], Loss = 0.0168\n",
      "Epoch [43/150], Step [1801/5000], Loss = 0.0009\n",
      "Epoch [43/150], Step [1901/5000], Loss = 0.0025\n",
      "Epoch [43/150], Step [2001/5000], Loss = 0.0398\n",
      "Epoch [43/150], Step [2101/5000], Loss = 0.0028\n",
      "Epoch [43/150], Step [2201/5000], Loss = 0.0002\n",
      "Epoch [43/150], Step [2301/5000], Loss = 0.0005\n",
      "Epoch [43/150], Step [2401/5000], Loss = 0.0335\n",
      "Epoch [43/150], Step [2501/5000], Loss = 0.0058\n",
      "Epoch [43/150], Step [2601/5000], Loss = 0.0006\n",
      "Epoch [43/150], Step [2701/5000], Loss = 0.0015\n",
      "Epoch [43/150], Step [2801/5000], Loss = 0.0010\n",
      "Epoch [43/150], Step [2901/5000], Loss = 0.0060\n",
      "Epoch [43/150], Step [3001/5000], Loss = 0.0004\n",
      "Epoch [43/150], Step [3101/5000], Loss = 0.0087\n",
      "Epoch [43/150], Step [3201/5000], Loss = 0.0004\n",
      "Epoch [43/150], Step [3301/5000], Loss = 0.0001\n",
      "Epoch [43/150], Step [3401/5000], Loss = 0.0004\n",
      "Epoch [43/150], Step [3501/5000], Loss = 0.0003\n",
      "Epoch [43/150], Step [3601/5000], Loss = 0.0011\n",
      "Epoch [43/150], Step [3701/5000], Loss = 0.0167\n",
      "Epoch [43/150], Step [3801/5000], Loss = 0.0058\n",
      "Epoch [43/150], Step [3901/5000], Loss = 0.0008\n",
      "Epoch [43/150], Step [4001/5000], Loss = 0.0121\n",
      "Epoch [43/150], Step [4101/5000], Loss = 0.0022\n",
      "Epoch [43/150], Step [4201/5000], Loss = 0.0000\n",
      "Epoch [43/150], Step [4301/5000], Loss = 0.0289\n",
      "Epoch [43/150], Step [4401/5000], Loss = 0.0004\n",
      "Epoch [43/150], Step [4501/5000], Loss = 0.0001\n",
      "Epoch [43/150], Step [4601/5000], Loss = 0.1121\n",
      "Epoch [43/150], Step [4701/5000], Loss = 0.0083\n",
      "Epoch [43/150], Step [4801/5000], Loss = 0.0000\n",
      "Epoch [43/150], Step [4901/5000], Loss = 0.0000\n",
      "Epoch [43/150], Acc = 60.0000\n",
      "Epoch [44/150], Step [1/5000], Loss = 0.0005\n",
      "Epoch [44/150], Step [101/5000], Loss = 0.0003\n",
      "Epoch [44/150], Step [201/5000], Loss = 0.0011\n",
      "Epoch [44/150], Step [301/5000], Loss = 0.0088\n",
      "Epoch [44/150], Step [401/5000], Loss = 0.0005\n",
      "Epoch [44/150], Step [501/5000], Loss = 0.0036\n",
      "Epoch [44/150], Step [601/5000], Loss = 0.0002\n",
      "Epoch [44/150], Step [701/5000], Loss = 0.1699\n",
      "Epoch [44/150], Step [801/5000], Loss = 0.0040\n",
      "Epoch [44/150], Step [901/5000], Loss = 0.0563\n",
      "Epoch [44/150], Step [1001/5000], Loss = 0.1029\n",
      "Epoch [44/150], Step [1101/5000], Loss = 0.0015\n",
      "Epoch [44/150], Step [1201/5000], Loss = 0.0000\n",
      "Epoch [44/150], Step [1301/5000], Loss = 0.0003\n",
      "Epoch [44/150], Step [1401/5000], Loss = 0.0916\n",
      "Epoch [44/150], Step [1501/5000], Loss = 0.0000\n",
      "Epoch [44/150], Step [1601/5000], Loss = 0.0004\n",
      "Epoch [44/150], Step [1701/5000], Loss = 0.3742\n",
      "Epoch [44/150], Step [1801/5000], Loss = 0.0338\n",
      "Epoch [44/150], Step [1901/5000], Loss = 0.0328\n",
      "Epoch [44/150], Step [2001/5000], Loss = 0.0004\n",
      "Epoch [44/150], Step [2101/5000], Loss = 0.0004\n",
      "Epoch [44/150], Step [2201/5000], Loss = 0.0042\n",
      "Epoch [44/150], Step [2301/5000], Loss = 0.2355\n",
      "Epoch [44/150], Step [2401/5000], Loss = 0.0256\n",
      "Epoch [44/150], Step [2501/5000], Loss = 0.0005\n",
      "Epoch [44/150], Step [2601/5000], Loss = 0.0200\n",
      "Epoch [44/150], Step [2701/5000], Loss = 0.0215\n",
      "Epoch [44/150], Step [2801/5000], Loss = 0.0891\n",
      "Epoch [44/150], Step [2901/5000], Loss = 0.0005\n",
      "Epoch [44/150], Step [3001/5000], Loss = 0.0013\n",
      "Epoch [44/150], Step [3101/5000], Loss = 0.0013\n",
      "Epoch [44/150], Step [3201/5000], Loss = 0.0063\n",
      "Epoch [44/150], Step [3301/5000], Loss = 0.0009\n",
      "Epoch [44/150], Step [3401/5000], Loss = 0.0730\n",
      "Epoch [44/150], Step [3501/5000], Loss = 0.0022\n",
      "Epoch [44/150], Step [3601/5000], Loss = 0.0001\n",
      "Epoch [44/150], Step [3701/5000], Loss = 0.0000\n",
      "Epoch [44/150], Step [3801/5000], Loss = 0.0748\n",
      "Epoch [44/150], Step [3901/5000], Loss = 0.0011\n",
      "Epoch [44/150], Step [4001/5000], Loss = 0.0049\n",
      "Epoch [44/150], Step [4101/5000], Loss = 0.0247\n",
      "Epoch [44/150], Step [4201/5000], Loss = 0.0265\n",
      "Epoch [44/150], Step [4301/5000], Loss = 0.0073\n",
      "Epoch [44/150], Step [4401/5000], Loss = 0.0383\n",
      "Epoch [44/150], Step [4501/5000], Loss = 0.0005\n",
      "Epoch [44/150], Step [4601/5000], Loss = 0.1142\n",
      "Epoch [44/150], Step [4701/5000], Loss = 0.0005\n",
      "Epoch [44/150], Step [4801/5000], Loss = 0.0016\n",
      "Epoch [44/150], Step [4901/5000], Loss = 0.0001\n",
      "Epoch [44/150], Acc = 60.0000\n",
      "Epoch [45/150], Step [1/5000], Loss = 0.0454\n",
      "Epoch [45/150], Step [101/5000], Loss = 0.0000\n",
      "Epoch [45/150], Step [201/5000], Loss = 0.0007\n",
      "Epoch [45/150], Step [301/5000], Loss = 0.0199\n",
      "Epoch [45/150], Step [401/5000], Loss = 0.0000\n",
      "Epoch [45/150], Step [501/5000], Loss = 0.0378\n",
      "Epoch [45/150], Step [601/5000], Loss = 0.0001\n",
      "Epoch [45/150], Step [701/5000], Loss = 0.0033\n",
      "Epoch [45/150], Step [801/5000], Loss = 0.0037\n",
      "Epoch [45/150], Step [901/5000], Loss = 0.0005\n",
      "Epoch [45/150], Step [1001/5000], Loss = 0.0499\n",
      "Epoch [45/150], Step [1101/5000], Loss = 0.0002\n",
      "Epoch [45/150], Step [1201/5000], Loss = 0.0015\n",
      "Epoch [45/150], Step [1301/5000], Loss = 0.0110\n",
      "Epoch [45/150], Step [1401/5000], Loss = 0.0000\n",
      "Epoch [45/150], Step [1501/5000], Loss = 0.0220\n",
      "Epoch [45/150], Step [1601/5000], Loss = 0.0031\n",
      "Epoch [45/150], Step [1701/5000], Loss = 0.0045\n",
      "Epoch [45/150], Step [1801/5000], Loss = 0.0551\n",
      "Epoch [45/150], Step [1901/5000], Loss = 0.0038\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [45/150], Step [2001/5000], Loss = 0.0003\n",
      "Epoch [45/150], Step [2101/5000], Loss = 0.0035\n",
      "Epoch [45/150], Step [2201/5000], Loss = 0.0009\n",
      "Epoch [45/150], Step [2301/5000], Loss = 0.0107\n",
      "Epoch [45/150], Step [2401/5000], Loss = 0.0006\n",
      "Epoch [45/150], Step [2501/5000], Loss = 0.0009\n",
      "Epoch [45/150], Step [2601/5000], Loss = 0.0010\n",
      "Epoch [45/150], Step [2701/5000], Loss = 0.0057\n",
      "Epoch [45/150], Step [2801/5000], Loss = 0.0004\n",
      "Epoch [45/150], Step [2901/5000], Loss = 0.0032\n",
      "Epoch [45/150], Step [3001/5000], Loss = 0.0002\n",
      "Epoch [45/150], Step [3101/5000], Loss = 0.0006\n",
      "Epoch [45/150], Step [3201/5000], Loss = 0.0041\n",
      "Epoch [45/150], Step [3301/5000], Loss = 0.0000\n",
      "Epoch [45/150], Step [3401/5000], Loss = 0.0025\n",
      "Epoch [45/150], Step [3501/5000], Loss = 0.0000\n",
      "Epoch [45/150], Step [3601/5000], Loss = 0.0004\n",
      "Epoch [45/150], Step [3701/5000], Loss = 0.0004\n",
      "Epoch [45/150], Step [3801/5000], Loss = 0.0387\n",
      "Epoch [45/150], Step [3901/5000], Loss = 0.0049\n",
      "Epoch [45/150], Step [4001/5000], Loss = 0.0088\n",
      "Epoch [45/150], Step [4101/5000], Loss = 0.0851\n",
      "Epoch [45/150], Step [4201/5000], Loss = 0.0006\n",
      "Epoch [45/150], Step [4301/5000], Loss = 0.0021\n",
      "Epoch [45/150], Step [4401/5000], Loss = 0.2852\n",
      "Epoch [45/150], Step [4501/5000], Loss = 0.0071\n",
      "Epoch [45/150], Step [4601/5000], Loss = 0.0001\n",
      "Epoch [45/150], Step [4701/5000], Loss = 0.0101\n",
      "Epoch [45/150], Step [4801/5000], Loss = 0.0059\n",
      "Epoch [45/150], Step [4901/5000], Loss = 0.0378\n",
      "Epoch [45/150], Acc = 40.0000\n",
      "Epoch [46/150], Step [1/5000], Loss = 0.0010\n",
      "Epoch [46/150], Step [101/5000], Loss = 0.0015\n",
      "Epoch [46/150], Step [201/5000], Loss = 0.0719\n",
      "Epoch [46/150], Step [301/5000], Loss = 0.0051\n",
      "Epoch [46/150], Step [401/5000], Loss = 0.0027\n",
      "Epoch [46/150], Step [501/5000], Loss = 0.0001\n",
      "Epoch [46/150], Step [601/5000], Loss = 0.0001\n",
      "Epoch [46/150], Step [701/5000], Loss = 0.3227\n",
      "Epoch [46/150], Step [801/5000], Loss = 0.0001\n",
      "Epoch [46/150], Step [901/5000], Loss = 0.0038\n",
      "Epoch [46/150], Step [1001/5000], Loss = 0.0002\n",
      "Epoch [46/150], Step [1101/5000], Loss = 0.6224\n",
      "Epoch [46/150], Step [1201/5000], Loss = 0.2973\n",
      "Epoch [46/150], Step [1301/5000], Loss = 0.0010\n",
      "Epoch [46/150], Step [1401/5000], Loss = 0.0000\n",
      "Epoch [46/150], Step [1501/5000], Loss = 0.0031\n",
      "Epoch [46/150], Step [1601/5000], Loss = 0.0003\n",
      "Epoch [46/150], Step [1701/5000], Loss = 0.0042\n",
      "Epoch [46/150], Step [1801/5000], Loss = 0.0001\n",
      "Epoch [46/150], Step [1901/5000], Loss = 0.0001\n",
      "Epoch [46/150], Step [2001/5000], Loss = 0.0205\n",
      "Epoch [46/150], Step [2101/5000], Loss = 0.0346\n",
      "Epoch [46/150], Step [2201/5000], Loss = 0.0010\n",
      "Epoch [46/150], Step [2301/5000], Loss = 0.0156\n",
      "Epoch [46/150], Step [2401/5000], Loss = 0.3309\n",
      "Epoch [46/150], Step [2501/5000], Loss = 0.0082\n",
      "Epoch [46/150], Step [2601/5000], Loss = 0.0001\n",
      "Epoch [46/150], Step [2701/5000], Loss = 0.0005\n",
      "Epoch [46/150], Step [2801/5000], Loss = 0.0083\n",
      "Epoch [46/150], Step [2901/5000], Loss = 0.0105\n",
      "Epoch [46/150], Step [3001/5000], Loss = 0.0188\n",
      "Epoch [46/150], Step [3101/5000], Loss = 0.2182\n",
      "Epoch [46/150], Step [3201/5000], Loss = 0.1150\n",
      "Epoch [46/150], Step [3301/5000], Loss = 0.1255\n",
      "Epoch [46/150], Step [3401/5000], Loss = 0.0010\n",
      "Epoch [46/150], Step [3501/5000], Loss = 0.0043\n",
      "Epoch [46/150], Step [3601/5000], Loss = 0.0530\n",
      "Epoch [46/150], Step [3701/5000], Loss = 0.0005\n",
      "Epoch [46/150], Step [3801/5000], Loss = 0.0008\n",
      "Epoch [46/150], Step [3901/5000], Loss = 0.0023\n",
      "Epoch [46/150], Step [4001/5000], Loss = 0.0018\n",
      "Epoch [46/150], Step [4101/5000], Loss = 0.0000\n",
      "Epoch [46/150], Step [4201/5000], Loss = 0.0012\n",
      "Epoch [46/150], Step [4301/5000], Loss = 0.0857\n",
      "Epoch [46/150], Step [4401/5000], Loss = 0.0002\n",
      "Epoch [46/150], Step [4501/5000], Loss = 0.0032\n",
      "Epoch [46/150], Step [4601/5000], Loss = 0.0033\n",
      "Epoch [46/150], Step [4701/5000], Loss = 0.0004\n",
      "Epoch [46/150], Step [4801/5000], Loss = 0.0121\n",
      "Epoch [46/150], Step [4901/5000], Loss = 0.0074\n",
      "Epoch [46/150], Acc = 70.0000\n",
      "Epoch [47/150], Step [1/5000], Loss = 0.0002\n",
      "Epoch [47/150], Step [101/5000], Loss = 0.0032\n",
      "Epoch [47/150], Step [201/5000], Loss = 0.0082\n",
      "Epoch [47/150], Step [301/5000], Loss = 0.0001\n",
      "Epoch [47/150], Step [401/5000], Loss = 0.0001\n",
      "Epoch [47/150], Step [501/5000], Loss = 0.0234\n",
      "Epoch [47/150], Step [601/5000], Loss = 0.0005\n",
      "Epoch [47/150], Step [701/5000], Loss = 0.0019\n",
      "Epoch [47/150], Step [801/5000], Loss = 0.0784\n",
      "Epoch [47/150], Step [901/5000], Loss = 0.0003\n",
      "Epoch [47/150], Step [1001/5000], Loss = 0.0045\n",
      "Epoch [47/150], Step [1101/5000], Loss = 0.0003\n",
      "Epoch [47/150], Step [1201/5000], Loss = 0.0106\n",
      "Epoch [47/150], Step [1301/5000], Loss = 0.0029\n",
      "Epoch [47/150], Step [1401/5000], Loss = 0.0030\n",
      "Epoch [47/150], Step [1501/5000], Loss = 0.0042\n",
      "Epoch [47/150], Step [1601/5000], Loss = 0.0002\n",
      "Epoch [47/150], Step [1701/5000], Loss = 0.0004\n",
      "Epoch [47/150], Step [1801/5000], Loss = 0.0855\n",
      "Epoch [47/150], Step [1901/5000], Loss = 0.0069\n",
      "Epoch [47/150], Step [2001/5000], Loss = 0.0166\n",
      "Epoch [47/150], Step [2101/5000], Loss = 0.0968\n",
      "Epoch [47/150], Step [2201/5000], Loss = 0.0028\n",
      "Epoch [47/150], Step [2301/5000], Loss = 0.0001\n",
      "Epoch [47/150], Step [2401/5000], Loss = 0.0655\n",
      "Epoch [47/150], Step [2501/5000], Loss = 0.0004\n",
      "Epoch [47/150], Step [2601/5000], Loss = 0.0011\n",
      "Epoch [47/150], Step [2701/5000], Loss = 0.0468\n",
      "Epoch [47/150], Step [2801/5000], Loss = 0.2368\n",
      "Epoch [47/150], Step [2901/5000], Loss = 0.0065\n",
      "Epoch [47/150], Step [3001/5000], Loss = 0.0012\n",
      "Epoch [47/150], Step [3101/5000], Loss = 0.0003\n",
      "Epoch [47/150], Step [3201/5000], Loss = 0.0041\n",
      "Epoch [47/150], Step [3301/5000], Loss = 0.0040\n",
      "Epoch [47/150], Step [3401/5000], Loss = 0.0014\n",
      "Epoch [47/150], Step [3501/5000], Loss = 0.0105\n",
      "Epoch [47/150], Step [3601/5000], Loss = 0.0092\n",
      "Epoch [47/150], Step [3701/5000], Loss = 0.0406\n",
      "Epoch [47/150], Step [3801/5000], Loss = 0.0004\n",
      "Epoch [47/150], Step [3901/5000], Loss = 0.0027\n",
      "Epoch [47/150], Step [4001/5000], Loss = 0.0002\n",
      "Epoch [47/150], Step [4101/5000], Loss = 0.0001\n",
      "Epoch [47/150], Step [4201/5000], Loss = 0.0001\n",
      "Epoch [47/150], Step [4301/5000], Loss = 0.0204\n",
      "Epoch [47/150], Step [4401/5000], Loss = 0.0006\n",
      "Epoch [47/150], Step [4501/5000], Loss = 0.0070\n",
      "Epoch [47/150], Step [4601/5000], Loss = 0.0002\n",
      "Epoch [47/150], Step [4701/5000], Loss = 0.0054\n",
      "Epoch [47/150], Step [4801/5000], Loss = 0.0011\n",
      "Epoch [47/150], Step [4901/5000], Loss = 0.0013\n",
      "Epoch [47/150], Acc = 80.0000\n",
      "Epoch [48/150], Step [1/5000], Loss = 0.0002\n",
      "Epoch [48/150], Step [101/5000], Loss = 0.0000\n",
      "Epoch [48/150], Step [201/5000], Loss = 0.0014\n",
      "Epoch [48/150], Step [301/5000], Loss = 0.0005\n",
      "Epoch [48/150], Step [401/5000], Loss = 0.0002\n",
      "Epoch [48/150], Step [501/5000], Loss = 0.0013\n",
      "Epoch [48/150], Step [601/5000], Loss = 0.0006\n",
      "Epoch [48/150], Step [701/5000], Loss = 0.0019\n",
      "Epoch [48/150], Step [801/5000], Loss = 0.0010\n",
      "Epoch [48/150], Step [901/5000], Loss = 0.0006\n",
      "Epoch [48/150], Step [1001/5000], Loss = 0.0130\n",
      "Epoch [48/150], Step [1101/5000], Loss = 0.0038\n",
      "Epoch [48/150], Step [1201/5000], Loss = 0.0001\n",
      "Epoch [48/150], Step [1301/5000], Loss = 0.0008\n",
      "Epoch [48/150], Step [1401/5000], Loss = 0.0000\n",
      "Epoch [48/150], Step [1501/5000], Loss = 0.0111\n",
      "Epoch [48/150], Step [1601/5000], Loss = 0.0279\n",
      "Epoch [48/150], Step [1701/5000], Loss = 0.0011\n",
      "Epoch [48/150], Step [1801/5000], Loss = 0.0005\n",
      "Epoch [48/150], Step [1901/5000], Loss = 0.0065\n",
      "Epoch [48/150], Step [2001/5000], Loss = 0.0174\n",
      "Epoch [48/150], Step [2101/5000], Loss = 0.0000\n",
      "Epoch [48/150], Step [2201/5000], Loss = 0.0247\n",
      "Epoch [48/150], Step [2301/5000], Loss = 0.0001\n",
      "Epoch [48/150], Step [2401/5000], Loss = 0.0017\n",
      "Epoch [48/150], Step [2501/5000], Loss = 0.0013\n",
      "Epoch [48/150], Step [2601/5000], Loss = 0.0042\n",
      "Epoch [48/150], Step [2701/5000], Loss = 0.0000\n",
      "Epoch [48/150], Step [2801/5000], Loss = 0.0027\n",
      "Epoch [48/150], Step [2901/5000], Loss = 0.1324\n",
      "Epoch [48/150], Step [3001/5000], Loss = 0.0097\n",
      "Epoch [48/150], Step [3101/5000], Loss = 0.4786\n",
      "Epoch [48/150], Step [3201/5000], Loss = 0.0005\n",
      "Epoch [48/150], Step [3301/5000], Loss = 0.0052\n",
      "Epoch [48/150], Step [3401/5000], Loss = 0.0005\n",
      "Epoch [48/150], Step [3501/5000], Loss = 0.0004\n",
      "Epoch [48/150], Step [3601/5000], Loss = 0.0107\n",
      "Epoch [48/150], Step [3701/5000], Loss = 0.0029\n",
      "Epoch [48/150], Step [3801/5000], Loss = 0.0002\n",
      "Epoch [48/150], Step [3901/5000], Loss = 0.0007\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [48/150], Step [4001/5000], Loss = 0.0019\n",
      "Epoch [48/150], Step [4101/5000], Loss = 0.0010\n",
      "Epoch [48/150], Step [4201/5000], Loss = 0.0014\n",
      "Epoch [48/150], Step [4301/5000], Loss = 0.0036\n",
      "Epoch [48/150], Step [4401/5000], Loss = 0.0054\n",
      "Epoch [48/150], Step [4501/5000], Loss = 0.0012\n",
      "Epoch [48/150], Step [4601/5000], Loss = 0.0013\n",
      "Epoch [48/150], Step [4701/5000], Loss = 0.0146\n",
      "Epoch [48/150], Step [4801/5000], Loss = 0.0007\n",
      "Epoch [48/150], Step [4901/5000], Loss = 0.0041\n",
      "Epoch [48/150], Acc = 60.0000\n",
      "Epoch [49/150], Step [1/5000], Loss = 0.0062\n",
      "Epoch [49/150], Step [101/5000], Loss = 0.0002\n",
      "Epoch [49/150], Step [201/5000], Loss = 0.0031\n",
      "Epoch [49/150], Step [301/5000], Loss = 0.0046\n",
      "Epoch [49/150], Step [401/5000], Loss = 0.0018\n",
      "Epoch [49/150], Step [501/5000], Loss = 0.0021\n",
      "Epoch [49/150], Step [601/5000], Loss = 0.0063\n",
      "Epoch [49/150], Step [701/5000], Loss = 0.0006\n",
      "Epoch [49/150], Step [801/5000], Loss = 0.2104\n",
      "Epoch [49/150], Step [901/5000], Loss = 0.0010\n",
      "Epoch [49/150], Step [1001/5000], Loss = 0.0111\n",
      "Epoch [49/150], Step [1101/5000], Loss = 0.0019\n",
      "Epoch [49/150], Step [1201/5000], Loss = 0.0035\n",
      "Epoch [49/150], Step [1301/5000], Loss = 0.0209\n",
      "Epoch [49/150], Step [1401/5000], Loss = 0.0009\n",
      "Epoch [49/150], Step [1501/5000], Loss = 0.0011\n",
      "Epoch [49/150], Step [1601/5000], Loss = 0.0011\n",
      "Epoch [49/150], Step [1701/5000], Loss = 0.0003\n",
      "Epoch [49/150], Step [1801/5000], Loss = 0.0017\n",
      "Epoch [49/150], Step [1901/5000], Loss = 0.2309\n",
      "Epoch [49/150], Step [2001/5000], Loss = 0.0009\n",
      "Epoch [49/150], Step [2101/5000], Loss = 0.0002\n",
      "Epoch [49/150], Step [2201/5000], Loss = 0.0018\n",
      "Epoch [49/150], Step [2301/5000], Loss = 0.0023\n",
      "Epoch [49/150], Step [2401/5000], Loss = 0.4005\n",
      "Epoch [49/150], Step [2501/5000], Loss = 0.0001\n",
      "Epoch [49/150], Step [2601/5000], Loss = 0.0004\n",
      "Epoch [49/150], Step [2701/5000], Loss = 0.0152\n",
      "Epoch [49/150], Step [2801/5000], Loss = 0.0168\n",
      "Epoch [49/150], Step [2901/5000], Loss = 0.0039\n",
      "Epoch [49/150], Step [3001/5000], Loss = 0.0117\n",
      "Epoch [49/150], Step [3101/5000], Loss = 0.0000\n",
      "Epoch [49/150], Step [3201/5000], Loss = 0.0477\n",
      "Epoch [49/150], Step [3301/5000], Loss = 0.0042\n",
      "Epoch [49/150], Step [3401/5000], Loss = 0.0007\n",
      "Epoch [49/150], Step [3501/5000], Loss = 0.0003\n",
      "Epoch [49/150], Step [3601/5000], Loss = 0.0002\n",
      "Epoch [49/150], Step [3701/5000], Loss = 0.0058\n",
      "Epoch [49/150], Step [3801/5000], Loss = 0.0004\n",
      "Epoch [49/150], Step [3901/5000], Loss = 0.0021\n",
      "Epoch [49/150], Step [4001/5000], Loss = 0.0000\n",
      "Epoch [49/150], Step [4101/5000], Loss = 0.0016\n",
      "Epoch [49/150], Step [4201/5000], Loss = 0.0396\n",
      "Epoch [49/150], Step [4301/5000], Loss = 0.0011\n",
      "Epoch [49/150], Step [4401/5000], Loss = 0.0097\n",
      "Epoch [49/150], Step [4501/5000], Loss = 0.0001\n",
      "Epoch [49/150], Step [4601/5000], Loss = 0.0007\n",
      "Epoch [49/150], Step [4701/5000], Loss = 0.1485\n",
      "Epoch [49/150], Step [4801/5000], Loss = 0.0034\n",
      "Epoch [49/150], Step [4901/5000], Loss = 0.0002\n",
      "Epoch [49/150], Acc = 70.0000\n",
      "Epoch [50/150], Step [1/5000], Loss = 0.0001\n",
      "Epoch [50/150], Step [101/5000], Loss = 0.0058\n",
      "Epoch [50/150], Step [201/5000], Loss = 0.0013\n",
      "Epoch [50/150], Step [301/5000], Loss = 0.0029\n",
      "Epoch [50/150], Step [401/5000], Loss = 0.0331\n",
      "Epoch [50/150], Step [501/5000], Loss = 0.0207\n",
      "Epoch [50/150], Step [601/5000], Loss = 0.0047\n",
      "Epoch [50/150], Step [701/5000], Loss = 0.0006\n",
      "Epoch [50/150], Step [801/5000], Loss = 0.0102\n",
      "Epoch [50/150], Step [901/5000], Loss = 0.0006\n",
      "Epoch [50/150], Step [1001/5000], Loss = 0.0001\n",
      "Epoch [50/150], Step [1101/5000], Loss = 0.0000\n",
      "Epoch [50/150], Step [1201/5000], Loss = 0.0111\n",
      "Epoch [50/150], Step [1301/5000], Loss = 0.0025\n",
      "Epoch [50/150], Step [1401/5000], Loss = 0.0053\n",
      "Epoch [50/150], Step [1501/5000], Loss = 0.0029\n",
      "Epoch [50/150], Step [1601/5000], Loss = 0.0109\n",
      "Epoch [50/150], Step [1701/5000], Loss = 0.0011\n",
      "Epoch [50/150], Step [1801/5000], Loss = 0.3357\n",
      "Epoch [50/150], Step [1901/5000], Loss = 0.0000\n",
      "Epoch [50/150], Step [2001/5000], Loss = 0.0003\n",
      "Epoch [50/150], Step [2101/5000], Loss = 0.0671\n",
      "Epoch [50/150], Step [2201/5000], Loss = 0.0000\n",
      "Epoch [50/150], Step [2301/5000], Loss = 0.0095\n",
      "Epoch [50/150], Step [2401/5000], Loss = 0.0005\n",
      "Epoch [50/150], Step [2501/5000], Loss = 0.0173\n",
      "Epoch [50/150], Step [2601/5000], Loss = 0.0046\n",
      "Epoch [50/150], Step [2701/5000], Loss = 0.0460\n",
      "Epoch [50/150], Step [2801/5000], Loss = 0.0004\n",
      "Epoch [50/150], Step [2901/5000], Loss = 0.0105\n",
      "Epoch [50/150], Step [3001/5000], Loss = 0.0010\n",
      "Epoch [50/150], Step [3101/5000], Loss = 0.0024\n",
      "Epoch [50/150], Step [3201/5000], Loss = 0.3257\n",
      "Epoch [50/150], Step [3301/5000], Loss = 0.0003\n",
      "Epoch [50/150], Step [3401/5000], Loss = 0.3267\n",
      "Epoch [50/150], Step [3501/5000], Loss = 0.0005\n",
      "Epoch [50/150], Step [3601/5000], Loss = 0.0324\n",
      "Epoch [50/150], Step [3701/5000], Loss = 0.0591\n",
      "Epoch [50/150], Step [3801/5000], Loss = 0.0002\n",
      "Epoch [50/150], Step [3901/5000], Loss = 0.0003\n",
      "Epoch [50/150], Step [4001/5000], Loss = 0.0002\n",
      "Epoch [50/150], Step [4101/5000], Loss = 0.0003\n",
      "Epoch [50/150], Step [4201/5000], Loss = 0.0301\n",
      "Epoch [50/150], Step [4301/5000], Loss = 0.0085\n",
      "Epoch [50/150], Step [4401/5000], Loss = 0.4532\n",
      "Epoch [50/150], Step [4501/5000], Loss = 0.0013\n",
      "Epoch [50/150], Step [4601/5000], Loss = 0.0002\n",
      "Epoch [50/150], Step [4701/5000], Loss = 0.0043\n",
      "Epoch [50/150], Step [4801/5000], Loss = 0.0008\n",
      "Epoch [50/150], Step [4901/5000], Loss = 0.0039\n",
      "Epoch [50/150], Acc = 70.0000\n",
      "Epoch [51/150], Step [1/5000], Loss = 0.0002\n",
      "Epoch [51/150], Step [101/5000], Loss = 0.0002\n",
      "Epoch [51/150], Step [201/5000], Loss = 0.0000\n",
      "Epoch [51/150], Step [301/5000], Loss = 0.0010\n",
      "Epoch [51/150], Step [401/5000], Loss = 0.0059\n",
      "Epoch [51/150], Step [501/5000], Loss = 0.0719\n",
      "Epoch [51/150], Step [601/5000], Loss = 0.0031\n",
      "Epoch [51/150], Step [701/5000], Loss = 0.0005\n",
      "Epoch [51/150], Step [801/5000], Loss = 0.0105\n",
      "Epoch [51/150], Step [901/5000], Loss = 0.0003\n",
      "Epoch [51/150], Step [1001/5000], Loss = 0.0005\n",
      "Epoch [51/150], Step [1101/5000], Loss = 0.0020\n",
      "Epoch [51/150], Step [1201/5000], Loss = 0.0005\n",
      "Epoch [51/150], Step [1301/5000], Loss = 0.0002\n",
      "Epoch [51/150], Step [1401/5000], Loss = 0.0004\n",
      "Epoch [51/150], Step [1501/5000], Loss = 0.0000\n",
      "Epoch [51/150], Step [1601/5000], Loss = 0.0009\n",
      "Epoch [51/150], Step [1701/5000], Loss = 0.0029\n",
      "Epoch [51/150], Step [1801/5000], Loss = 0.0168\n",
      "Epoch [51/150], Step [1901/5000], Loss = 0.0007\n",
      "Epoch [51/150], Step [2001/5000], Loss = 0.0001\n",
      "Epoch [51/150], Step [2101/5000], Loss = 0.0012\n",
      "Epoch [51/150], Step [2201/5000], Loss = 0.0870\n",
      "Epoch [51/150], Step [2301/5000], Loss = 0.0017\n",
      "Epoch [51/150], Step [2401/5000], Loss = 0.0002\n",
      "Epoch [51/150], Step [2501/5000], Loss = 0.0018\n",
      "Epoch [51/150], Step [2601/5000], Loss = 0.0005\n",
      "Epoch [51/150], Step [2701/5000], Loss = 0.1839\n",
      "Epoch [51/150], Step [2801/5000], Loss = 0.0224\n",
      "Epoch [51/150], Step [2901/5000], Loss = 0.0002\n",
      "Epoch [51/150], Step [3001/5000], Loss = 0.0556\n",
      "Epoch [51/150], Step [3101/5000], Loss = 0.0002\n",
      "Epoch [51/150], Step [3201/5000], Loss = 0.0096\n",
      "Epoch [51/150], Step [3301/5000], Loss = 0.0005\n",
      "Epoch [51/150], Step [3401/5000], Loss = 0.0033\n",
      "Epoch [51/150], Step [3501/5000], Loss = 0.0004\n",
      "Epoch [51/150], Step [3601/5000], Loss = 0.0000\n",
      "Epoch [51/150], Step [3701/5000], Loss = 0.0019\n",
      "Epoch [51/150], Step [3801/5000], Loss = 0.3163\n",
      "Epoch [51/150], Step [3901/5000], Loss = 0.0001\n",
      "Epoch [51/150], Step [4001/5000], Loss = 0.0186\n",
      "Epoch [51/150], Step [4101/5000], Loss = 0.0000\n",
      "Epoch [51/150], Step [4201/5000], Loss = 0.0043\n",
      "Epoch [51/150], Step [4301/5000], Loss = 0.0012\n",
      "Epoch [51/150], Step [4401/5000], Loss = 0.0020\n",
      "Epoch [51/150], Step [4501/5000], Loss = 0.0009\n",
      "Epoch [51/150], Step [4601/5000], Loss = 0.0255\n",
      "Epoch [51/150], Step [4701/5000], Loss = 0.0033\n",
      "Epoch [51/150], Step [4801/5000], Loss = 0.0240\n",
      "Epoch [51/150], Step [4901/5000], Loss = 0.0000\n",
      "Epoch [51/150], Acc = 70.0000\n",
      "Epoch [52/150], Step [1/5000], Loss = 0.0041\n",
      "Epoch [52/150], Step [101/5000], Loss = 0.0081\n",
      "Epoch [52/150], Step [201/5000], Loss = 0.0451\n",
      "Epoch [52/150], Step [301/5000], Loss = 0.0020\n",
      "Epoch [52/150], Step [401/5000], Loss = 0.0014\n",
      "Epoch [52/150], Step [501/5000], Loss = 0.0002\n",
      "Epoch [52/150], Step [601/5000], Loss = 0.0029\n",
      "Epoch [52/150], Step [701/5000], Loss = 0.0007\n",
      "Epoch [52/150], Step [801/5000], Loss = 0.0001\n",
      "Epoch [52/150], Step [901/5000], Loss = 0.0613\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [52/150], Step [1001/5000], Loss = 0.0004\n",
      "Epoch [52/150], Step [1101/5000], Loss = 0.0012\n",
      "Epoch [52/150], Step [1201/5000], Loss = 0.0574\n",
      "Epoch [52/150], Step [1301/5000], Loss = 0.0005\n",
      "Epoch [52/150], Step [1401/5000], Loss = 0.0003\n",
      "Epoch [52/150], Step [1501/5000], Loss = 0.0005\n",
      "Epoch [52/150], Step [1601/5000], Loss = 0.0000\n",
      "Epoch [52/150], Step [1701/5000], Loss = 0.0012\n",
      "Epoch [52/150], Step [1801/5000], Loss = 0.0473\n",
      "Epoch [52/150], Step [1901/5000], Loss = 0.0019\n",
      "Epoch [52/150], Step [2001/5000], Loss = 0.0016\n",
      "Epoch [52/150], Step [2101/5000], Loss = 0.1006\n",
      "Epoch [52/150], Step [2201/5000], Loss = 0.0005\n",
      "Epoch [52/150], Step [2301/5000], Loss = 0.0007\n",
      "Epoch [52/150], Step [2401/5000], Loss = 0.0010\n",
      "Epoch [52/150], Step [2501/5000], Loss = 0.0092\n",
      "Epoch [52/150], Step [2601/5000], Loss = 0.0003\n",
      "Epoch [52/150], Step [2701/5000], Loss = 0.0030\n",
      "Epoch [52/150], Step [2801/5000], Loss = 0.0778\n",
      "Epoch [52/150], Step [2901/5000], Loss = 0.0012\n",
      "Epoch [52/150], Step [3001/5000], Loss = 0.0227\n",
      "Epoch [52/150], Step [3101/5000], Loss = 0.0001\n",
      "Epoch [52/150], Step [3201/5000], Loss = 0.0003\n",
      "Epoch [52/150], Step [3301/5000], Loss = 0.0403\n",
      "Epoch [52/150], Step [3401/5000], Loss = 0.0007\n",
      "Epoch [52/150], Step [3501/5000], Loss = 0.0000\n",
      "Epoch [52/150], Step [3601/5000], Loss = 0.0001\n",
      "Epoch [52/150], Step [3701/5000], Loss = 0.0019\n",
      "Epoch [52/150], Step [3801/5000], Loss = 0.0014\n",
      "Epoch [52/150], Step [3901/5000], Loss = 0.0076\n",
      "Epoch [52/150], Step [4001/5000], Loss = 0.0023\n",
      "Epoch [52/150], Step [4101/5000], Loss = 0.0000\n",
      "Epoch [52/150], Step [4201/5000], Loss = 0.0085\n",
      "Epoch [52/150], Step [4301/5000], Loss = 0.0050\n",
      "Epoch [52/150], Step [4401/5000], Loss = 0.0109\n",
      "Epoch [52/150], Step [4501/5000], Loss = 0.0082\n",
      "Epoch [52/150], Step [4601/5000], Loss = 0.0005\n",
      "Epoch [52/150], Step [4701/5000], Loss = 0.5297\n",
      "Epoch [52/150], Step [4801/5000], Loss = 0.0120\n",
      "Epoch [52/150], Step [4901/5000], Loss = 0.0001\n",
      "Epoch [52/150], Acc = 80.0000\n",
      "Epoch [53/150], Step [1/5000], Loss = 0.0244\n",
      "Epoch [53/150], Step [101/5000], Loss = 0.0082\n",
      "Epoch [53/150], Step [201/5000], Loss = 0.0001\n",
      "Epoch [53/150], Step [301/5000], Loss = 0.0000\n",
      "Epoch [53/150], Step [401/5000], Loss = 0.0022\n",
      "Epoch [53/150], Step [501/5000], Loss = 0.0001\n",
      "Epoch [53/150], Step [601/5000], Loss = 0.0012\n",
      "Epoch [53/150], Step [701/5000], Loss = 0.0001\n",
      "Epoch [53/150], Step [801/5000], Loss = 0.0002\n",
      "Epoch [53/150], Step [901/5000], Loss = 0.0059\n",
      "Epoch [53/150], Step [1001/5000], Loss = 0.0096\n",
      "Epoch [53/150], Step [1101/5000], Loss = 0.0522\n",
      "Epoch [53/150], Step [1201/5000], Loss = 0.0033\n",
      "Epoch [53/150], Step [1301/5000], Loss = 0.0001\n",
      "Epoch [53/150], Step [1401/5000], Loss = 0.0404\n",
      "Epoch [53/150], Step [1501/5000], Loss = 0.0014\n",
      "Epoch [53/150], Step [1601/5000], Loss = 0.0003\n",
      "Epoch [53/150], Step [1701/5000], Loss = 0.0018\n",
      "Epoch [53/150], Step [1801/5000], Loss = 0.0006\n",
      "Epoch [53/150], Step [1901/5000], Loss = 0.0106\n",
      "Epoch [53/150], Step [2001/5000], Loss = 0.0231\n",
      "Epoch [53/150], Step [2101/5000], Loss = 0.0007\n",
      "Epoch [53/150], Step [2201/5000], Loss = 0.0025\n",
      "Epoch [53/150], Step [2301/5000], Loss = 0.0037\n",
      "Epoch [53/150], Step [2401/5000], Loss = 0.0003\n",
      "Epoch [53/150], Step [2501/5000], Loss = 0.1007\n",
      "Epoch [53/150], Step [2601/5000], Loss = 0.0060\n",
      "Epoch [53/150], Step [2701/5000], Loss = 0.0698\n",
      "Epoch [53/150], Step [2801/5000], Loss = 0.0001\n",
      "Epoch [53/150], Step [2901/5000], Loss = 0.0011\n",
      "Epoch [53/150], Step [3001/5000], Loss = 0.0143\n",
      "Epoch [53/150], Step [3101/5000], Loss = 0.0191\n",
      "Epoch [53/150], Step [3201/5000], Loss = 0.0004\n",
      "Epoch [53/150], Step [3301/5000], Loss = 0.0496\n",
      "Epoch [53/150], Step [3401/5000], Loss = 0.0004\n",
      "Epoch [53/150], Step [3501/5000], Loss = 0.0021\n",
      "Epoch [53/150], Step [3601/5000], Loss = 0.0165\n",
      "Epoch [53/150], Step [3701/5000], Loss = 0.0020\n",
      "Epoch [53/150], Step [3801/5000], Loss = 0.0000\n",
      "Epoch [53/150], Step [3901/5000], Loss = 0.0009\n",
      "Epoch [53/150], Step [4001/5000], Loss = 0.0002\n",
      "Epoch [53/150], Step [4101/5000], Loss = 0.0001\n",
      "Epoch [53/150], Step [4201/5000], Loss = 0.0001\n",
      "Epoch [53/150], Step [4301/5000], Loss = 0.0001\n",
      "Epoch [53/150], Step [4401/5000], Loss = 0.0005\n",
      "Epoch [53/150], Step [4501/5000], Loss = 0.0049\n",
      "Epoch [53/150], Step [4601/5000], Loss = 0.0001\n",
      "Epoch [53/150], Step [4701/5000], Loss = 0.0004\n",
      "Epoch [53/150], Step [4801/5000], Loss = 0.0019\n",
      "Epoch [53/150], Step [4901/5000], Loss = 0.0002\n",
      "Epoch [53/150], Acc = 70.0000\n",
      "Epoch [54/150], Step [1/5000], Loss = 0.0419\n",
      "Epoch [54/150], Step [101/5000], Loss = 0.0002\n",
      "Epoch [54/150], Step [201/5000], Loss = 0.0000\n",
      "Epoch [54/150], Step [301/5000], Loss = 0.0001\n",
      "Epoch [54/150], Step [401/5000], Loss = 0.0113\n",
      "Epoch [54/150], Step [501/5000], Loss = 0.0019\n",
      "Epoch [54/150], Step [601/5000], Loss = 0.0028\n",
      "Epoch [54/150], Step [701/5000], Loss = 0.0002\n",
      "Epoch [54/150], Step [801/5000], Loss = 0.0250\n",
      "Epoch [54/150], Step [901/5000], Loss = 0.0001\n",
      "Epoch [54/150], Step [1001/5000], Loss = 0.0476\n",
      "Epoch [54/150], Step [1101/5000], Loss = 0.0001\n",
      "Epoch [54/150], Step [1201/5000], Loss = 0.0064\n",
      "Epoch [54/150], Step [1301/5000], Loss = 0.1956\n",
      "Epoch [54/150], Step [1401/5000], Loss = 0.0071\n",
      "Epoch [54/150], Step [1501/5000], Loss = 0.0001\n",
      "Epoch [54/150], Step [1601/5000], Loss = 0.0000\n",
      "Epoch [54/150], Step [1701/5000], Loss = 0.0001\n",
      "Epoch [54/150], Step [1801/5000], Loss = 0.0779\n",
      "Epoch [54/150], Step [1901/5000], Loss = 0.0001\n",
      "Epoch [54/150], Step [2001/5000], Loss = 0.0000\n",
      "Epoch [54/150], Step [2101/5000], Loss = 0.0000\n",
      "Epoch [54/150], Step [2201/5000], Loss = 0.0001\n",
      "Epoch [54/150], Step [2301/5000], Loss = 0.0020\n",
      "Epoch [54/150], Step [2401/5000], Loss = 0.1107\n",
      "Epoch [54/150], Step [2501/5000], Loss = 0.2112\n",
      "Epoch [54/150], Step [2601/5000], Loss = 0.0001\n",
      "Epoch [54/150], Step [2701/5000], Loss = 0.0036\n",
      "Epoch [54/150], Step [2801/5000], Loss = 0.1966\n",
      "Epoch [54/150], Step [2901/5000], Loss = 0.0002\n",
      "Epoch [54/150], Step [3001/5000], Loss = 0.4216\n",
      "Epoch [54/150], Step [3101/5000], Loss = 0.1060\n",
      "Epoch [54/150], Step [3201/5000], Loss = 0.0001\n",
      "Epoch [54/150], Step [3301/5000], Loss = 0.0000\n",
      "Epoch [54/150], Step [3401/5000], Loss = 0.0269\n",
      "Epoch [54/150], Step [3501/5000], Loss = 0.0003\n",
      "Epoch [54/150], Step [3601/5000], Loss = 0.0003\n",
      "Epoch [54/150], Step [3701/5000], Loss = 0.0034\n",
      "Epoch [54/150], Step [3801/5000], Loss = 0.2608\n",
      "Epoch [54/150], Step [3901/5000], Loss = 0.0001\n",
      "Epoch [54/150], Step [4001/5000], Loss = 0.7008\n",
      "Epoch [54/150], Step [4101/5000], Loss = 0.0042\n",
      "Epoch [54/150], Step [4201/5000], Loss = 0.0117\n",
      "Epoch [54/150], Step [4301/5000], Loss = 0.0005\n",
      "Epoch [54/150], Step [4401/5000], Loss = 0.0751\n",
      "Epoch [54/150], Step [4501/5000], Loss = 0.0003\n",
      "Epoch [54/150], Step [4601/5000], Loss = 0.0135\n",
      "Epoch [54/150], Step [4701/5000], Loss = 0.0002\n",
      "Epoch [54/150], Step [4801/5000], Loss = 0.2081\n",
      "Epoch [54/150], Step [4901/5000], Loss = 0.0001\n",
      "Epoch [54/150], Acc = 70.0000\n",
      "Epoch [55/150], Step [1/5000], Loss = 0.0002\n",
      "Epoch [55/150], Step [101/5000], Loss = 0.0009\n",
      "Epoch [55/150], Step [201/5000], Loss = 0.0000\n",
      "Epoch [55/150], Step [301/5000], Loss = 0.0005\n",
      "Epoch [55/150], Step [401/5000], Loss = 0.0007\n",
      "Epoch [55/150], Step [501/5000], Loss = 0.0373\n",
      "Epoch [55/150], Step [601/5000], Loss = 0.0019\n",
      "Epoch [55/150], Step [701/5000], Loss = 0.0066\n",
      "Epoch [55/150], Step [801/5000], Loss = 0.0001\n",
      "Epoch [55/150], Step [901/5000], Loss = 0.2804\n",
      "Epoch [55/150], Step [1001/5000], Loss = 0.0047\n",
      "Epoch [55/150], Step [1101/5000], Loss = 0.0003\n",
      "Epoch [55/150], Step [1201/5000], Loss = 0.0002\n",
      "Epoch [55/150], Step [1301/5000], Loss = 0.0008\n",
      "Epoch [55/150], Step [1401/5000], Loss = 0.0001\n",
      "Epoch [55/150], Step [1501/5000], Loss = 0.0014\n",
      "Epoch [55/150], Step [1601/5000], Loss = 0.0001\n",
      "Epoch [55/150], Step [1701/5000], Loss = 0.0344\n",
      "Epoch [55/150], Step [1801/5000], Loss = 0.0010\n",
      "Epoch [55/150], Step [1901/5000], Loss = 0.0002\n",
      "Epoch [55/150], Step [2001/5000], Loss = 0.0000\n",
      "Epoch [55/150], Step [2101/5000], Loss = 0.0002\n",
      "Epoch [55/150], Step [2201/5000], Loss = 0.0000\n",
      "Epoch [55/150], Step [2301/5000], Loss = 0.0005\n",
      "Epoch [55/150], Step [2401/5000], Loss = 0.4304\n",
      "Epoch [55/150], Step [2501/5000], Loss = 0.0005\n",
      "Epoch [55/150], Step [2601/5000], Loss = 0.0016\n",
      "Epoch [55/150], Step [2701/5000], Loss = 0.0000\n",
      "Epoch [55/150], Step [2801/5000], Loss = 0.0852\n",
      "Epoch [55/150], Step [2901/5000], Loss = 0.0059\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [55/150], Step [3001/5000], Loss = 0.0000\n",
      "Epoch [55/150], Step [3101/5000], Loss = 0.0106\n",
      "Epoch [55/150], Step [3201/5000], Loss = 0.0355\n",
      "Epoch [55/150], Step [3301/5000], Loss = 0.0228\n",
      "Epoch [55/150], Step [3401/5000], Loss = 0.0004\n",
      "Epoch [55/150], Step [3501/5000], Loss = 0.0001\n",
      "Epoch [55/150], Step [3601/5000], Loss = 0.0445\n",
      "Epoch [55/150], Step [3701/5000], Loss = 0.0103\n",
      "Epoch [55/150], Step [3801/5000], Loss = 0.0013\n",
      "Epoch [55/150], Step [3901/5000], Loss = 0.0006\n",
      "Epoch [55/150], Step [4001/5000], Loss = 0.0011\n",
      "Epoch [55/150], Step [4101/5000], Loss = 0.0411\n",
      "Epoch [55/150], Step [4201/5000], Loss = 0.0001\n",
      "Epoch [55/150], Step [4301/5000], Loss = 0.0000\n",
      "Epoch [55/150], Step [4401/5000], Loss = 0.0004\n",
      "Epoch [55/150], Step [4501/5000], Loss = 0.0005\n",
      "Epoch [55/150], Step [4601/5000], Loss = 0.1574\n",
      "Epoch [55/150], Step [4701/5000], Loss = 0.0580\n",
      "Epoch [55/150], Step [4801/5000], Loss = 0.0023\n",
      "Epoch [55/150], Step [4901/5000], Loss = 0.0015\n",
      "Epoch [55/150], Acc = 90.0000\n",
      "Epoch [56/150], Step [1/5000], Loss = 0.0000\n",
      "Epoch [56/150], Step [101/5000], Loss = 0.0001\n",
      "Epoch [56/150], Step [201/5000], Loss = 0.0043\n",
      "Epoch [56/150], Step [301/5000], Loss = 0.0069\n",
      "Epoch [56/150], Step [401/5000], Loss = 0.0016\n",
      "Epoch [56/150], Step [501/5000], Loss = 0.0181\n",
      "Epoch [56/150], Step [601/5000], Loss = 0.1023\n",
      "Epoch [56/150], Step [701/5000], Loss = 0.1738\n",
      "Epoch [56/150], Step [801/5000], Loss = 0.0004\n",
      "Epoch [56/150], Step [901/5000], Loss = 0.0001\n",
      "Epoch [56/150], Step [1001/5000], Loss = 0.0041\n",
      "Epoch [56/150], Step [1101/5000], Loss = 0.0007\n",
      "Epoch [56/150], Step [1201/5000], Loss = 0.5067\n",
      "Epoch [56/150], Step [1301/5000], Loss = 0.0000\n",
      "Epoch [56/150], Step [1401/5000], Loss = 0.0002\n",
      "Epoch [56/150], Step [1501/5000], Loss = 0.0004\n",
      "Epoch [56/150], Step [1601/5000], Loss = 0.1600\n",
      "Epoch [56/150], Step [1701/5000], Loss = 0.0320\n",
      "Epoch [56/150], Step [1801/5000], Loss = 0.0046\n",
      "Epoch [56/150], Step [1901/5000], Loss = 0.0000\n",
      "Epoch [56/150], Step [2001/5000], Loss = 0.0010\n",
      "Epoch [56/150], Step [2101/5000], Loss = 0.0005\n",
      "Epoch [56/150], Step [2201/5000], Loss = 0.0004\n",
      "Epoch [56/150], Step [2301/5000], Loss = 0.1315\n",
      "Epoch [56/150], Step [2401/5000], Loss = 0.0085\n",
      "Epoch [56/150], Step [2501/5000], Loss = 0.0006\n",
      "Epoch [56/150], Step [2601/5000], Loss = 0.0013\n",
      "Epoch [56/150], Step [2701/5000], Loss = 0.0000\n",
      "Epoch [56/150], Step [2801/5000], Loss = 0.0526\n",
      "Epoch [56/150], Step [2901/5000], Loss = 0.0002\n",
      "Epoch [56/150], Step [3001/5000], Loss = 0.0016\n",
      "Epoch [56/150], Step [3101/5000], Loss = 0.0015\n",
      "Epoch [56/150], Step [3201/5000], Loss = 0.0019\n",
      "Epoch [56/150], Step [3301/5000], Loss = 0.0258\n",
      "Epoch [56/150], Step [3401/5000], Loss = 0.0953\n",
      "Epoch [56/150], Step [3501/5000], Loss = 0.0013\n",
      "Epoch [56/150], Step [3601/5000], Loss = 0.0452\n",
      "Epoch [56/150], Step [3701/5000], Loss = 0.0002\n",
      "Epoch [56/150], Step [3801/5000], Loss = 0.0203\n",
      "Epoch [56/150], Step [3901/5000], Loss = 0.0001\n",
      "Epoch [56/150], Step [4001/5000], Loss = 0.0005\n",
      "Epoch [56/150], Step [4101/5000], Loss = 0.0974\n",
      "Epoch [56/150], Step [4201/5000], Loss = 0.0002\n",
      "Epoch [56/150], Step [4301/5000], Loss = 0.0232\n",
      "Epoch [56/150], Step [4401/5000], Loss = 0.0003\n",
      "Epoch [56/150], Step [4501/5000], Loss = 0.0037\n",
      "Epoch [56/150], Step [4601/5000], Loss = 0.0013\n",
      "Epoch [56/150], Step [4701/5000], Loss = 0.0081\n",
      "Epoch [56/150], Step [4801/5000], Loss = 0.0093\n",
      "Epoch [56/150], Step [4901/5000], Loss = 0.0014\n",
      "Epoch [56/150], Acc = 80.0000\n",
      "Epoch [57/150], Step [1/5000], Loss = 0.0569\n",
      "Epoch [57/150], Step [101/5000], Loss = 0.2155\n",
      "Epoch [57/150], Step [201/5000], Loss = 0.0001\n",
      "Epoch [57/150], Step [301/5000], Loss = 0.0204\n",
      "Epoch [57/150], Step [401/5000], Loss = 0.0006\n",
      "Epoch [57/150], Step [501/5000], Loss = 0.0019\n",
      "Epoch [57/150], Step [601/5000], Loss = 0.0048\n",
      "Epoch [57/150], Step [701/5000], Loss = 0.0000\n",
      "Epoch [57/150], Step [801/5000], Loss = 0.0015\n",
      "Epoch [57/150], Step [901/5000], Loss = 0.0644\n",
      "Epoch [57/150], Step [1001/5000], Loss = 0.0317\n",
      "Epoch [57/150], Step [1101/5000], Loss = 0.0091\n",
      "Epoch [57/150], Step [1201/5000], Loss = 0.1036\n",
      "Epoch [57/150], Step [1301/5000], Loss = 0.0082\n",
      "Epoch [57/150], Step [1401/5000], Loss = 0.0510\n",
      "Epoch [57/150], Step [1501/5000], Loss = 0.0016\n",
      "Epoch [57/150], Step [1601/5000], Loss = 0.0674\n",
      "Epoch [57/150], Step [1701/5000], Loss = 0.0033\n",
      "Epoch [57/150], Step [1801/5000], Loss = 0.0157\n",
      "Epoch [57/150], Step [1901/5000], Loss = 0.0081\n",
      "Epoch [57/150], Step [2001/5000], Loss = 0.0056\n",
      "Epoch [57/150], Step [2101/5000], Loss = 0.0009\n",
      "Epoch [57/150], Step [2201/5000], Loss = 0.0006\n",
      "Epoch [57/150], Step [2301/5000], Loss = 0.0155\n",
      "Epoch [57/150], Step [2401/5000], Loss = 0.0056\n",
      "Epoch [57/150], Step [2501/5000], Loss = 0.0106\n",
      "Epoch [57/150], Step [2601/5000], Loss = 0.0000\n",
      "Epoch [57/150], Step [2701/5000], Loss = 0.0197\n",
      "Epoch [57/150], Step [2801/5000], Loss = 0.0001\n",
      "Epoch [57/150], Step [2901/5000], Loss = 0.0000\n",
      "Epoch [57/150], Step [3001/5000], Loss = 0.0001\n",
      "Epoch [57/150], Step [3101/5000], Loss = 0.0144\n",
      "Epoch [57/150], Step [3201/5000], Loss = 0.0007\n",
      "Epoch [57/150], Step [3301/5000], Loss = 0.0391\n",
      "Epoch [57/150], Step [3401/5000], Loss = 0.0011\n",
      "Epoch [57/150], Step [3501/5000], Loss = 0.0001\n",
      "Epoch [57/150], Step [3601/5000], Loss = 0.0093\n",
      "Epoch [57/150], Step [3701/5000], Loss = 0.0280\n",
      "Epoch [57/150], Step [3801/5000], Loss = 0.0003\n",
      "Epoch [57/150], Step [3901/5000], Loss = 0.0000\n",
      "Epoch [57/150], Step [4001/5000], Loss = 0.0005\n",
      "Epoch [57/150], Step [4101/5000], Loss = 0.0001\n",
      "Epoch [57/150], Step [4201/5000], Loss = 0.0002\n",
      "Epoch [57/150], Step [4301/5000], Loss = 0.0000\n",
      "Epoch [57/150], Step [4401/5000], Loss = 0.0793\n",
      "Epoch [57/150], Step [4501/5000], Loss = 0.0113\n",
      "Epoch [57/150], Step [4601/5000], Loss = 0.0006\n",
      "Epoch [57/150], Step [4701/5000], Loss = 0.0012\n",
      "Epoch [57/150], Step [4801/5000], Loss = 0.0006\n",
      "Epoch [57/150], Step [4901/5000], Loss = 0.0127\n",
      "Epoch [57/150], Acc = 80.0000\n",
      "Epoch [58/150], Step [1/5000], Loss = 0.0342\n",
      "Epoch [58/150], Step [101/5000], Loss = 0.0017\n",
      "Epoch [58/150], Step [201/5000], Loss = 0.0028\n",
      "Epoch [58/150], Step [301/5000], Loss = 0.0000\n",
      "Epoch [58/150], Step [401/5000], Loss = 0.0006\n",
      "Epoch [58/150], Step [501/5000], Loss = 0.0020\n",
      "Epoch [58/150], Step [601/5000], Loss = 0.0010\n",
      "Epoch [58/150], Step [701/5000], Loss = 0.0006\n",
      "Epoch [58/150], Step [801/5000], Loss = 0.0029\n",
      "Epoch [58/150], Step [901/5000], Loss = 0.0011\n",
      "Epoch [58/150], Step [1001/5000], Loss = 0.0050\n",
      "Epoch [58/150], Step [1101/5000], Loss = 0.0032\n",
      "Epoch [58/150], Step [1201/5000], Loss = 0.0000\n",
      "Epoch [58/150], Step [1301/5000], Loss = 0.0033\n",
      "Epoch [58/150], Step [1401/5000], Loss = 0.0005\n",
      "Epoch [58/150], Step [1501/5000], Loss = 0.0008\n",
      "Epoch [58/150], Step [1601/5000], Loss = 0.0005\n",
      "Epoch [58/150], Step [1701/5000], Loss = 0.0006\n",
      "Epoch [58/150], Step [1801/5000], Loss = 0.0001\n",
      "Epoch [58/150], Step [1901/5000], Loss = 0.0006\n",
      "Epoch [58/150], Step [2001/5000], Loss = 0.0009\n",
      "Epoch [58/150], Step [2101/5000], Loss = 0.0002\n",
      "Epoch [58/150], Step [2201/5000], Loss = 0.0012\n",
      "Epoch [58/150], Step [2301/5000], Loss = 0.0059\n",
      "Epoch [58/150], Step [2401/5000], Loss = 0.0254\n",
      "Epoch [58/150], Step [2501/5000], Loss = 0.0008\n",
      "Epoch [58/150], Step [2601/5000], Loss = 0.0009\n",
      "Epoch [58/150], Step [2701/5000], Loss = 0.0001\n",
      "Epoch [58/150], Step [2801/5000], Loss = 0.0061\n",
      "Epoch [58/150], Step [2901/5000], Loss = 0.0028\n",
      "Epoch [58/150], Step [3001/5000], Loss = 0.0002\n",
      "Epoch [58/150], Step [3101/5000], Loss = 0.0020\n",
      "Epoch [58/150], Step [3201/5000], Loss = 0.0004\n",
      "Epoch [58/150], Step [3301/5000], Loss = 0.0001\n",
      "Epoch [58/150], Step [3401/5000], Loss = 0.0002\n",
      "Epoch [58/150], Step [3501/5000], Loss = 0.0507\n",
      "Epoch [58/150], Step [3601/5000], Loss = 0.0003\n",
      "Epoch [58/150], Step [3701/5000], Loss = 0.0774\n",
      "Epoch [58/150], Step [3801/5000], Loss = 0.0029\n",
      "Epoch [58/150], Step [3901/5000], Loss = 0.0246\n",
      "Epoch [58/150], Step [4001/5000], Loss = 0.1724\n",
      "Epoch [58/150], Step [4101/5000], Loss = 0.0012\n",
      "Epoch [58/150], Step [4201/5000], Loss = 0.0012\n",
      "Epoch [58/150], Step [4301/5000], Loss = 0.0061\n",
      "Epoch [58/150], Step [4401/5000], Loss = 0.4144\n",
      "Epoch [58/150], Step [4501/5000], Loss = 0.0005\n",
      "Epoch [58/150], Step [4601/5000], Loss = 0.0000\n",
      "Epoch [58/150], Step [4701/5000], Loss = 0.0010\n",
      "Epoch [58/150], Step [4801/5000], Loss = 0.0944\n",
      "Epoch [58/150], Step [4901/5000], Loss = 0.0118\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [58/150], Acc = 80.0000\n",
      "Epoch [59/150], Step [1/5000], Loss = 0.0064\n",
      "Epoch [59/150], Step [101/5000], Loss = 0.0088\n",
      "Epoch [59/150], Step [201/5000], Loss = 0.0201\n",
      "Epoch [59/150], Step [301/5000], Loss = 0.0116\n",
      "Epoch [59/150], Step [401/5000], Loss = 0.0001\n",
      "Epoch [59/150], Step [501/5000], Loss = 0.0009\n",
      "Epoch [59/150], Step [601/5000], Loss = 0.0202\n",
      "Epoch [59/150], Step [701/5000], Loss = 0.0000\n",
      "Epoch [59/150], Step [801/5000], Loss = 0.0017\n",
      "Epoch [59/150], Step [901/5000], Loss = 0.0025\n",
      "Epoch [59/150], Step [1001/5000], Loss = 0.2136\n",
      "Epoch [59/150], Step [1101/5000], Loss = 0.0046\n",
      "Epoch [59/150], Step [1201/5000], Loss = 0.0010\n",
      "Epoch [59/150], Step [1301/5000], Loss = 0.0003\n",
      "Epoch [59/150], Step [1401/5000], Loss = 0.0128\n",
      "Epoch [59/150], Step [1501/5000], Loss = 0.0000\n",
      "Epoch [59/150], Step [1601/5000], Loss = 0.0097\n",
      "Epoch [59/150], Step [1701/5000], Loss = 0.0077\n",
      "Epoch [59/150], Step [1801/5000], Loss = 0.0004\n",
      "Epoch [59/150], Step [1901/5000], Loss = 0.0000\n",
      "Epoch [59/150], Step [2001/5000], Loss = 0.0192\n",
      "Epoch [59/150], Step [2101/5000], Loss = 0.0158\n",
      "Epoch [59/150], Step [2201/5000], Loss = 0.0014\n",
      "Epoch [59/150], Step [2301/5000], Loss = 0.0023\n",
      "Epoch [59/150], Step [2401/5000], Loss = 0.0001\n",
      "Epoch [59/150], Step [2501/5000], Loss = 0.0011\n",
      "Epoch [59/150], Step [2601/5000], Loss = 0.0003\n",
      "Epoch [59/150], Step [2701/5000], Loss = 0.0074\n",
      "Epoch [59/150], Step [2801/5000], Loss = 0.0005\n",
      "Epoch [59/150], Step [2901/5000], Loss = 0.0017\n",
      "Epoch [59/150], Step [3001/5000], Loss = 0.0543\n",
      "Epoch [59/150], Step [3101/5000], Loss = 0.1215\n",
      "Epoch [59/150], Step [3201/5000], Loss = 0.0010\n",
      "Epoch [59/150], Step [3301/5000], Loss = 0.0010\n",
      "Epoch [59/150], Step [3401/5000], Loss = 0.0033\n",
      "Epoch [59/150], Step [3501/5000], Loss = 0.0019\n",
      "Epoch [59/150], Step [3601/5000], Loss = 0.0120\n",
      "Epoch [59/150], Step [3701/5000], Loss = 0.0002\n",
      "Epoch [59/150], Step [3801/5000], Loss = 0.0035\n",
      "Epoch [59/150], Step [3901/5000], Loss = 0.0001\n",
      "Epoch [59/150], Step [4001/5000], Loss = 0.2560\n",
      "Epoch [59/150], Step [4101/5000], Loss = 0.0008\n",
      "Epoch [59/150], Step [4201/5000], Loss = 0.0004\n",
      "Epoch [59/150], Step [4301/5000], Loss = 0.0320\n",
      "Epoch [59/150], Step [4401/5000], Loss = 0.0001\n",
      "Epoch [59/150], Step [4501/5000], Loss = 0.0026\n",
      "Epoch [59/150], Step [4601/5000], Loss = 0.0007\n",
      "Epoch [59/150], Step [4701/5000], Loss = 0.0001\n",
      "Epoch [59/150], Step [4801/5000], Loss = 0.0003\n",
      "Epoch [59/150], Step [4901/5000], Loss = 0.0035\n",
      "Epoch [59/150], Acc = 70.0000\n",
      "Epoch [60/150], Step [1/5000], Loss = 0.0002\n",
      "Epoch [60/150], Step [101/5000], Loss = 0.0015\n",
      "Epoch [60/150], Step [201/5000], Loss = 0.0003\n",
      "Epoch [60/150], Step [301/5000], Loss = 0.0015\n",
      "Epoch [60/150], Step [401/5000], Loss = 0.0881\n",
      "Epoch [60/150], Step [501/5000], Loss = 0.0772\n",
      "Epoch [60/150], Step [601/5000], Loss = 0.0002\n",
      "Epoch [60/150], Step [701/5000], Loss = 0.0005\n",
      "Epoch [60/150], Step [801/5000], Loss = 0.0000\n",
      "Epoch [60/150], Step [901/5000], Loss = 0.0001\n",
      "Epoch [60/150], Step [1001/5000], Loss = 0.0390\n",
      "Epoch [60/150], Step [1101/5000], Loss = 0.0005\n",
      "Epoch [60/150], Step [1201/5000], Loss = 0.0003\n",
      "Epoch [60/150], Step [1301/5000], Loss = 0.0119\n",
      "Epoch [60/150], Step [1401/5000], Loss = 0.0015\n",
      "Epoch [60/150], Step [1501/5000], Loss = 0.0003\n",
      "Epoch [60/150], Step [1601/5000], Loss = 0.0001\n",
      "Epoch [60/150], Step [1701/5000], Loss = 0.0004\n",
      "Epoch [60/150], Step [1801/5000], Loss = 0.0011\n",
      "Epoch [60/150], Step [1901/5000], Loss = 0.0004\n",
      "Epoch [60/150], Step [2001/5000], Loss = 0.0001\n",
      "Epoch [60/150], Step [2101/5000], Loss = 0.0008\n",
      "Epoch [60/150], Step [2201/5000], Loss = 0.0161\n",
      "Epoch [60/150], Step [2301/5000], Loss = 0.0041\n",
      "Epoch [60/150], Step [2401/5000], Loss = 0.0022\n",
      "Epoch [60/150], Step [2501/5000], Loss = 0.0050\n",
      "Epoch [60/150], Step [2601/5000], Loss = 0.0576\n",
      "Epoch [60/150], Step [2701/5000], Loss = 0.0376\n",
      "Epoch [60/150], Step [2801/5000], Loss = 0.0001\n",
      "Epoch [60/150], Step [2901/5000], Loss = 0.0004\n",
      "Epoch [60/150], Step [3001/5000], Loss = 0.0002\n",
      "Epoch [60/150], Step [3101/5000], Loss = 0.0964\n",
      "Epoch [60/150], Step [3201/5000], Loss = 0.0002\n",
      "Epoch [60/150], Step [3301/5000], Loss = 0.0046\n",
      "Epoch [60/150], Step [3401/5000], Loss = 0.0062\n",
      "Epoch [60/150], Step [3501/5000], Loss = 0.0010\n",
      "Epoch [60/150], Step [3601/5000], Loss = 0.0002\n",
      "Epoch [60/150], Step [3701/5000], Loss = 0.0019\n",
      "Epoch [60/150], Step [3801/5000], Loss = 0.0014\n",
      "Epoch [60/150], Step [3901/5000], Loss = 0.0221\n",
      "Epoch [60/150], Step [4001/5000], Loss = 0.0007\n",
      "Epoch [60/150], Step [4101/5000], Loss = 0.0019\n",
      "Epoch [60/150], Step [4201/5000], Loss = 0.0032\n",
      "Epoch [60/150], Step [4301/5000], Loss = 0.0021\n",
      "Epoch [60/150], Step [4401/5000], Loss = 0.0024\n",
      "Epoch [60/150], Step [4501/5000], Loss = 0.0000\n",
      "Epoch [60/150], Step [4601/5000], Loss = 0.0000\n",
      "Epoch [60/150], Step [4701/5000], Loss = 0.0015\n",
      "Epoch [60/150], Step [4801/5000], Loss = 0.0048\n",
      "Epoch [60/150], Step [4901/5000], Loss = 0.0021\n",
      "Epoch [60/150], Acc = 80.0000\n",
      "Epoch [61/150], Step [1/5000], Loss = 0.0016\n",
      "Epoch [61/150], Step [101/5000], Loss = 0.0004\n",
      "Epoch [61/150], Step [201/5000], Loss = 0.0114\n",
      "Epoch [61/150], Step [301/5000], Loss = 0.0146\n",
      "Epoch [61/150], Step [401/5000], Loss = 0.0661\n",
      "Epoch [61/150], Step [501/5000], Loss = 0.0041\n",
      "Epoch [61/150], Step [601/5000], Loss = 0.0003\n",
      "Epoch [61/150], Step [701/5000], Loss = 0.0000\n",
      "Epoch [61/150], Step [801/5000], Loss = 0.0001\n",
      "Epoch [61/150], Step [901/5000], Loss = 0.0005\n",
      "Epoch [61/150], Step [1001/5000], Loss = 0.0001\n",
      "Epoch [61/150], Step [1101/5000], Loss = 0.0001\n",
      "Epoch [61/150], Step [1201/5000], Loss = 0.0001\n",
      "Epoch [61/150], Step [1301/5000], Loss = 0.0080\n",
      "Epoch [61/150], Step [1401/5000], Loss = 0.0084\n",
      "Epoch [61/150], Step [1501/5000], Loss = 0.0075\n",
      "Epoch [61/150], Step [1601/5000], Loss = 0.0097\n",
      "Epoch [61/150], Step [1701/5000], Loss = 0.0000\n",
      "Epoch [61/150], Step [1801/5000], Loss = 0.3271\n",
      "Epoch [61/150], Step [1901/5000], Loss = 0.0003\n",
      "Epoch [61/150], Step [2001/5000], Loss = 0.0017\n",
      "Epoch [61/150], Step [2101/5000], Loss = 0.0258\n",
      "Epoch [61/150], Step [2201/5000], Loss = 0.0001\n",
      "Epoch [61/150], Step [2301/5000], Loss = 0.0009\n",
      "Epoch [61/150], Step [2401/5000], Loss = 0.0027\n",
      "Epoch [61/150], Step [2501/5000], Loss = 0.0006\n",
      "Epoch [61/150], Step [2601/5000], Loss = 0.0000\n",
      "Epoch [61/150], Step [2701/5000], Loss = 0.0328\n",
      "Epoch [61/150], Step [2801/5000], Loss = 0.0071\n",
      "Epoch [61/150], Step [2901/5000], Loss = 0.0004\n",
      "Epoch [61/150], Step [3001/5000], Loss = 0.0185\n",
      "Epoch [61/150], Step [3101/5000], Loss = 0.0001\n",
      "Epoch [61/150], Step [3201/5000], Loss = 0.0081\n",
      "Epoch [61/150], Step [3301/5000], Loss = 0.0000\n",
      "Epoch [61/150], Step [3401/5000], Loss = 0.0052\n",
      "Epoch [61/150], Step [3501/5000], Loss = 0.0008\n",
      "Epoch [61/150], Step [3601/5000], Loss = 0.0036\n",
      "Epoch [61/150], Step [3701/5000], Loss = 0.0034\n",
      "Epoch [61/150], Step [3801/5000], Loss = 0.0613\n",
      "Epoch [61/150], Step [3901/5000], Loss = 0.0007\n",
      "Epoch [61/150], Step [4001/5000], Loss = 0.0481\n",
      "Epoch [61/150], Step [4101/5000], Loss = 0.0000\n",
      "Epoch [61/150], Step [4201/5000], Loss = 0.0002\n",
      "Epoch [61/150], Step [4301/5000], Loss = 0.0008\n",
      "Epoch [61/150], Step [4401/5000], Loss = 0.0028\n",
      "Epoch [61/150], Step [4501/5000], Loss = 0.0001\n",
      "Epoch [61/150], Step [4601/5000], Loss = 0.0022\n",
      "Epoch [61/150], Step [4701/5000], Loss = 0.0419\n",
      "Epoch [61/150], Step [4801/5000], Loss = 0.0037\n",
      "Epoch [61/150], Step [4901/5000], Loss = 0.0017\n",
      "Epoch [61/150], Acc = 70.0000\n",
      "Epoch [62/150], Step [1/5000], Loss = 0.0008\n",
      "Epoch [62/150], Step [101/5000], Loss = 0.0004\n",
      "Epoch [62/150], Step [201/5000], Loss = 0.0008\n",
      "Epoch [62/150], Step [301/5000], Loss = 0.0549\n",
      "Epoch [62/150], Step [401/5000], Loss = 0.0018\n",
      "Epoch [62/150], Step [501/5000], Loss = 0.0002\n",
      "Epoch [62/150], Step [601/5000], Loss = 0.0040\n",
      "Epoch [62/150], Step [701/5000], Loss = 0.0000\n",
      "Epoch [62/150], Step [801/5000], Loss = 0.0001\n",
      "Epoch [62/150], Step [901/5000], Loss = 0.0010\n",
      "Epoch [62/150], Step [1001/5000], Loss = 0.0013\n",
      "Epoch [62/150], Step [1101/5000], Loss = 0.0025\n",
      "Epoch [62/150], Step [1201/5000], Loss = 0.0009\n",
      "Epoch [62/150], Step [1301/5000], Loss = 0.0012\n",
      "Epoch [62/150], Step [1401/5000], Loss = 0.0912\n",
      "Epoch [62/150], Step [1501/5000], Loss = 0.0000\n",
      "Epoch [62/150], Step [1601/5000], Loss = 0.0006\n",
      "Epoch [62/150], Step [1701/5000], Loss = 0.0015\n",
      "Epoch [62/150], Step [1801/5000], Loss = 0.0010\n",
      "Epoch [62/150], Step [1901/5000], Loss = 0.0001\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [62/150], Step [2001/5000], Loss = 0.0000\n",
      "Epoch [62/150], Step [2101/5000], Loss = 0.0010\n",
      "Epoch [62/150], Step [2201/5000], Loss = 0.0000\n",
      "Epoch [62/150], Step [2301/5000], Loss = 0.0005\n",
      "Epoch [62/150], Step [2401/5000], Loss = 0.0008\n",
      "Epoch [62/150], Step [2501/5000], Loss = 0.0090\n",
      "Epoch [62/150], Step [2601/5000], Loss = 0.2726\n",
      "Epoch [62/150], Step [2701/5000], Loss = 0.0010\n",
      "Epoch [62/150], Step [2801/5000], Loss = 0.0010\n",
      "Epoch [62/150], Step [2901/5000], Loss = 0.0052\n",
      "Epoch [62/150], Step [3001/5000], Loss = 0.0071\n",
      "Epoch [62/150], Step [3101/5000], Loss = 0.0001\n",
      "Epoch [62/150], Step [3201/5000], Loss = 0.0019\n",
      "Epoch [62/150], Step [3301/5000], Loss = 0.0005\n",
      "Epoch [62/150], Step [3401/5000], Loss = 0.0000\n",
      "Epoch [62/150], Step [3501/5000], Loss = 0.0022\n",
      "Epoch [62/150], Step [3601/5000], Loss = 0.0014\n",
      "Epoch [62/150], Step [3701/5000], Loss = 0.5525\n",
      "Epoch [62/150], Step [3801/5000], Loss = 0.0673\n",
      "Epoch [62/150], Step [3901/5000], Loss = 0.0007\n",
      "Epoch [62/150], Step [4001/5000], Loss = 0.0034\n",
      "Epoch [62/150], Step [4101/5000], Loss = 0.0358\n",
      "Epoch [62/150], Step [4201/5000], Loss = 0.0071\n",
      "Epoch [62/150], Step [4301/5000], Loss = 0.0010\n",
      "Epoch [62/150], Step [4401/5000], Loss = 0.0024\n",
      "Epoch [62/150], Step [4501/5000], Loss = 0.0002\n",
      "Epoch [62/150], Step [4601/5000], Loss = 0.0018\n",
      "Epoch [62/150], Step [4701/5000], Loss = 0.0002\n",
      "Epoch [62/150], Step [4801/5000], Loss = 0.0004\n",
      "Epoch [62/150], Step [4901/5000], Loss = 0.0014\n",
      "Epoch [62/150], Acc = 70.0000\n",
      "Epoch [63/150], Step [1/5000], Loss = 0.0000\n",
      "Epoch [63/150], Step [101/5000], Loss = 0.0003\n",
      "Epoch [63/150], Step [201/5000], Loss = 0.0114\n",
      "Epoch [63/150], Step [301/5000], Loss = 0.1701\n",
      "Epoch [63/150], Step [401/5000], Loss = 0.0010\n",
      "Epoch [63/150], Step [501/5000], Loss = 0.0101\n",
      "Epoch [63/150], Step [601/5000], Loss = 0.0041\n",
      "Epoch [63/150], Step [701/5000], Loss = 0.0003\n",
      "Epoch [63/150], Step [801/5000], Loss = 0.0022\n",
      "Epoch [63/150], Step [901/5000], Loss = 0.0001\n",
      "Epoch [63/150], Step [1001/5000], Loss = 0.0000\n",
      "Epoch [63/150], Step [1101/5000], Loss = 0.2013\n",
      "Epoch [63/150], Step [1201/5000], Loss = 0.0052\n",
      "Epoch [63/150], Step [1301/5000], Loss = 0.0001\n",
      "Epoch [63/150], Step [1401/5000], Loss = 0.0202\n",
      "Epoch [63/150], Step [1501/5000], Loss = 0.0000\n",
      "Epoch [63/150], Step [1601/5000], Loss = 0.0000\n",
      "Epoch [63/150], Step [1701/5000], Loss = 0.0004\n",
      "Epoch [63/150], Step [1801/5000], Loss = 0.0001\n",
      "Epoch [63/150], Step [1901/5000], Loss = 0.0007\n",
      "Epoch [63/150], Step [2001/5000], Loss = 0.0002\n",
      "Epoch [63/150], Step [2101/5000], Loss = 0.0688\n",
      "Epoch [63/150], Step [2201/5000], Loss = 0.0001\n",
      "Epoch [63/150], Step [2301/5000], Loss = 0.0009\n",
      "Epoch [63/150], Step [2401/5000], Loss = 0.0031\n",
      "Epoch [63/150], Step [2501/5000], Loss = 0.0000\n",
      "Epoch [63/150], Step [2601/5000], Loss = 0.0057\n",
      "Epoch [63/150], Step [2701/5000], Loss = 0.0002\n",
      "Epoch [63/150], Step [2801/5000], Loss = 0.0245\n",
      "Epoch [63/150], Step [2901/5000], Loss = 0.0011\n",
      "Epoch [63/150], Step [3001/5000], Loss = 0.0003\n",
      "Epoch [63/150], Step [3101/5000], Loss = 0.0010\n",
      "Epoch [63/150], Step [3201/5000], Loss = 0.0461\n",
      "Epoch [63/150], Step [3301/5000], Loss = 0.0004\n",
      "Epoch [63/150], Step [3401/5000], Loss = 0.0001\n",
      "Epoch [63/150], Step [3501/5000], Loss = 0.0172\n",
      "Epoch [63/150], Step [3601/5000], Loss = 0.0003\n",
      "Epoch [63/150], Step [3701/5000], Loss = 0.0440\n",
      "Epoch [63/150], Step [3801/5000], Loss = 0.0007\n",
      "Epoch [63/150], Step [3901/5000], Loss = 0.0002\n",
      "Epoch [63/150], Step [4001/5000], Loss = 0.0005\n",
      "Epoch [63/150], Step [4101/5000], Loss = 0.0016\n",
      "Epoch [63/150], Step [4201/5000], Loss = 0.0003\n",
      "Epoch [63/150], Step [4301/5000], Loss = 0.0138\n",
      "Epoch [63/150], Step [4401/5000], Loss = 0.0000\n",
      "Epoch [63/150], Step [4501/5000], Loss = 0.0002\n",
      "Epoch [63/150], Step [4601/5000], Loss = 0.0001\n",
      "Epoch [63/150], Step [4701/5000], Loss = 0.0664\n",
      "Epoch [63/150], Step [4801/5000], Loss = 0.0015\n",
      "Epoch [63/150], Step [4901/5000], Loss = 0.2062\n",
      "Epoch [63/150], Acc = 80.0000\n",
      "Epoch [64/150], Step [1/5000], Loss = 0.0012\n",
      "Epoch [64/150], Step [101/5000], Loss = 0.0009\n",
      "Epoch [64/150], Step [201/5000], Loss = 0.0027\n",
      "Epoch [64/150], Step [301/5000], Loss = 0.0004\n",
      "Epoch [64/150], Step [401/5000], Loss = 0.0932\n",
      "Epoch [64/150], Step [501/5000], Loss = 0.0003\n",
      "Epoch [64/150], Step [601/5000], Loss = 0.0002\n",
      "Epoch [64/150], Step [701/5000], Loss = 0.0000\n",
      "Epoch [64/150], Step [801/5000], Loss = 0.0062\n",
      "Epoch [64/150], Step [901/5000], Loss = 0.0032\n",
      "Epoch [64/150], Step [1001/5000], Loss = 0.0008\n",
      "Epoch [64/150], Step [1101/5000], Loss = 0.0001\n"
     ]
    }
   ],
   "source": [
    "niter = 0\n",
    "for epoch in range(num_epochs):\n",
    "    for i,(images,labels) in enumerate(trainloader):\n",
    "        images = images.cuda()\n",
    "        labels =labels.cuda()\n",
    "        outputs = model(images)\n",
    "        optimizer.zero_grad()\n",
    "        loss = criterion(outputs,labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        del images,labels,outputs\n",
    "        if i%100 == 0:\n",
    "            print('Epoch [%d/%d], Step [%d/%d], Loss = %.4f' %(epoch+1, num_epochs, i+1, len(trainset)//batch_size, loss.data))\n",
    "            writer.add_scalar('Train/Loss', loss.data, niter)\n",
    "            niter += 100\n",
    "    acc = val(testloader,model)\n",
    "    print('Epoch [%d/%d], Acc = %.4f' %(epoch + 1, num_epochs, acc))\n",
    "    writer.add_scalar('Val/Acc', acc, epoch + 1)\n",
    "    torch.save(model.state_dict(),'densenet_checkpoint.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the network on the 10000 test images: 74 %\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
